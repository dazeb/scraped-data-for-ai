[
  {
    "title": "更新日志 | DeepSeek API Docs",
    "url": "https://platform.deepseek.com/api-docs/zh-cn/updates/",
    "html": "跳到主要内容\nDeepSeek API 文档\n中文（中国）\nDeepSeek Platform\n快速开始\nAPIs\n基本信息\n对话（Chat)\n对话补全\n模型（Model）\n列出模型\n其它\n查询余额\n模型 & 价格\n常见问题\n更新日志\n更新日志\n更新日志\n版本：2024-06-28​\ndeepseek-chat​\n\n模型推理能力提升，相关基准测试：\n\n代码，HumanEval Pass@1 79.88% -> 84.76%\n数学，MATH ACC@1 55.02% -> 71.02%\n推理，BBH 78.56% -> 83.40%\n\n在 Arena-Hard 测评中，与 GPT-4-0314 的对战胜率从 41.6% 提升到了 68.3%。\n\n模型角色扮演能力显著增强，可以在对话中按要求扮演不同角色。\n\n版本：2024-06-14​\ndeepseek-coder​\n\ndeepseek-coder 模型升级为 DeepSeek-Coder-V2 Instruct，代码能力显著提升，在代码生成、代码理解、代码修复和代码补全上达到了 GPT-4-Turbo-0409 的水平，并拥有卓越的数学和推理能力，其通用能力与 DeepSeek-V2 Chat 持平。\n\n版本：2024-05-17​\ndeepseek-chat​\n\n模型在指令跟随方面的性能得到了显著提升，IFEval Benchmark Prompt-Level 准确率从 63.9% 跃升至 77.6%。此外，我们对API端的“system”区域指令跟随能力进行了优化，显著增强了沉浸式翻译、RAG 等任务的用户体验。\n\n模型对于 JSON 格式输出的准确性得到了提升。在内部测试集中，JSON 解析率从 78% 提高到了85%。通过引入恰当的正则表达式，JSON 解析率进一步提高至 97%。\n\n上一页\n常见问题\n版本：2024-06-28\ndeepseek-chat\n版本：2024-06-14\ndeepseek-coder\n版本：2024-05-17\ndeepseek-chat\n微信公众号\n社区\n邮箱\nDiscord\nTwitter\n更多\nGitHub\nCopyright © 2024 DeepSeek, Inc."
  },
  {
    "title": "DeepSeek API Docs",
    "url": "https://platform.deepseek.com/api-docs/zh-cn/faq/",
    "html": "跳到主要内容\nDeepSeek API 文档\n中文（中国）\nDeepSeek Platform\n快速开始\nAPIs\n基本信息\n对话（Chat)\n对话补全\n模型（Model）\n列出模型\n其它\n查询余额\n模型 & 价格\n常见问题\n更新日志\n常见问题\n常见问题\n账号问题​\n账号无法登陆​\n\n您账号近期的行为可能触发了我们的自动化风控策略，导致我们暂时关闭了您对账号的访问权限。如需申诉，请填写问卷，我们会尽快处理。\n\n企业认证​\n个人实名认证与企业实名认证有什么区别？​\n\n个人实名认证账号与企业实名认证账号在用户权益和产品功能上目前没有区别，但认证方式和所需材料有所不同。根据合规要求，请以您账号的实际使用情况进行认证。\n\n企业实名账号可以更改为个人账号吗？​\n\n企业实名认证账号不可变更为个人认证或其他企业。\n\n财务问题​\n如何充值？​\n\n线上充值：完成实名认证后，您可以在充值页使用支付宝/微信进行在线充值。您可以在账单页查询充值结果。\n\n线下汇款：请添加DeepSeek API小助手企业微信对接汇款流程。汇款后，请向小助手企业微信提交回执单，在汇款户名、银行信息正确的情况下，汇款预计1 - 2 个工作日内到账，请耐心等待。\n\n余额是否会过期？​\n\n充值余额不会失效过期。赠送余额的有效期您可以在账单页查看。\n\n如何申请发票？​\n\n我们目前支持按照充值金额开具电子发票。企业用户开具发票时，发票抬头需要与实名认证信息一致，目前开发票的周期为7个工作日左右。已开具发票的金额不予退款。 请添加DeepSeek API小助手企业微信，对接开票流程。\n\nAPI 调用问题​\n调用模型时的并发限制是多少？是否可以提高账号的并发上限？​\n\n当前阶段，我们没有按照用户设置硬性并发上限。在系统总负载量较高时，基于系统负载和用户短时历史用量的动态限流模型可能会导致用户收到 503 或 429 错误码。\n\n目前暂不支持针对单个账号提高并发上限，感谢您的理解。\n\n为什么我感觉 API 返回比网页端慢​\n\n网页端默认使用流式输出（stream=true），即模型每输出一个字符，都会增量地显示在前端。\n\nAPI 默认使用非流式输出（stream=false），即模型在所有内容输出完后，才会返回给用户。您可以通过开启 API 的 stream 模式来提升交互性。\n\n是否支持 LangChain？​\n\n支持。LangChain 支持 OpenAI API 接口，而 DeepSeek API 接口与 OpenAI 兼容。您可以下载以下代码文件并替换代码中的 API Key，实现在 LangChain 中调用 DeepSeek API。\n\ndeepseek_v2_langchain.py\n\n是否支持 Embedding、Function Calling？​\n\n暂不支持。正在计划开发当中。\n\n是否支持 JSON Output？​\n\n您可以在 prompt 中要求模型返回 JSON 格式内容，并对结果进行解析。暂不支持 OpenAI SDK 中 response_format = { \"type\": \"json_object\" } 的调用。\n\n如何离线计算 Tokens 用量？​\n\n您可以通过如下压缩包中的代码来运行 tokenizer，以离线计算一段文本的 Token 用量。\n\ndeepseek_v2_tokenizer.zip\n\n本地私有化部署问题​\n是否支持本地私有化部署？​\n\nDeepSeek 提供本地私有化部署服务，标准化成品交付，开箱即用，轻松升级。 价格 45 万/套/年，支持灵活的商务方案（请添加API小助手企业微信对接流程）。\n\n价格包含：\n\n一台推理训练一体化的高性能服务器（Nvidia H20、Huawei 910B 或其它同级别显卡，8 显卡互联）。\n模型：DeepSeek-V2-236B、DeepSeek-Coder-V2-236B、后续其它模型。\n一站式软件套件：推理、微调、运维等。\n对每个客户，DeepSeek 均会针对应用场景，使用公开数据、脱敏数据进行训练和调优。客户可以使用私有数据进一步微调。\n不低于 5 人日/年的技术支持。\n\n预期性能：\n\n输入：20000 tokens/s\n输出：5000~10000 tokens/s\n上一页\n模型 & 价格\n下一页\n更新日志\n账号问题\n账号无法登陆\n企业认证\n个人实名认证与企业实名认证有什么区别？\n企业实名账号可以更改为个人账号吗？\n财务问题\n如何充值？\n余额是否会过期？\n如何申请发票？\nAPI 调用问题\n调用模型时的并发限制是多少？是否可以提高账号的并发上限？\n为什么我感觉 API 返回比网页端慢\n是否支持 LangChain？\n是否支持 Embedding、Function Calling？\n是否支持 JSON Output？\n如何离线计算 Tokens 用量？\n本地私有化部署问题\n是否支持本地私有化部署？\n微信公众号\n社区\n邮箱\nDiscord\nTwitter\n更多\nGitHub\nCopyright © 2024 DeepSeek, Inc."
  },
  {
    "title": "DeepSeek API Docs",
    "url": "https://platform.deepseek.com/api-docs/zh-cn/pricing/",
    "html": "跳到主要内容\nDeepSeek API 文档\n中文（中国）\nDeepSeek Platform\n快速开始\nAPIs\n基本信息\n对话（Chat)\n对话补全\n模型（Model）\n列出模型\n其它\n查询余额\n模型 & 价格\n常见问题\n更新日志\n模型 & 价格\n模型 & 价格\n\n下表所列模型价格以“百万 tokens”为单位。Token 是模型用来表示自然语言文本的的最小单位，可以是一个词、一个数字或一个标点符号等。我们将根据模型输入和输出的总 token 数进行计量计费。\n\n价格说明​\nCNY\nUSD\n模型\t描述\t输入价格\t输出价格\ndeepseek-chat (1)\t擅长通用对话任务，上下文长度为 32K (2)\t1 元 / 百万 tokens\t2 元 / 百万 tokens\ndeepseek-coder (1)\t擅长处理编程和数学任务，上下文长度为 32K (2)\t1 元 / 百万 tokens\t2 元 / 百万 tokens\n\n(1) deepseek-chat 和 deepseek-coder 后端模型已更新为 DeepSeek-V2 和 DeepSeek-Coder-V2，无需修改模型名称即可访问。\n\n(2) DeepSeek-V2 与 DeepSeek-Coder-V2 开源版本支持 128K 上下文，API/网页版本支持 32K 上下文。\n\n扣费规则​\n\n扣减费用 = token 消耗量 × 模型单价，对应的费用将直接从充值余额或赠送余额中进行扣减。 当充值余额与赠送余额同时存在时，优先扣减赠送余额。\n\n产品价格可能发生变动，DeepSeek 保留修改价格的权利。请您依据实际用量按需充值，定期查看此页面以获知最新价格信息。\n\n上一页\n查询余额\n下一页\n常见问题\n价格说明\n扣费规则\n微信公众号\n社区\n邮箱\nDiscord\nTwitter\n更多\nGitHub\nCopyright © 2024 DeepSeek, Inc."
  },
  {
    "title": "DeepSeek API Docs",
    "url": "https://platform.deepseek.com/api-docs/zh-cn/api/get-user-balance/",
    "html": "跳到主要内容\nDeepSeek API 文档\n中文（中国）\nDeepSeek Platform\n快速开始\nAPIs\n基本信息\n对话（Chat)\n对话补全\n模型（Model）\n列出模型\n其它\n查询余额\n模型 & 价格\n常见问题\n更新日志\nAPIs其它查询余额\n查询余额\nGET\n/user/balance\n\n查询账号余额\n\nResponses​\n200\n\nOK, 返回用户余额详情\n\nAPPLICATION/JSON\nSchema\nExample (from schema)\nExample\n\nSCHEMA\n\nis_available\nboolean\n\n当前账户是否有余额可供 API 调用\n\nbalance_infos\n\nobject[]\n\nLoading...\n上一页\n列出模型\n下一页\n模型 & 价格\n微信公众号\n社区\n邮箱\nDiscord\nTwitter\n更多\nGitHub\nCopyright © 2024 DeepSeek, Inc."
  },
  {
    "title": "DeepSeek API Docs",
    "url": "https://platform.deepseek.com/api-docs/zh-cn/api/create-chat-completion/",
    "html": "跳到主要内容\nDeepSeek API 文档\n中文（中国）\nDeepSeek Platform\n快速开始\nAPIs\n基本信息\n对话（Chat)\n对话补全\n模型（Model）\n列出模型\n其它\n查询余额\n模型 & 价格\n常见问题\n更新日志\nAPIs对话（Chat)对话补全\n对话补全\nPOST\n/chat/completions\n\n根据输入的上下文，来让模型补全对话内容。\n\nRequest​\nAPPLICATION/JSON\n\nBODY\n\nREQUIRED\n\nmessages\n\nobject[]\n\nREQUIRED\n\nmodel\nstring\nREQUIRED\n\nPossible values: [deepseek-chat, deepseek-coder]\n\n使用的模型的 ID。您可以使用 deepseek-chat 或者 deepseek-coder。\n\nfrequency_penalty\nnumber\nNULLABLE\n\nPossible values: >= -2 and <= 2\n\nDefault value: 0\n\n介于 -2.0 和 2.0 之间的数字。如果该值为正，那么新 token 会根据其在已有文本中的出现频率受到相应的惩罚，降低模型重复相同内容的可能性。\n\nmax_tokens\ninteger\nNULLABLE\n\nPossible values: > 1\n\n限制一次请求中模型生成 completion 的最大 token 数。输入 token 和输出 token 的总长度受模型的上下文长度的限制。\n\npresence_penalty\nnumber\nNULLABLE\n\nPossible values: >= -2 and <= 2\n\nDefault value: 0\n\n介于 -2.0 和 2.0 之间的数字。如果该值为正，那么新 token 会根据其是否已在已有文本中出现受到相应的惩罚，从而增加模型谈论新主题的可能性。\n\nstop\n\nobject\n\nstream\nboolean\nNULLABLE\n\n如果设置为 True，将会以 SSE（server-sent events）的形式以流式发送消息增量。消息流以 data: [DONE] 结尾。\n\ntemperature\nnumber\nNULLABLE\n\nPossible values: <= 2\n\nDefault value: 1\n\n采样温度，介于 0 和 2 之间。更高的值，如 0.8，会使输出更随机，而更低的值，如 0.2，会使其更加集中和确定。 我们通常建议可以更改这个值或者更改 top_p，但不建议同时对两者进行修改。\n\ntop_p\nnumber\nNULLABLE\n\nPossible values: <= 1\n\nDefault value: 1\n\n作为调节采样温度的替代方案，模型会考虑前 top_p 概率的 token 的结果。所以 0.1 就意味着只有包括在最高 10% 概率中的 token 会被考虑。 我们通常建议修改这个值或者更改 temperature，但不建议同时对两者进行修改。\n\nlogprobs\nboolean\nNULLABLE\n\n是否返回所输出 token 的对数概率。如果为 true，则在 message 的 content 中返回每个输出 token 的对数概率。\n\ntop_logprobs\ninteger\nNULLABLE\n\nPossible values: <= 20\n\n一个介于 0 到 20 之间的整数 N，指定每个输出位置返回输出概率 top N 的 token，且返回这些 token 的对数概率。指定此参数时，logprobs 必须为 true。\n\nResponses​\n200 (No streaming)\n200 (Streaming)\n\nOK, 返回一个 chat completion 对象。\n\nAPPLICATION/JSON\nSchema\nExample (from schema)\nExample\n\nSCHEMA\n\nid\nstring\nREQUIRED\n\n该对话的唯一标识符。\n\nchoices\n\nobject[]\n\nREQUIRED\n\ncreated\ninteger\nREQUIRED\n\n创建聊天完成时的 Unix 时间戳（以秒为单位）。\n\nmodel\nstring\nREQUIRED\n\n生成该 completion 的模型名。\n\nsystem_fingerprint\nstring\nREQUIRED\n\nThis fingerprint represents the backend configuration that the model runs with.\n\nobject\nstring\nREQUIRED\n\nPossible values: [chat.completion]\n\n对象的类型, 其值为 chat.completion。\n\nusage\n\nobject\n\nLoading...\n上一页\n基本信息\n下一页\n列出模型\n微信公众号\n社区\n邮箱\nDiscord\nTwitter\n更多\nGitHub\nCopyright © 2024 DeepSeek, Inc."
  },
  {
    "title": "DeepSeek API Docs",
    "url": "https://platform.deepseek.com/api-docs/zh-cn/api/list-models/",
    "html": "跳到主要内容\nDeepSeek API 文档\n中文（中国）\nDeepSeek Platform\n快速开始\nAPIs\n基本信息\n对话（Chat)\n对话补全\n模型（Model）\n列出模型\n其它\n查询余额\n模型 & 价格\n常见问题\n更新日志\nAPIs模型（Model）列出模型\n列出模型\nGET\n/models\n\n列出可用的模型列表，并提供相关模型的基本信息。请前往模型 & 价格查看当前支持的模型列表\n\nResponses​\n200\n\nOK, 返回模型列表\n\nAPPLICATION/JSON\nSchema\nExample (from schema)\nExample\n\nSCHEMA\n\nobject\nstring\nREQUIRED\n\nPossible values: [list]\n\ndata\n\nModel[]\n\nREQUIRED\n\nLoading...\n上一页\n对话补全\n下一页\n查询余额\n微信公众号\n社区\n邮箱\nDiscord\nTwitter\n更多\nGitHub\nCopyright © 2024 DeepSeek, Inc."
  },
  {
    "title": "DeepSeek API Docs",
    "url": "https://platform.deepseek.com/api-docs/updates/",
    "html": "Skip to main content\nDeepSeek API Docs\nEnglish\nDeepSeek Platform\nQuick Start\nAPIs\nIntroduction\nChat\nCreate Chat Completion\nModels\nLists Models\nOthers\nGet User Balance\nModels & Pricing\nFAQ\nChange Log\nChange Log\nChange Log\nVersion: 2024-06-28​\ndeepseek-chat​\n\nModel's reasoning capabilities have improved, as shown in relevant benchmarks:\n\nCoding: HumanEval Pass@1 79.88% -> 84.76%\nMathematics: MATH ACC@1 55.02% -> 71.02%\nReasoning: BBH 78.56% -> 83.40%\n\nIn the Arena-Hard evaluation, the win rate against GPT-4-0314 increased from 41.6% to 68.3%.\n\nThe model's role-playing capabilities have significantly enhanced, allowing it to act as different characters as requested during conversations.\n\nVersion: 2024-06-14​\ndeepseek-coder​\n\nThe deepseek-coder model has been upgraded to DeepSeek-Coder-V2 Instruct, significantly enhancing its coding capabilities. It has reached the level of GPT-4-Turbo-0409 in code generation, code understanding, code debugging, and code completion. Additionally, it possesses excellent mathematical and reasoning abilities, and its general capabilities are on par with DeepSeek-V2 Chat.\n\nVersion: 2024-05-17​\ndeepseek-chat​\n\nThe model has seen a significant improvement in following instructions, with the IFEval Benchmark Prompt-Level accuracy jumping from 63.9% to 77.6%. Additionally, on API end, we have optimized model ability to follow instruction filled in the ``system\" part. This optimization has significantly elevated the user experience across a variety of tasks, including immersive translation, Retrieval-Augmented Generation (RAG), and more.\n\nThe model's accuracy in outputting JSON format has been enhanced. In our internal test set, the JSON parsing rate increased from 78% to 85%. By introducing appropriate regular expressions, the JSON parsing rate was further improved to 97%.\n\nPrevious\nFAQ\nVersion: 2024-06-28\ndeepseek-chat\nVersion: 2024-06-14\ndeepseek-coder\nVersion: 2024-05-17\ndeepseek-chat\nWeChat Official Account\nCommunity\nEmail\nDiscord\nTwitter\nMore\nGitHub\nCopyright © 2024 DeepSeek, Inc."
  },
  {
    "title": "DeepSeek API Docs",
    "url": "https://platform.deepseek.com/api-docs/zh-cn/api/deepseek-api/",
    "html": "跳到主要内容\nDeepSeek API 文档\n中文（中国）\nDeepSeek Platform\n快速开始\nAPIs\n基本信息\n对话（Chat)\n对话补全\n模型（Model）\n列出模型\n其它\n查询余额\n模型 & 价格\n常见问题\n更新日志\nAPIs基本信息\nVersion: 1.0.0\nDeepseek API\n\n使用 DeepSeek API 之前，请先 创建 API 密钥。\n\nAuthentication​\nHTTP: Bearer Auth\n\nSecurity Scheme Type:\n\n\t\n\nhttp\n\n\n\n\nHTTP Authorization Scheme:\n\n\t\n\nbearer\n\nContact\n\nDeepSeek 技术支持: api-service@deepseek.com\n\nTerms of Service\n\nhttps://platform.deepseek.com/downloads/DeepSeek开放平台用户协议.html\n\nLicense\n\nMIT\n\n上一页\n快速开始\n下一页\n对话补全\n微信公众号\n社区\n邮箱\nDiscord\nTwitter\n更多\nGitHub\nCopyright © 2024 DeepSeek, Inc."
  },
  {
    "title": "FAQ | DeepSeek API Docs",
    "url": "https://platform.deepseek.com/api-docs/faq/",
    "html": "Skip to main content\nDeepSeek API Docs\nEnglish\nDeepSeek Platform\nQuick Start\nAPIs\nIntroduction\nChat\nCreate Chat Completion\nModels\nLists Models\nOthers\nGet User Balance\nModels & Pricing\nFAQ\nChange Log\nFAQ\nFAQ\nAccount​\nCannot sign in to my account​\n\nYour recent account activity may have triggered our automated risk control strategy, resulting in the temporary suspension of your access to the account. If you wish to appeal, please fill out this form, and we will process it as soon as possible.\n\nBilling​\nIs there any expiration date for my balance?​\n\nYour topped-up balance will not expire. You can check the expiration date of the granted balance on the billing page.\n\nAPI Call​\nAre there any rate limits when calling your API? Can I increase the limits for my account?​\n\nThe rate limit exposed on each account is adjusted dynamically according to our real-time traffic pressure and each account's short-term historical usage.\n\nWe temporarily do not support increasing the dynamic rate limit exposed on any individual account, thanks for your understanding.\n\nWhy do I feel that your API's speed is slower than the web service?​\n\nThe web service uses streaming output, i.e., every time the model outputs a token, it will be displayed incrementally on the web page.\n\nThe API uses non-streaming output (stream=false) by default, i.e., the model's output will not be returned to the user until the generation is done completely. You can use streaming output in your API call to optimize interactivity.\n\nDoes your API support LangChain?​\n\nYes. You can refer to the demo code below, which demonstrates how to use LangChain with DeepSeek API. Replace the API key in the code as necessary.\n\ndeepseek_v2_langchain.py\n\nDoes your API support Embedding or Function Calling?​\n\nWe do not support these features at this moment, but they are in our development plans.\n\nDoes your API support JSON Output?​\n\nYou can ask the model to return content in JSON format in the prompt and then parse the results. The call to response_format = { \"type\": \"json_object\" } in OpenAI SDK is not yet supported.\n\nHow to calculate token usage offline?​\n\nYou can run the demo tokenizer code in the following zip package to calculate the token usage for your intput/output.\n\ndeepseek_v2_tokenizer.zip\n\nPrevious\nModels & Pricing\nNext\nChange Log\nAccount\nCannot sign in to my account\nBilling\nIs there any expiration date for my balance?\nAPI Call\nAre there any rate limits when calling your API? Can I increase the limits for my account?\nWhy do I feel that your API's speed is slower than the web service?\nDoes your API support LangChain?\nDoes your API support Embedding or Function Calling?\nDoes your API support JSON Output?\nHow to calculate token usage offline?\nWeChat Official Account\nCommunity\nEmail\nDiscord\nTwitter\nMore\nGitHub\nCopyright © 2024 DeepSeek, Inc."
  },
  {
    "title": "DeepSeek API Docs",
    "url": "https://platform.deepseek.com/api-docs/pricing/",
    "html": "Skip to main content\nDeepSeek API Docs\nEnglish\nDeepSeek Platform\nQuick Start\nAPIs\nIntroduction\nChat\nCreate Chat Completion\nModels\nLists Models\nOthers\nGet User Balance\nModels & Pricing\nFAQ\nChange Log\nModels & Pricing\nModels & Pricing\n\nThe prices listed below are in unites of per 1M tokens. A token, the smallest unit of text that the model recognizes, can be a word, a number, or even a punctuation mark. We will bill based on the total number of input and output tokens by the model.\n\nPricing Details​\nUSD\nCNY\nMODEL\tDESCRIPTION\tINPUT PRICE\tOUTPUT PRICE\ndeepseek-chat (1)\tGood at general tasks, 32K (2) context length\t$0.14 / 1M tokens\t$0.28 / 1M tokens\ndeepseek-coder (1)\tGood at coding and math tasks, 32K (2) context length\t$0.14 / 1M tokens\t$0.28 / 1M tokens\n\n(1) The backend model of deepseek-chat and deepseek-coder has been updated to DeepSeek-V2 and DeepSeek-Coder-V2, you can access them without modification to the model name.\n\n(2) The open-source DeepSeek-V2 and DeepSeek-Coder-V2 models support 128K context window, and the API/Web supports 32K context window.\n\nDeduction Rules​\n\nThe expense = number of tokens × price. The corresponding fees will be directly deducted from your topped-up balance or granted balance, with a preference for using the granted balance first when both balances are available.\n\nProduct prices may vary and DeepSeek reserves the right to adjust them. We recommend topping up based on your actual usage and regularly checking this page for the most recent pricing information.\n\nPrevious\nGet User Balance\nNext\nFAQ\nPricing Details\nDeduction Rules\nWeChat Official Account\nCommunity\nEmail\nDiscord\nTwitter\nMore\nGitHub\nCopyright © 2024 DeepSeek, Inc."
  },
  {
    "title": "快速开始 | DeepSeek API Docs",
    "url": "https://platform.deepseek.com/api-docs/zh-cn/",
    "html": "跳到主要内容\nDeepSeek API 文档\n中文（中国）\nDeepSeek Platform\n快速开始\nAPIs\n基本信息\n对话（Chat)\n对话补全\n模型（Model）\n列出模型\n其它\n查询余额\n模型 & 价格\n常见问题\n更新日志\n快速开始\n快速开始\n\nDeepSeek API 使用与 OpenAI 兼容的 API 格式，通过修改配置，您可以使用 OpenAI SDK 来访问 DeepSeek API，或使用与 OpenAI API 兼容的软件。\n\n参数        \t值\nbase_url *\thttps://api.deepseek.com\napi_key\t申请 API key\n\n* 出于与 OpenAI 兼容考虑，您也可以将 base_url 设置为 https://api.deepseek.com/v1 来使用，但注意，此处 v1 与模型版本无关。\n\n调用对话 API​\n\n在创建 API key 之后，你可以使用以下样例脚本的来访问 DeepSeek API。样例为非流式输出，您可以将 stream 设置为 true 来使用流式输出。\n\n# bash\ncurl https://api.deepseek.com/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $DEEPSEEK_API_KEY\" \\\n  -d '{\n        \"model\": \"deepseek-chat\",\n        \"messages\": [\n          {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n          {\"role\": \"user\", \"content\": \"Hello!\"}\n        ],\n        \"stream\": false\n      }'\n\n# python3\n# Please install OpenAI SDK first：`pip3 install openai`\nfrom openai import OpenAI\n\nclient = OpenAI(api_key=\"<deepseek api key>\", base_url=\"https://api.deepseek.com\")\n\nresponse = client.chat.completions.create(\n    model=\"deepseek-chat\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n        {\"role\": \"user\", \"content\": \"Hello\"},\n    ],\n    stream=False\n)\n\nprint(response.choices[0].message.content)\n\n模型​\n模型\t描述\t上下文长度\t最大输出长度\ndeepseek-chat (1)\t擅长通用对话任务\t32K (2)\t4K\ndeepseek-coder (1)\t擅长处理编程和数学任务\t32K (2)\t4K\n\n(1) deepseek-chat 和 deepseek-coder 后端模型已更新为 DeepSeek-V2 和 DeepSeek-Coder-V2，无需修改模型名称即可访问。\n\n(2) DeepSeek-V2 与 DeepSeek-Coder-V2 开源版本支持 128K 上下文，API/网页版本支持 32K 上下文。\n\n模型 temperature 设置​\n\ntemperature 参数默认为 1.0。\n\n对于 deepseek-coder，我们建议您使用默认 temperature 值（1.0）。\n对于 deepseek-chat，我们建议您根据如下表格，按使用场景设置 temperature。\n场景\t温度\n代码生成/数学解题   \t0.0\n数据抽取/分析\t0.7\n通用对话\t1.0\n翻译\t1.1\n创意类写作/诗歌创作\t1.25\n限速​\n\n每个账户的速率限制会根据我们实时的流量压力动态调整。当我们的服务器承受高流量压力时，您可能会收到 429（请求速率达到上限）或 503（服务器繁忙）的错误。当这种情况发生时，请稍等片刻再重试。我们也建议您临时切换到其它大模型厂商（如 OpenAI）的 API。\n\nToken & Token 用量计算​\n\ntoken 是模型用来表示自然语言文本的基本单位，也是我们的计费单元，可以直观的理解为“字”或“词”；通常 1 个中文词语、1 个英文单词、1 个数字或 1 个符号计为 1 个 token。\n\n一般情况下模型中 token 和字数的换算比例大致如下：\n\n1 个英文字符 ≈ 0.3 个 token。\n1 个中文字符 ≈ 0.6 个 token。\n\n但因为不同模型的分词不同，所以换算比例也存在差异，每一次实际处理 token 数量以模型返回为准，您可以从返回结果的 usage 中查看。\n\n错误码​\n\n您在调用 DeepSeek API 时，可能会遇到以下错误。这里列出了相关错误的原因及其解决方法。\n\n错误码\t描述\n400 - 格式错误\t原因：请求体格式错误\n解决方法：请根据错误信息提示修改请求体\n401 - 认证失败\t原因：API key 错误，认证失败\n解决方法：请检查您的 API key 是否正确，如没有 API key，请先 创建 API key\n402 - 余额不足\t原因：账号余额不足\n解决方法：请确认账户余额，并前往 充值 页面进行充值\n422 - 参数错误\t原因：请求体参数错误\n解决方法：请根据错误信息提示修改相关参数\n429 - 请求速率达到上限\t原因：请求速率（TPM 或 RPM）达到上限\n解决方法：请合理规划您的请求速率。我们也建议您临时切换到其它大模型厂商（如 OpenAI）的 API\n500 - 服务器故障\t原因：服务器内部故障\n解决方法：请等待后重试。若问题一直存在，请联系我们解决\n503 - 服务器繁忙\t原因：服务器负载过高\n解决方法：请稍后重试您的请求\n下一页\n基本信息\n调用对话 API\n模型\n模型 temperature 设置\n限速\nToken & Token 用量计算\n错误码\n微信公众号\n社区\n邮箱\nDiscord\nTwitter\n更多\nGitHub\nCopyright © 2024 DeepSeek, Inc."
  },
  {
    "title": "DeepSeek API Docs",
    "url": "https://platform.deepseek.com/api-docs/api/get-user-balance/",
    "html": "Skip to main content\nDeepSeek API Docs\nEnglish\nDeepSeek Platform\nQuick Start\nAPIs\nIntroduction\nChat\nCreate Chat Completion\nModels\nLists Models\nOthers\nGet User Balance\nModels & Pricing\nFAQ\nChange Log\nAPIsOthersGet User Balance\nGet User Balance\nGET\n/user/balance\n\nGet user current balance\n\nResponses​\n200\n\nOK, returns user balance info.\n\nAPPLICATION/JSON\nSchema\nExample (from schema)\nExample\n\nSCHEMA\n\nis_available\nboolean\n\nWhether the user's balance is sufficient for API calls.\n\nbalance_infos\n\nobject[]\n\nLoading...\nPrevious\nLists Models\nNext\nModels & Pricing\nWeChat Official Account\nCommunity\nEmail\nDiscord\nTwitter\nMore\nGitHub\nCopyright © 2024 DeepSeek, Inc."
  },
  {
    "title": "Lists Models | DeepSeek API Docs",
    "url": "https://platform.deepseek.com/api-docs/api/list-models/",
    "html": "Skip to main content\nDeepSeek API Docs\nEnglish\nDeepSeek Platform\nQuick Start\nAPIs\nIntroduction\nChat\nCreate Chat Completion\nModels\nLists Models\nOthers\nGet User Balance\nModels & Pricing\nFAQ\nChange Log\nAPIsModelsLists Models\nLists Models\nGET\n/models\n\nLists the currently available models, and provides basic information about each one such as the owner and availability. Check Models & Pricing for our currently supported models.\n\nResponses​\n200\n\nOK, returns A list of models\n\nAPPLICATION/JSON\nSchema\nExample (from schema)\nExample\n\nSCHEMA\n\nobject\nstring\nREQUIRED\n\nPossible values: [list]\n\ndata\n\nModel[]\n\nREQUIRED\n\nLoading...\nPrevious\nCreate Chat Completion\nNext\nGet User Balance\nWeChat Official Account\nCommunity\nEmail\nDiscord\nTwitter\nMore\nGitHub\nCopyright © 2024 DeepSeek, Inc."
  },
  {
    "title": "Create Chat Completion | DeepSeek API Docs",
    "url": "https://platform.deepseek.com/api-docs/api/create-chat-completion/",
    "html": "Skip to main content\nDeepSeek API Docs\nEnglish\nDeepSeek Platform\nQuick Start\nAPIs\nIntroduction\nChat\nCreate Chat Completion\nModels\nLists Models\nOthers\nGet User Balance\nModels & Pricing\nFAQ\nChange Log\nAPIsChatCreate Chat Completion\nCreate Chat Completion\nPOST\n/chat/completions\n\nCreates a model response for the given chat conversation.\n\nRequest​\nAPPLICATION/JSON\n\nBODY\n\nREQUIRED\n\nmessages\n\nobject[]\n\nREQUIRED\n\nmodel\nstring\nREQUIRED\n\nPossible values: [deepseek-chat, deepseek-coder]\n\nID of the model to use. You can use either usedeepseek-coder or deepseek-chat.\n\nfrequency_penalty\nnumber\nNULLABLE\n\nPossible values: >= -2 and <= 2\n\nDefault value: 0\n\nNumber between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n\nmax_tokens\ninteger\nNULLABLE\n\nPossible values: > 1\n\nThe maximum number of tokens that can be generated in the chat completion.\n\nThe total length of input tokens and generated tokens is limited by the model's context length.\n\npresence_penalty\nnumber\nNULLABLE\n\nPossible values: >= -2 and <= 2\n\nDefault value: 0\n\nNumber between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\n\nstop\n\nobject\n\nstream\nboolean\nNULLABLE\n\nIf set, partial message deltas will be sent. Tokens will be sent as data-only server-sent events (SSE) as they become available, with the stream terminated by a data: [DONE] message.\n\ntemperature\nnumber\nNULLABLE\n\nPossible values: <= 2\n\nDefault value: 1\n\nWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\n\nWe generally recommend altering this or top_p but not both.\n\ntop_p\nnumber\nNULLABLE\n\nPossible values: <= 1\n\nDefault value: 1\n\nAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n\nWe generally recommend altering this or temperature but not both.\n\nlogprobs\nboolean\nNULLABLE\n\nWhether to return log probabilities of the output tokens or not. If true, returns the log probabilities of each output token returned in the content of message.\n\ntop_logprobs\ninteger\nNULLABLE\n\nPossible values: <= 20\n\nAn integer between 0 and 20 specifying the number of most likely tokens to return at each token position, each with an associated log probability. logprobs must be set to true if this parameter is used.\n\nResponses​\n200 (No streaming)\n200 (Streaming)\n\nOK, returns a chat completion object\n\nAPPLICATION/JSON\nSchema\nExample (from schema)\nExample\n\nSCHEMA\n\nid\nstring\nREQUIRED\n\nA unique identifier for the chat completion.\n\nchoices\n\nobject[]\n\nREQUIRED\n\ncreated\ninteger\nREQUIRED\n\nThe Unix timestamp (in seconds) of when the chat completion was created.\n\nmodel\nstring\nREQUIRED\n\nThe model used for the chat completion.\n\nsystem_fingerprint\nstring\nREQUIRED\n\nThis fingerprint represents the backend configuration that the model runs with.\n\nobject\nstring\nREQUIRED\n\nPossible values: [chat.completion]\n\nThe object type, which is always chat.completion.\n\nusage\n\nobject\n\nLoading...\nPrevious\nIntroduction\nNext\nLists Models\nWeChat Official Account\nCommunity\nEmail\nDiscord\nTwitter\nMore\nGitHub\nCopyright © 2024 DeepSeek, Inc."
  },
  {
    "title": "DeepSeek API Docs",
    "url": "https://platform.deepseek.com/api-docs/api/deepseek-api/",
    "html": "Skip to main content\nDeepSeek API Docs\nEnglish\nDeepSeek Platform\nQuick Start\nAPIs\nIntroduction\nChat\nCreate Chat Completion\nModels\nLists Models\nOthers\nGet User Balance\nModels & Pricing\nFAQ\nChange Log\nAPIsIntroduction\nVersion: 1.0.0\nDeepSeek API\n\nThe DeepSeek API. To use the DeepSeek API, please create an API key first.\n\nAuthentication​\nHTTP: Bearer Auth\n\nSecurity Scheme Type:\n\n\t\n\nhttp\n\n\n\n\nHTTP Authorization Scheme:\n\n\t\n\nbearer\n\nContact\n\nDeepSeek Support: api-service@deepseek.com\n\nTerms of Service\n\nhttps://platform.deepseek.com/downloads/DeepSeek%20Open%20Platform%20Terms%20of%20Service.html\n\nLicense\n\nMIT\n\nPrevious\nQuick Start\nNext\nCreate Chat Completion\nWeChat Official Account\nCommunity\nEmail\nDiscord\nTwitter\nMore\nGitHub\nCopyright © 2024 DeepSeek, Inc."
  },
  {
    "title": "DeepSeek API Docs",
    "url": "https://platform.deepseek.com/api-docs/",
    "html": "Skip to main content\nDeepSeek API Docs\nEnglish\nDeepSeek Platform\nQuick Start\nAPIs\nIntroduction\nChat\nCreate Chat Completion\nModels\nLists Models\nOthers\nGet User Balance\nModels & Pricing\nFAQ\nChange Log\nQuick Start\nQuick Start\n\nThe DeepSeek API uses an API format compatible with OpenAI. By modifying the configuration, you can use the OpenAI SDK or softwares compatible with the OpenAI API to access the DeepSeek API.\n\nPARAM\tVALUE\nbase_url *       \thttps://api.deepseek.com\napi_key\tapply for an API key\n\n* To be compatible with OpenAI, you can also use https://api.deepseek.com/v1 as the base_url. But note that the v1 here has NO relationship with the model's version.\n\nInvoke The Chat API​\n\nOnce you have obtained an API key, you can access the DeepSeek API using the following example scripts. This is a non-stream example, you can set the stream parameter to true to get stream response.\n\n# bash\ncurl https://api.deepseek.com/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $DEEPSEEK_API_KEY\" \\\n  -d '{\n        \"model\": \"deepseek-chat\",\n        \"messages\": [\n          {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n          {\"role\": \"user\", \"content\": \"Hello!\"}\n        ],\n        \"stream\": false\n      }'\n\n# python3\n# please install OpenAI SDK first: `pip3 install openai`\nfrom openai import OpenAI\n\nclient = OpenAI(api_key=\"<deepseek api key>\", base_url=\"https://api.deepseek.com\")\n\nresponse = client.chat.completions.create(\n    model=\"deepseek-chat\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n        {\"role\": \"user\", \"content\": \"Hello\"},\n    ],\n    stream=False\n)\n\nprint(response.choices[0].message.content)\n\nModels​\nMODEL\tDESCRIPTION\tCONTEXT LENGTH\tMAX OUTPUT LENGTH\ndeepseek-chat (1)\tgood at general tasks\t32K (2)\t4K\ndeepseek-coder (1)\tgood at coding and math\t32K (2)\t4K\n(1) The backend model of deepseek-chat and deepseek-coder has been updated to DeepSeek-V2 and DeepSeek-Coder-V2, you can access them without modification to the model name.\n(2) The open-source DeepSeek-V2 and DeepSeek-Coder-V2 models support 128K context window, and the API/Web supports 32K context window.\nThe temperature Parameter​\n\nThe default value of temperature is 1.0.\n\nFor deepseek-coder，we recommend users to use the default temperature (1.0).\nFor deepseek-chat，we recommend users to set the temperature according to their use case listed in below.\nUSE CASE\tTEMPERATURE\nCoding / Math   \t0.0\nData Cleaning / Data Analysis\t0.7\nGeneral Conversation\t1.0\nTranslation\t1.1\nCreative Writing / Poetry\t1.25\nRate Limiting​\n\nThe rate limit of each account is adjusted dynamically according to our real-time traffic pressure. When our servers are under high traffic pressure, you may receive 429 (Rate Limit Reached) or 503 (Server Overloaded). When this happens, please wait for a while and retry, and we also advise users to temporarily switch to the APIs of alternative LLM service providers, like OpenAI.\n\nToken & Token Usage​\n\nTokens are the basic units used by models to represent natural language text, and also the units we use for billing. They can be intuitively understood as 'characters' or 'words'. Typically, a Chinese word, an English word, a number, or a symbol is counted as a token.\n\nGenerally, the conversion ratio between tokens in the model and the number of characters is approximately as following:\n\n1 English character ≈ 0.3 token.\n1 Chinese character ≈ 0.6 token.\n\nHowever, due to the different tokenization methods used by different models, the conversion ratios can vary. The actual number of tokens processed each time is based on the model's return, which you can view from the usage results.\n\nError Codes​\n\nWhen calling DeepSeek API, you may encounter errors. Here list the causes and solutions.\n\nCODE\tDESCRIPTION\n400 - Invalid Format\tCause: Invalid request body format.\nSolution: Please modify your request body according to the hints in the error message. For more API format details, please refer to DeepSeek API Docs.\n401 - Authentication Fails\tCause: Authentication fails due to the wrong API key.\nSolution: Please check your API key. If you don't have one, please create an API key first.\n402 - Insufficient Balance\tCause: You have run out of balance.\nSolution: Please check your account's balance, and go to the Top up page to add funds.\n422 - Invalid Parameters\tCause: Your request contains invalid parameters.\nSolution: Please modify your request parameters according to the hints in the error message. For more API format details, please refer to DeepSeek API Docs.\n429 - Rate Limit Reached\tCause: You are sending requests too quickly.\nSolution: Please pace your requests reasonably. We also advise users to temporarily switch to the APIs of alternative LLM service providers, like OpenAI.\n500 - Server Error\tCause: Our server encounters an issue.\nSolution: Please retry your request after a brief wait and contact us if the issue persists.\n503 - Server Overloaded\tCause: The server is overloaded due to high traffic.\nSolution: Please retry your request after a brief wait.\nNext\nIntroduction\nInvoke The Chat API\nModels\nThe temperature Parameter\nRate Limiting\nToken & Token Usage\nError Codes\nWeChat Official Account\nCommunity\nEmail\nDiscord\nTwitter\nMore\nGitHub\nCopyright © 2024 DeepSeek, Inc."
  }
]