[
  {
    "title": "Supabase | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/vector-stores/supabase",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nAstraDB\nChroma\nElastic\nFaiss\nIn-Memory Vector Store\nMilvus\nMongoDB Atlas\nOpenSearch\nPinecone\nPostgres\nQdrant\nRedis\nSingleStore\nSupabase\nUpstash Vector\nVectara\nWeaviate\nZep Collection - Open Source\nZep Collection - Cloud\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nSupabase\nPrerequisite\n\nRegister an account for Supabase\n\nClick New project\n\nInput required fields\n\nField Name\tDescription\n\n\nName\n\n\t\n\nname of the project to be created. (e.g. Flowise)\n\n\n\n\nDatabase Password\n\n\t\n\npassword to your postgres database\n\nClick Create new project and wait for the project to finish setting up\n\nClick SQL Editor\n\nClick New query\n\nCopy and Paste the below SQL query and run it by Ctrl + Enter or click RUN. Take note of the table name and function name.\n\nTable name: documents\n\nQuery name: match_documents\n\nCopy\n-- Enable the pgvector extension to work with embedding vectors\n\ncreate extension vector;\n\n\n\n-- Create a table to store your documents\n\ncreate table documents (\n\n  id bigserial primary key,\n\n  content text, -- corresponds to Document.pageContent\n\n  metadata jsonb, -- corresponds to Document.metadata\n\n  embedding vector(1536) -- 1536 works for OpenAI embeddings, change if needed\n\n);\n\n\n\n-- Create a function to search for documents\n\ncreate function match_documents (\n\n  query_embedding vector(1536),\n\n  match_count int DEFAULT null,\n\n  filter jsonb DEFAULT '{}'\n\n) returns table (\n\n  id bigint,\n\n  content text,\n\n  metadata jsonb,\n\n  similarity float\n\n)\n\nlanguage plpgsql\n\nas $$\n\n#variable_conflict use_column\n\nbegin\n\n  return query\n\n  select\n\n    id,\n\n    content,\n\n    metadata,\n\n    1 - (documents.embedding <=> query_embedding) as similarity\n\n  from documents\n\n  where metadata @> filter\n\n  order by documents.embedding <=> query_embedding\n\n  limit match_count;\n\nend;\n\n$$;\n\n\nIf some cases, you might be using Record Manager to keep track of the upserts and prevent duplications. Since Record Manager generates a random UUID for each embeddings, you will have to change the id column entity to text:\n\nCopy\n-- Enable the pgvector extension to work with embedding vectors\n\ncreate extension vector;\n\n\n\n-- Create a table to store your documents\n\ncreate table documents (\n\n  id text primary key, -- CHANGE TO TEXT\n\n  content text,\n\n  metadata jsonb,\n\n  embedding vector(1536)\n\n);\n\n\n\n-- Create a function to search for documents\n\ncreate function match_documents (\n\n  query_embedding vector(1536),\n\n  match_count int DEFAULT null,\n\n  filter jsonb DEFAULT '{}'\n\n) returns table (\n\n  id text, -- CHANGE TO TEXT\n\n  content text,\n\n  metadata jsonb,\n\n  similarity float\n\n)\n\nlanguage plpgsql\n\nas $$\n\n#variable_conflict use_column\n\nbegin\n\n  return query\n\n  select\n\n    id,\n\n    content,\n\n    metadata,\n\n    1 - (documents.embedding <=> query_embedding) as similarity\n\n  from documents\n\n  where metadata @> filter\n\n  order by documents.embedding <=> query_embedding\n\n  limit match_count;\n\nend;\n\n$$;\n\nSetup\n\nClick Project Settings\n\nGet your Project URL & API Key\n\nCopy and Paste each details (API Key, URL, Table Name, Query Name) into Supabase node\n\nDocument can be connected with any node under Document Loader category\n\nEmbeddings can be connected with any node under Embeddings category\n\nFiltering\n\nLet's say you have different documents upserted, each specified with a unique value under the metadata key {source}\n\nYou can use metadata filtering to query specific metadata:\n\nUI\n\nAPI\n\nCopy\n\"overrideConfig\": {\n\n    \"supabaseMetadataFilter\": {\n\n        \"source\": \"henry\"\n\n    }\n\n}\nResources\n\nLangChain JS Supabase\n\nSupabase Blog Post\n\nMetadata Filtering\n\nPrevious\nSingleStore\nNext\nUpstash Vector\n\nLast updated 4 days ago\n\nPrerequisite\nSetup\nFiltering\nResources\nEdit on GitHub"
  },
  {
    "title": "SingleStore | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/vector-stores/singlestore",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nAstraDB\nChroma\nElastic\nFaiss\nIn-Memory Vector Store\nMilvus\nMongoDB Atlas\nOpenSearch\nPinecone\nPostgres\nQdrant\nRedis\nSingleStore\nSupabase\nUpstash Vector\nVectara\nWeaviate\nZep Collection - Open Source\nZep Collection - Cloud\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nSingleStore\nSetup\n\nRegister an account on SingleStore\n\nLogin to portal. On the left side panel, click CLOUD -> Create new workspace group. Then click Create Workspace button.\n\nSelect cloud provider and data region, then click Next:\n\nReview and click Create Workspace:\n\nYou should now see your workspace created:\n\nProceed to create a database\n\nYou should be able to see your database created and attached to the workspace:\n\nClick Connect from the workspace dropdown -> Connect Directly:\n\nYou can specify a new password or use the default generated one. Then click Continue:\n\nOn the tabs, switch to Your App, and select Node.js from the dropdown. Take note/save the Username, Host, Password as you will need these in Flowise later.\n\nBack to Flowise canvas, drag and drop SingleStore nodes. Click Create New from the Credentials dropdown:\n\nPut in the Username and Password from above:\n\nThen specify the Host and Database Name:\n\nNow you can start upserting data with SingleStore:\n\nNavigate back to SingleStore portal, and to your database, you will be able to see all the data that has been upserted:\n\nPrevious\nRedis\nNext\nSupabase\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Redis | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/vector-stores/redis",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nAstraDB\nChroma\nElastic\nFaiss\nIn-Memory Vector Store\nMilvus\nMongoDB Atlas\nOpenSearch\nPinecone\nPostgres\nQdrant\nRedis\nSingleStore\nSupabase\nUpstash Vector\nVectara\nWeaviate\nZep Collection - Open Source\nZep Collection - Cloud\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nRedis\nPrerequisite\n\nSpin up a Redis-Stack Server using Docker\n\nCopy\ndocker run -d --name redis-stack-server -p 6379:6379 redis/redis-stack-server:latest\nSetup\n\nAdd a new Redis node on canvas.\n\nCreate new Redis credential.\n\nSelect type of Redis Credential. Choose Redis API if you have username and password, otherwise Redis URL:\n\nFill in the url:\n\nNow you can start upserting data with Redis:\n\nNavigate to Redis Insight portal, and to your database, you will be able to see all the data that has been upserted:\n\nPrevious\nQdrant\nNext\nSingleStore\n\nLast updated 16 days ago\n\nPrerequisite\nSetup\nEdit on GitHub"
  },
  {
    "title": "Postgres | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/vector-stores/postgres",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nAstraDB\nChroma\nElastic\nFaiss\nIn-Memory Vector Store\nMilvus\nMongoDB Atlas\nOpenSearch\nPinecone\nPostgres\nQdrant\nRedis\nSingleStore\nSupabase\nUpstash Vector\nVectara\nWeaviate\nZep Collection - Open Source\nZep Collection - Cloud\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nPostgres\n\nUpsert embedded data and perform similarity search upon query using pgvector on Postgres.\n\nPostgres Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nPinecone\nNext\nQdrant\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Qdrant | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/vector-stores/qdrant",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nAstraDB\nChroma\nElastic\nFaiss\nIn-Memory Vector Store\nMilvus\nMongoDB Atlas\nOpenSearch\nPinecone\nPostgres\nQdrant\nRedis\nSingleStore\nSupabase\nUpstash Vector\nVectara\nWeaviate\nZep Collection - Open Source\nZep Collection - Cloud\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nQdrant\nPrerequisites\n\nA locally running instance of Qdrant or a Qdrant cloud instance.\n\nTo get a Qdrant cloud instance:\n\nHead to the Clusters section of the Cloud Dashboard.\n\nSelect Clusters and then click + Create.\n\nChoose your cluster configurations and region.\n\nHit Create to provision your cluster.\n\nSetup\n\nGet/Create your API Key from the Data Access Control section of the Cloud Dashboard.\n\nAdd a new Qdrant node on canvas.\n\nCreate new Qdrant credential using the API Key\n\nEnter the required info into the Qdrant node:\n\nQdrant server URL\n\nCollection name\n\nDocument input can be connected with any node under Document Loader category.\n\nEmbeddings input can be connected with any node under Embeddings category.\n\nFiltering\n\nLet's say you have different documents upserted, each specified with a unique value under the metadata key {source}\n\nThen, you want to filter by it. Qdrant supports following syntax when it comes to filtering:\n\nUI\n\nAPI\n\nCopy\n\"overrideConfig\": {\n\n    \"qdrantFilter\": {\n\n        \"should\": [\n\n            {\n\n                \"key\": \"metadata.source\",\n\n                \"match\": {\n\n                    \"value\": \"apple\"\n\n                }\n\n            }\n\n        ]\n\n    }\n\n}\nResources\n\nQdrant documentation\n\nLangChain JS Qdrant\n\nQdrant Filter\n\nPrevious\nPostgres\nNext\nRedis\n\nLast updated 16 days ago\n\nPrerequisites\nSetup\nFiltering\nResources\nEdit on GitHub"
  },
  {
    "title": "Pinecone | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/vector-stores/pinecone",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nAstraDB\nChroma\nElastic\nFaiss\nIn-Memory Vector Store\nMilvus\nMongoDB Atlas\nOpenSearch\nPinecone\nPostgres\nQdrant\nRedis\nSingleStore\nSupabase\nUpstash Vector\nVectara\nWeaviate\nZep Collection - Open Source\nZep Collection - Cloud\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nPinecone\n\nUpsert embedded data and perform similarity search upon query using Pinecone, a leading fully managed hosted vector database.\n\nPrerequisite\n\nRegister an account for Pinecone\n\nClick Create index\n\nFill in required fields:\n\nIndex Name, name of the index to be created. (e.g. \"flowise-test\")\n\nDimensions, size of the vectors to be inserted in the index. (e.g. 1536)\n\nClick Create Index\n\nSetup\n\nGet/Create your API Key\n\nAdd a new Pinecone node to canvas and fill in the parameters:\n\nPinecone Index\n\nPinecone namespace (optional)\n\nCreate new Pinecone credential -> Fill in API Key\n\nAdd additional nodes to canvas and start the upsert process\n\nDocument can be connected with any node under Document Loader category\n\nEmbeddings can be connected with any node under Embeddings category\n\nVerify from Pinecone dashboard to see if data has been successfully upserted:\n\nResources\n\nLangChain Pinecone vectorstore integrations\n\nPython\n\nNodeJS\n\nPinecone LangChain integration\n\nPinecone Flowise integration\n\nPinecone official clients\n\nPrevious\nOpenSearch\nNext\nPostgres\n\nLast updated 2 days ago\n\nPrerequisite\nSetup\nResources\nEdit on GitHub"
  },
  {
    "title": "MongoDB Atlas | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/vector-stores/mongodb-atlas",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nAstraDB\nChroma\nElastic\nFaiss\nIn-Memory Vector Store\nMilvus\nMongoDB Atlas\nOpenSearch\nPinecone\nPostgres\nQdrant\nRedis\nSingleStore\nSupabase\nUpstash Vector\nVectara\nWeaviate\nZep Collection - Open Source\nZep Collection - Cloud\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nMongoDB Atlas\n\nUpsert embedded data and perform similarity or mmr search upon query using MongoDB Atlas, a managed cloud mongodb database.\n\nMongoDB Atlas Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nMilvus\nNext\nOpenSearch\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "OpenSearch | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/vector-stores/opensearch",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nAstraDB\nChroma\nElastic\nFaiss\nIn-Memory Vector Store\nMilvus\nMongoDB Atlas\nOpenSearch\nPinecone\nPostgres\nQdrant\nRedis\nSingleStore\nSupabase\nUpstash Vector\nVectara\nWeaviate\nZep Collection - Open Source\nZep Collection - Cloud\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nOpenSearch\n\nUpsert embedded data and perform similarity search upon query using OpenSearch, an open-source, all-in-one vector database.\n\nOpenSearch Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nMongoDB Atlas\nNext\nPinecone\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Milvus | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/vector-stores/milvus",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nAstraDB\nChroma\nElastic\nFaiss\nIn-Memory Vector Store\nMilvus\nMongoDB Atlas\nOpenSearch\nPinecone\nPostgres\nQdrant\nRedis\nSingleStore\nSupabase\nUpstash Vector\nVectara\nWeaviate\nZep Collection - Open Source\nZep Collection - Cloud\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nMilvus\n\nUpsert embedded data and perform similarity search upon query using Milvus, world's most advanced open-source vector database.\n\nMilvus Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nIn-Memory Vector Store\nNext\nMongoDB Atlas\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "In-Memory Vector Store | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/vector-stores/in-memory-vector-store",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nAstraDB\nChroma\nElastic\nFaiss\nIn-Memory Vector Store\nMilvus\nMongoDB Atlas\nOpenSearch\nPinecone\nPostgres\nQdrant\nRedis\nSingleStore\nSupabase\nUpstash Vector\nVectara\nWeaviate\nZep Collection - Open Source\nZep Collection - Cloud\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nIn-Memory Vector Store\n\nIn-memory vectorstore that stores embeddings and does an exact, linear search for the most similar embeddings.\n\nIn-Memory Vector Store Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nFaiss\nNext\nMilvus\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Custom Tool | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/tools/custom-tool",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nBraveSearch API\nCalculator\nChain Tool\nChatflow Tool\nCustom Tool\nGoogle Custom Search\nOpenAPI Toolkit\nRead File\nRetriever Tool\nSearchApi\nSerp API\nSerper\nWeb Browser\nWrite File\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nCustom Tool\n\nWatch how to use custom tools\n\nProblem\n\nFunction usually takes in structured input data. Let's say you want the LLM to be able to call Airtable Create Record API, the body parameters has to be structured in a specific way. For example:\n\nCopy\n\"records\": [\n\n  {\n\n    \"fields\": {\n\n      \"Address\": \"some address\",\n\n      \"Name\": \"some name\",\n\n      \"Visited\": true\n\n    }\n\n  }\n\n]\n\nIdeally, we want LLM to return a proper structured data like this:\n\nCopy\n{\n\n  \"Address\": \"some address\",\n\n  \"Name\": \"some name\",\n\n  \"Visited\": true\n\n}\n\nSo we can extract the value and parse it into the body needed for API. However, instructing LLM to output the exact pattern is difficult.\n\nWith the new OpenAI Function Calling models, it is now possible. gpt-4-0613 and gpt-3.5-turbo-0613 are specifically trained to return structured data. The model will intelligently choose to output a JSON object containing arguments to call those functions.\n\nTutorial\n\nGoal: Have the agent automatically get the stock price movement, retrieve related stock news, and add a new record to Airtable.\n\nLet's get started🚀\n\nCreate Tools\n\nWe need 3 tools to achieve the goal:\n\nGet Stock Price Movement\n\nGet Stock News\n\nAdd Airtable Record\n\nGet Stock Price Movement\n\nCreate a new Tool with the following details (you can change as you want):\n\nName: get_stock_movers\n\nDescription: Get the stocks that has biggest price/volume moves, e.g. actives, gainers, losers, etc.\n\nDescription is an important piece as ChatGPT is relying on this to decide when to use this tool.\n\nJavaScript Function: We are going to use Morning Star /market/v2/get-movers API to get data. First you have to click Subscribe to Test if you haven't already, then copy the code and paste it into JavaScript Function.\n\nAdd const fetch = require('node-fetch'); at the top to import the library. You can import any built-in NodeJS modules and external libraries.\n\nReturn the result at the end.\n\nThe final code should be:\n\nCopy\nconst fetch = require('node-fetch');\n\nconst url = 'https://morning-star.p.rapidapi.com/market/v2/get-movers';\n\nconst options = {\n\n\tmethod: 'GET',\n\n\theaders: {\n\n\t\t'X-RapidAPI-Key': 'replace with your api key',\n\n\t\t'X-RapidAPI-Host': 'morning-star.p.rapidapi.com'\n\n\t}\n\n};\n\n\n\ntry {\n\n\tconst response = await fetch(url, options);\n\n\tconst result = await response.text();\n\n\tconsole.log(result);\n\n\treturn result;\n\n} catch (error) {\n\n\tconsole.error(error);\n\n\treturn '';\n\n}\n\nYou can now save it.\n\nGet Stock news\n\nCreate a new Tool with the following details (you can change as you want):\n\nName: get_stock_news\n\nDescription: Get latest news for a stock\n\nInput Schema:\n\nProperty: performanceId\n\nType: string\n\nDescription: id of the stock, which is referred as performanceID in the API\n\nRequired: true\n\nInput Schema tells LLM what to return as a JSON object. In this case, we are expecting a JSON object like below:\n\nCopy\n{ \"performanceId\": \"SOME TICKER\" }\n\nJavaScript Function: We are going to use Morning Star /news/list API to get the data. First you have to click Subscribe to Test if you haven't already, then copy the code and paste it into JavaScript Function.\n\nAdd const fetch = require('node-fetch'); at the top to import the library. You can import any built-in NodeJS modules and external libraries.\n\nReturn the result at the end.\n\nNext, replace the hard-coded url query parameter performanceId: 0P0000OQN8 to the property variable specified in Input Schema: $performanceId\n\nYou can use any properties specified in Input Schema as variables in the JavaScript Function by appending a prefix $ at the front of the variable name.\n\nFinal code:\n\nCopy\nconst fetch = require('node-fetch');\n\nconst url = 'https://morning-star.p.rapidapi.com/news/list?performanceId=' + $performanceId;\n\nconst options = {\n\n\tmethod: 'GET',\n\n\theaders: {\n\n\t\t'X-RapidAPI-Key': 'replace with your api key',\n\n\t\t'X-RapidAPI-Host': 'morning-star.p.rapidapi.com'\n\n\t}\n\n};\n\n\n\ntry {\n\n\tconst response = await fetch(url, options);\n\n\tconst result = await response.text();\n\n\tconsole.log(result);\n\n\treturn result;\n\n} catch (error) {\n\n\tconsole.error(error);\n\n\treturn '';\n\n}\n\nYou can now save it.\n\nAdd Airtable Record\n\nCreate a new Tool with the following details (you can change as you want):\n\nName: add_airtable\n\nDescription: Add the stock, news summary & price move to Airtable\n\nInput Schema:\n\nProperty: stock\n\nType: string\n\nDescription: stock ticker\n\nRequired: true\n\nProperty: move\n\nType: string\n\nDescription: price move in %\n\nRequired: true\n\nProperty: news_summary\n\nType: string\n\nDescription: news summary of the stock\n\nRequired: true\n\nChatGPT will returns a JSON object like this:\n\nCopy\n{ \"stock\": \"SOME TICKER\", \"move\": \"20%\", \"news_summary\": \"Some summary\" }\n\nJavaScript Function: We are going to use Airtable Create Record API to create a new record to an existing table. You can find the tableId and baseId from here. You'll also need to create a personal access token, find how to do it here.\n\nFinal code should looks like below. Note how we pass in $stock, $move and $news_summary as variables:\n\nCopy\nconst fetch = require('node-fetch');\n\nconst baseId = 'your-base-id';\n\nconst tableId = 'your-table-id';\n\nconst token = 'your-token';\n\n\n\nconst body = {\n\n\t\"records\": [\n\n\t\t{\n\n\t\t\t\"fields\": {\n\n\t\t\t\t\"stock\": $stock,\n\n\t\t\t\t\"move\": $move,\n\n\t\t\t\t\"news_summary\": $news_summary,\n\n\t\t\t}\n\n\t\t}\n\n\t]\n\n};\n\n\n\nconst options = {\n\n\tmethod: 'POST',\n\n\theaders: {\n\n\t\t'Authorization': `Bearer ${token}`,\n\n\t\t'Content-Type': 'application/json'\n\n\t},\n\n\tbody: JSON.stringify(body)\n\n};\n\n\n\nconst url = `https://api.airtable.com/v0/${baseId}/${tableId}`\n\n\n\ntry {\n\n\tconst response = await fetch(url, options);\n\n\tconst text = await response.text();\n\n\treturn text;\n\n} catch (error) {\n\n\tconsole.error(error);\n\n\treturn '';\n\n}\n\nYou can now save it.\n\nYou should see 3 tools created:\n\nCreate Chatflow\n\nYou can use the template OpenAI Function Agent from marketplace, and replace the tools with Custom Tool. Select the tool you have created.\n\nNote: OpenAI Function Agent only supports 0613 models currently.\n\nSave the chatflow and start testing it. For starter, you can try asking:\n\nWhat is the stock that has the biggest price movement today?\n\nThe stock that has the biggest price movement today is Overstock.com (OSTK) with a price move of 17.47%.\n\nYou can then follow up with another question to get the news of that particular stock:\n\nWhat are the latest news about this stock that might cause the price movement?\n\nHere are the latest news about Overstock.com (OSTK) that might have caused the price movement:\n\nTitle: \"Overstock's shares soar on successful 21.5 million bid for Bed Bath & Beyond assets\" Source: MarketWatch Published Date: June 22, 2023 Summary: Overstock.com's shares experienced a significant increase after successfully winning a bid for Bed Bath & Beyond assets worth 21.5 million.\n\nTitle: \"Thinking about trading options or stock in Meta Platforms, Overstock.com, Walmart, Home Depot, or United Parcel Service?\" Source: PR Newswire Published Date: June 22, 2023 Summary: This news article discusses the potential trading options and stocks, including Overstock.com, that investors may consider.\n\nPlease note that these news articles are for informational purposes only and may not be the sole reason for the price movement. It is always recommended to conduct thorough research and analysis before making any investment decisions.\n\nLastly, you can ask ChatGPT to add a new record to Airtable:\n\nCan you add a record to Airtable with the stock ticker, price move and news summary?\n\nI have added a record to Airtable with the following details:\n\nStock Ticker: OSTK Price Move: 17.47% News Summary: Overstock.com's shares experienced a significant increase after successfully winning a bid for Bed Bath & Beyond assets worth $21.5 million.\n\n🎉🎉Voila! That's how you can create your own custom tool and use it with the OpenAI Function Agent!\n\nAdditional\nPass Session ID to Function\n\nBy default, Function in custom tool has access to the following flow configurations:\n\nCopy\n$flow.sessionId \n\n$flow.chatId\n\n$flow.chatflowId\n\n$flow.input\n\nBelow is an example of sending the sessionId to Discord webhook:\n\nJavascript\nCopy\nconst fetch = require('node-fetch');\n\nconst webhookUrl = \"https://discord.com/api/webhooks/1124783587267\";\n\nconst content = $content; // captured from input schema\n\nconst sessionId = $flow.sessionId;\n\n\n\nconst body = {\n\n\t\"content\": `${mycontent} and the sessionid is ${sessionId}`\n\n};\n\n\n\nconst options = {\n\n\tmethod: 'POST',\n\n\theaders: {\n\n\t\t'Content-Type': 'application/json'\n\n\t},\n\n\tbody: JSON.stringify(body)\n\n};\n\n\n\nconst url = `${webhookUrl}?wait=true`\n\n\n\ntry {\n\n\tconst response = await fetch(url, options);\n\n\tconst text = await response.text();\n\n\treturn text;\n\n} catch (error) {\n\n\tconsole.error(error);\n\n\treturn '';\n\n}\nPass variables to Function\n\nIn some cases, you would like to pass variables to custom tool function.\n\nFor example, you are creating a chatbot that uses a custom tool. The custom tool is executing a HTTP POST call and API key is needed for successful authenticated request. You can pass it as a variable.\n\nBy default, Function in custom tool has access to variables:\n\nCopy\n$vars.<variable-name>\n\nExample of how to pass variables in Flowise using API and Embedded:\n\nJavascript API\nEmbed\nCopy\nasync function query(data) {\n\n    const response = await fetch(\n\n        \"http://localhost:3000/api/v1/prediction/<chatflow-id>\",\n\n        {\n\n            method: \"POST\",\n\n            headers: {\n\n                \"Content-Type\": \"application/json\"\n\n            },\n\n            body: JSON.stringify(data)\n\n        }\n\n    );\n\n    const result = await response.json();\n\n    return result;\n\n}\n\n\n\nquery({\n\n    \"question\": \"Hey, how are you?\",\n\n    \"overrideConfig\": {\n\n        \"vars\": {\n\n            \"apiKey\": \"abc\"\n\n        }\n\n    }\n\n}).then((response) => {\n\n    console.log(response);\n\n});\n\nExample of how to receive the variables in custom tool:\n\nJavascript\nCopy\nconst fetch = require('node-fetch');\n\nconst webhookUrl = \"https://discord.com/api/webhooks/1124783587267\";\n\nconst content = $content; // captured from input schema\n\nconst sessionId = $flow.sessionId;\n\nconst apiKey = $vars.apiKey;\n\n\n\nconst body = {\n\n\t\"content\": `${mycontent} and the sessionid is ${sessionId}`\n\n};\n\n\n\nconst options = {\n\n\tmethod: 'POST',\n\n\theaders: {\n\n\t\t'Content-Type': 'application/json',\n\n\t\t'Authorization': `Bearer ${apiKey}`\n\n\t},\n\n\tbody: JSON.stringify(body)\n\n};\n\n\n\nconst url = `${webhookUrl}?wait=true`\n\n\n\ntry {\n\n\tconst response = await fetch(url, options);\n\n\tconst text = await response.text();\n\n\treturn text;\n\n} catch (error) {\n\n\tconsole.error(error);\n\n\treturn '';\n\n}\nOverride Custom Tool\n\nParameters below can be overriden\n\nParameter\tDescription\n\n\ncustomToolName\n\n\t\n\ntool name\n\n\n\n\ncustomToolDesc\n\n\t\n\ntool description\n\n\n\n\ncustomToolSchema\n\n\t\n\ntool schema\n\n\n\n\ncustomToolFunc\n\n\t\n\ntool function\n\nExample of an API call to override custom tool parameters:\n\nJavascript API\nCopy\nasync function query(data) {\n\n    const response = await fetch(\n\n        \"http://localhost:3000/api/v1/prediction/<chatflow-id>\",\n\n        {\n\n            method: \"POST\",\n\n            headers: {\n\n                \"Content-Type\": \"application/json\"\n\n            },\n\n            body: JSON.stringify(data)\n\n        }\n\n    );\n\n    const result = await response.json();\n\n    return result;\n\n}\n\n\n\nquery({\n\n    \"question\": \"Hey, how are you?\",\n\n    \"overrideConfig\": {\n\n        \"customToolName\": \"example_tool\",\n\n        \"customToolSchema\": \"z.object({title: z.string()})\"\n\n    }\n\n}).then((response) => {\n\n    console.log(response);\n\n});\nImport External Dependencies\n\nYou can import any built-in NodeJS modules and supported external libraries into Function.\n\nTo import any non-supported libraries, you can easily add the new npm package to package.json in packages/components folder.\n\nCopy\ncd Flowise && cd packages && cd components\n\npnpm add <your-library>\n\ncd .. && cd ..\n\npnpm install\n\npnpm build\n\nThen, add the imported libraries to TOOL_FUNCTION_EXTERNAL_DEP environment variable. Refer #builtin-and-external-dependencies for more details.\n\nStart the app\n\nCopy\npnpm start\n\nYou can then use the newly added library in the JavaScript Function like so:\n\nCopy\nconst axios = require('axios')\n\nWatch how to add additional dependencies and import libraries\n\nPrevious\nChatflow Tool\nNext\nGoogle Custom Search\n\nLast updated 16 days ago\n\nProblem\nTutorial\nCreate Tools\nCreate Chatflow\nAdditional\nPass Session ID to Function\nPass variables to Function\nOverride Custom Tool\nImport External Dependencies\nEdit on GitHub"
  },
  {
    "title": "Elastic | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/vector-stores/elastic",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nAstraDB\nChroma\nElastic\nFaiss\nIn-Memory Vector Store\nMilvus\nMongoDB Atlas\nOpenSearch\nPinecone\nPostgres\nQdrant\nRedis\nSingleStore\nSupabase\nUpstash Vector\nVectara\nWeaviate\nZep Collection - Open Source\nZep Collection - Cloud\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nElastic\nPrerequisite\n\nYou can use the official Docker image to get started, or you can use Elastic Cloud, Elastic's official cloud service. In this guide, we will be using cloud version.\n\nRegister an account or login with existing account on Elastic cloud.\n\nClick Create deployment. Then, name your deployment, and choose the provider.\n\nAfter deployment is finished, you should be able to see the setup guides as shown below. Click the Set up vector search option.\n\nYou should now see the Getting started page for Vector Search.\n\nOn the left hand side bar, click Indices. Then, Create a new index.\n\nSelect API ingestion method\n\nName your search index name, then Create Index\n\nAfter the index has been created, generate a new API key, take note of both generated API key and the URL\n\nFlowise Setup\n\nAdd a new Elasticsearch node on canvas and fill in the Index Name\n\nAdd new credential via Elasticsearch API\n\nTake the URL and API Key from Elasticsearch, fill in the fields\n\nAfter credential has been created successfully, you can start upserting the data\n\nAfter data has been upserted successfully, you can verify it from Elastic dashboard:\n\nVoila! You can now start asking question in the chat\n\nResources\n\nLangChain JS Elastic\n\nVector Search (kNN) Implementation Guide - API Edition\n\nPrevious\nChroma\nNext\nFaiss\n\nLast updated 16 days ago\n\nPrerequisite\nFlowise Setup\nResources\nEdit on GitHub"
  },
  {
    "title": "Chroma | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/vector-stores/chroma",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nAstraDB\nChroma\nElastic\nFaiss\nIn-Memory Vector Store\nMilvus\nMongoDB Atlas\nOpenSearch\nPinecone\nPostgres\nQdrant\nRedis\nSingleStore\nSupabase\nUpstash Vector\nVectara\nWeaviate\nZep Collection - Open Source\nZep Collection - Cloud\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChroma\nPrerequisite\n\nDownload & Install Docker and Git\n\nClone Chroma's repository with your terminal\n\nCopy\ngit clone https://github.com/chroma-core/chroma.git\n\nChange directory path to your cloned Chroma\n\nCopy\ncd chroma\n\nRun docker compose to build up Chroma image and container\n\nCopy\ndocker-compose up -d --build\n\nIf success, you will be able to see the docker images spun up:\n\nSetup\nInput\tDescription\tDefault\n\n\nDocument\n\n\t\n\nCan be connected with nodes from Document Loader\n\n\t\n\n\n\n\nEmbeddings\n\n\t\n\nCan be connected with nodes from Embeddings\n\n\t\n\n\n\n\nCollection Name\n\n\t\n\nChroma collection name. Refer to here for naming convention\n\n\t\n\n\n\n\nChroma URL\n\n\t\n\nSpecify the URL of your chroma instance\n\n\t\n\nhttp://localhost:8000\n\nAdditional\n\nIf you are running both Flowise and Chroma on Docker, there are additional steps involved.\n\nSpin up Chroma docker first\n\nCopy\ndocker-compose up -d --build\n\nOpen docker-compose.yml in Flowise\n\nCopy\ncd Flowise && cd docker\n\nModify the file to:\n\nCopy\nversion: '3.1'\n\n\n\nservices:\n\n    flowise:\n\n        image: flowiseai/flowise\n\n        restart: always\n\n        environment:\n\n            - PORT=${PORT}\n\n            - FLOWISE_USERNAME=${FLOWISE_USERNAME}\n\n            - FLOWISE_PASSWORD=${FLOWISE_PASSWORD}\n\n            - DEBUG=${DEBUG}\n\n            - DATABASE_PATH=${DATABASE_PATH}\n\n            - APIKEY_PATH=${APIKEY_PATH}\n\n            - SECRETKEY_PATH=${SECRETKEY_PATH}\n\n            - FLOWISE_SECRETKEY_OVERWRITE=${FLOWISE_SECRETKEY_OVERWRITE}\n\n            - LOG_PATH=${LOG_PATH}\n\n            - LOG_LEVEL=${LOG_LEVEL}\n\n            - EXECUTION_MODE=${EXECUTION_MODE}\n\n        ports:\n\n            - '${PORT}:${PORT}'\n\n        volumes:\n\n            - ~/.flowise:/root/.flowise\n\n        networks:\n\n            - flowise_net\n\n        command: /bin/sh -c \"sleep 3; flowise start\"\n\nnetworks:\n\n    flowise_net:\n\n        name: chroma_net\n\n        external: true\n\nSpin up Flowise docker image\n\nCopy\ndocker-compose up -d\n\nOn the Chroma URL, for Windows and MacOS Operating Systems specify http://host.docker.internal:8000. For Linux based systems the default docker gateway should be used since host.docker.internal is not available: http://172.17.0.1:8000\n\nResources\n\nLangChain JS Chroma\n\nChroma Getting Started\n\nPrevious\nAstraDB\nNext\nElastic\n\nLast updated 16 days ago\n\nPrerequisite\nSetup\nAdditional\nResources\nEdit on GitHub"
  },
  {
    "title": "Faiss | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/vector-stores/faiss",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nAstraDB\nChroma\nElastic\nFaiss\nIn-Memory Vector Store\nMilvus\nMongoDB Atlas\nOpenSearch\nPinecone\nPostgres\nQdrant\nRedis\nSingleStore\nSupabase\nUpstash Vector\nVectara\nWeaviate\nZep Collection - Open Source\nZep Collection - Cloud\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nFaiss\n\nUpsert embedded data and perform similarity search upon query using Faiss library from Meta.\n\nFaiss Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nElastic\nNext\nIn-Memory Vector Store\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "AstraDB | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/vector-stores/astradb",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nAstraDB\nChroma\nElastic\nFaiss\nIn-Memory Vector Store\nMilvus\nMongoDB Atlas\nOpenSearch\nPinecone\nPostgres\nQdrant\nRedis\nSingleStore\nSupabase\nUpstash Vector\nVectara\nWeaviate\nZep Collection - Open Source\nZep Collection - Cloud\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAstraDB\nSetup\n\nRegister an account on AstraDB\n\nLogin to portal. Create a Database\n\nChoose Serverless (Vector), fill in the Database name, Provider, and Region\n\nAfter database has been setup, grab the API Endpoint, and generate Application Token\n\nCreate a new collection, select the desired dimenstion and similarity metric:\n\nBack to Flowise canvas, drag and drop Astra node. Click Create New from the Credentials dropdown:\n\nSpecify the API Endpoint and Application Token:\n\nYou can now upsert data to AstraDB\n\nNavigate back to Astra portal, and to your collection, you will be able to see all the data that has been upserted:\n\nStart querying!\n\nPrevious\nVector Stores\nNext\nChroma\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Vector Stores | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/vector-stores",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nAstraDB\nChroma\nElastic\nFaiss\nIn-Memory Vector Store\nMilvus\nMongoDB Atlas\nOpenSearch\nPinecone\nPostgres\nQdrant\nRedis\nSingleStore\nSupabase\nUpstash Vector\nVectara\nWeaviate\nZep Collection - Open Source\nZep Collection - Cloud\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nVector Stores\n\nA vector store or vector database refers to a type of database system that specializes in storing and retrieving high-dimensional numerical vectors. Vector stores are designed to efficiently manage and index these vectors, allowing for fast similarity searches.\n\nWatch an intro on Vector Stores and how you can use that on Flowise\nAvailable Vector Stores:\n\nAstraDB\n\nChroma\n\nElastic\n\nFaiss\n\nIn-Memory Vector Store\n\nMilvus\n\nMongoDB Atlas\n\nOpenSearch\n\nPinecone\n\nPostgres\n\nQdrant\n\nRedis\n\nSingleStore\n\nSupabase\n\nUpstash Vector\n\nVectara\n\nWeaviate\n\nZep Collection - Open Source\n\nZep Collection - Cloud\n\nPrevious\nWrite File\nNext\nAstraDB\n\nLast updated 9 days ago\n\nWatch an intro on Vector Stores and how you can use that on Flowise\nAvailable Vector Stores:\nEdit on GitHub"
  },
  {
    "title": "Write File | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/tools/write-file",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nBraveSearch API\nCalculator\nChain Tool\nChatflow Tool\nCustom Tool\nGoogle Custom Search\nOpenAPI Toolkit\nRead File\nRetriever Tool\nSearchApi\nSerp API\nSerper\nWeb Browser\nWrite File\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nWrite File\n\nWrite file to disk.\n\nWrite File Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nWeb Browser\nNext\nVector Stores\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "OpenAPI Toolkit | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/tools/openapi-toolkit",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nBraveSearch API\nCalculator\nChain Tool\nChatflow Tool\nCustom Tool\nGoogle Custom Search\nOpenAPI Toolkit\nRead File\nRetriever Tool\nSearchApi\nSerp API\nSerper\nWeb Browser\nWrite File\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nOpenAPI Toolkit\n\nLoad OpenAPI specification.\n\nOpenAPI Toolkit Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nGoogle Custom Search\nNext\nRead File\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Web Browser | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/tools/web-browser",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nBraveSearch API\nCalculator\nChain Tool\nChatflow Tool\nCustom Tool\nGoogle Custom Search\nOpenAPI Toolkit\nRead File\nRetriever Tool\nSearchApi\nSerp API\nSerper\nWeb Browser\nWrite File\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nWeb Browser\n\nGives agent the ability to visit a website and extract information.\n\nWeb Browser Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nSerper\nNext\nWrite File\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Serper | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/tools/serper",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nBraveSearch API\nCalculator\nChain Tool\nChatflow Tool\nCustom Tool\nGoogle Custom Search\nOpenAPI Toolkit\nRead File\nRetriever Tool\nSearchApi\nSerp API\nSerper\nWeb Browser\nWrite File\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nSerper\n\nWrapper around Serper.dev - Google Search API.\n\nSerper Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nSerp API\nNext\nWeb Browser\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "SearchApi | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/tools/searchapi",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nBraveSearch API\nCalculator\nChain Tool\nChatflow Tool\nCustom Tool\nGoogle Custom Search\nOpenAPI Toolkit\nRead File\nRetriever Tool\nSearchApi\nSerp API\nSerper\nWeb Browser\nWrite File\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nSearchApi\n\nReal-time API for accessing Google Search data.\n\nSearchApi Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nRetriever Tool\nNext\nSerp API\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Serp API | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/tools/serp-api",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nBraveSearch API\nCalculator\nChain Tool\nChatflow Tool\nCustom Tool\nGoogle Custom Search\nOpenAPI Toolkit\nRead File\nRetriever Tool\nSearchApi\nSerp API\nSerper\nWeb Browser\nWrite File\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nSerp API\n\nWrapper around SerpAPI - a real-time API to access Google search results.\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nSearchApi\nNext\nSerper\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Chatflow Tool | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/tools/chatflow-tool",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nBraveSearch API\nCalculator\nChain Tool\nChatflow Tool\nCustom Tool\nGoogle Custom Search\nOpenAPI Toolkit\nRead File\nRetriever Tool\nSearchApi\nSerp API\nSerper\nWeb Browser\nWrite File\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChatflow Tool\n\nExecute another chatflow and get the response.\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nChain Tool\nNext\nCustom Tool\n\nLast updated 14 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Chain Tool | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/tools/chain-tool",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nBraveSearch API\nCalculator\nChain Tool\nChatflow Tool\nCustom Tool\nGoogle Custom Search\nOpenAPI Toolkit\nRead File\nRetriever Tool\nSearchApi\nSerp API\nSerper\nWeb Browser\nWrite File\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChain Tool\n\nUse a chain as allowed tool for agent.\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nCalculator\nNext\nChatflow Tool\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Retriever Tool | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/tools/retriever-tool",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nBraveSearch API\nCalculator\nChain Tool\nChatflow Tool\nCustom Tool\nGoogle Custom Search\nOpenAPI Toolkit\nRead File\nRetriever Tool\nSearchApi\nSerp API\nSerper\nWeb Browser\nWrite File\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nRetriever Tool\n\nUse a retriever as allowed tool for agent.\n\nRetriever Tool Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nRead File\nNext\nSearchApi\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Read File | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/tools/read-file",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nBraveSearch API\nCalculator\nChain Tool\nChatflow Tool\nCustom Tool\nGoogle Custom Search\nOpenAPI Toolkit\nRead File\nRetriever Tool\nSearchApi\nSerp API\nSerper\nWeb Browser\nWrite File\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nRead File\n\nRead file from disk.\n\nRead File Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nOpenAPI Toolkit\nNext\nRetriever Tool\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Google Custom Search | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/tools/google-custom-search",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nBraveSearch API\nCalculator\nChain Tool\nChatflow Tool\nCustom Tool\nGoogle Custom Search\nOpenAPI Toolkit\nRead File\nRetriever Tool\nSearchApi\nSerp API\nSerper\nWeb Browser\nWrite File\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nGoogle Custom Search\n\nWrapper around Google Custom Search API - a real-time API to access Google search results.\n\nGoogle Custom Search Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nCustom Tool\nNext\nOpenAPI Toolkit\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Calculator | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/tools/calculator",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nBraveSearch API\nCalculator\nChain Tool\nChatflow Tool\nCustom Tool\nGoogle Custom Search\nOpenAPI Toolkit\nRead File\nRetriever Tool\nSearchApi\nSerp API\nSerper\nWeb Browser\nWrite File\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nCalculator\n\nPerform calculations on response.\n\nCalculator Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nBraveSearch API\nNext\nChain Tool\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Tools | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/tools",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nBraveSearch API\nCalculator\nChain Tool\nChatflow Tool\nCustom Tool\nGoogle Custom Search\nOpenAPI Toolkit\nRead File\nRetriever Tool\nSearchApi\nSerp API\nSerper\nWeb Browser\nWrite File\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nTools\n\nTools are functions that agents can use to interact with the world. These tools can be generic utilities (e.g. search), other chains, or even other agents.\n\nAvailable Tools:\n\nBraveSearch API\n\nCalculator\n\nChain Tool\n\nChatflow Tool\n\nCustom Tool\n\nGoogle Custom Search\n\nOpenAPI Toolkit\n\nRead File\n\nRetriever Tool\n\nSearchApi\n\nSerp API\n\nSerper\n\nWeb Browser\n\nWrite File\n\nPrevious\nToken Text Splitter\nNext\nBraveSearch API\n\nLast updated 9 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Token Text Splitter | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/text-splitters/token-text-splitter",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nCharacter Text Splitter\nCode Text Splitter\nHtml-To-Markdown Text Splitter\nMarkdown Text Splitter\nRecursive Character Text Splitter\nToken Text Splitter\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nToken Text Splitter\n\nSplits a raw text string by first converting the text into BPE tokens, then split these tokens into chunks and convert the tokens within a single chunk back into text.\n\nToken Text Splitter Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nRecursive Character Text Splitter\nNext\nTools\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "BraveSearch API | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/tools/bravesearch-api",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nBraveSearch API\nCalculator\nChain Tool\nChatflow Tool\nCustom Tool\nGoogle Custom Search\nOpenAPI Toolkit\nRead File\nRetriever Tool\nSearchApi\nSerp API\nSerper\nWeb Browser\nWrite File\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nBraveSearch API\n\nWrapper around BraveSearch API - a real-time API to access Brave search results.\n\nBraveSearch API Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nTools\nNext\nCalculator\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Recursive Character Text Splitter | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/text-splitters/recursive-character-text-splitter",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nCharacter Text Splitter\nCode Text Splitter\nHtml-To-Markdown Text Splitter\nMarkdown Text Splitter\nRecursive Character Text Splitter\nToken Text Splitter\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nRecursive Character Text Splitter\n\nSplit documents recursively by different characters - starting with \"\\n\\n\", then \"\\n\", then \" \".\n\nRecursive Character Text Splitter Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nMarkdown Text Splitter\nNext\nToken Text Splitter\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Vector Store Retriever | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/retrievers/vector-store-retriever",
    "html": "An error occurred\n\nSorry, an unexpected error has occurred. Please try again later.\n\nRetry"
  },
  {
    "title": "Markdown Text Splitter | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/text-splitters/markdown-text-splitter",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nCharacter Text Splitter\nCode Text Splitter\nHtml-To-Markdown Text Splitter\nMarkdown Text Splitter\nRecursive Character Text Splitter\nToken Text Splitter\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nMarkdown Text Splitter\n\nSplit your content into documents based on the Markdown headers.\n\nMarkdown Text Splitter Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nHtml-To-Markdown Text Splitter\nNext\nRecursive Character Text Splitter\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Html-To-Markdown Text Splitter | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/text-splitters/html-to-markdown-text-splitter",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nCharacter Text Splitter\nCode Text Splitter\nHtml-To-Markdown Text Splitter\nMarkdown Text Splitter\nRecursive Character Text Splitter\nToken Text Splitter\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nHtml-To-Markdown Text Splitter\n\nConverts Html to Markdown and then split your content into documents based on the Markdown headers.\n\nHtml-To-Markdown Text Splitter Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nCode Text Splitter\nNext\nMarkdown Text Splitter\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Voyage AI Rerank Retriever | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/retrievers/page",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nCohere Rerank Retriever\nEmbeddings Filter Retriever\nHyDE Retriever\nLLM Filter Retriever\nPrompt Retriever\nReciprocal Rank Fusion Retriever\nSimilarity Score Threshold Retriever\nVector Store Retriever\nVoyage AI Rerank Retriever\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nVoyage AI Rerank Retriever\n\nVoyage AI Rerank indexes the documents from most to least semantically relevant to the query.\n\nVoyage AI Rerank Retriever Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nVector Store Retriever\nNext\nText Splitters\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Code Text Splitter | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/text-splitters/code-text-splitter",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nCharacter Text Splitter\nCode Text Splitter\nHtml-To-Markdown Text Splitter\nMarkdown Text Splitter\nRecursive Character Text Splitter\nToken Text Splitter\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nCode Text Splitter\n\nSplit documents based on language-specific syntax.\n\nCode Text Splitter Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nCharacter Text Splitter\nNext\nHtml-To-Markdown Text Splitter\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Similarity Score Threshold Retriever | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/retrievers/similarity-score-threshold-retriever",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nCohere Rerank Retriever\nEmbeddings Filter Retriever\nHyDE Retriever\nLLM Filter Retriever\nPrompt Retriever\nReciprocal Rank Fusion Retriever\nSimilarity Score Threshold Retriever\nVector Store Retriever\nVoyage AI Rerank Retriever\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nSimilarity Score Threshold Retriever\n\nReturn results based on the minimum similarity percentage.\n\nSimilarity Score Threshold Retriever Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nReciprocal Rank Fusion Retriever\nNext\nVector Store Retriever\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Character Text Splitter | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/text-splitters/character-text-splitter",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nCharacter Text Splitter\nCode Text Splitter\nHtml-To-Markdown Text Splitter\nMarkdown Text Splitter\nRecursive Character Text Splitter\nToken Text Splitter\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nCharacter Text Splitter\n\nSplits only on one type of character (defaults to \"\\n\\n\").\n\nCharacter Text Splitter\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nText Splitters\nNext\nCode Text Splitter\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Text Splitters | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/text-splitters",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nCharacter Text Splitter\nCode Text Splitter\nHtml-To-Markdown Text Splitter\nMarkdown Text Splitter\nRecursive Character Text Splitter\nToken Text Splitter\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nText Splitters\n\nWhen you want to deal with long pieces of text, it is necessary to split up that text into chunks.\nAs simple as this sounds, there is a lot of potential complexity here. Ideally, you want to keep the semantically related pieces of text together. What \"semantically related\" means could depend on the type of text. This notebook showcases several ways to do that.\n\nAt a high level, text splitters work as following:\n\nSplit the text up into small, semantically meaningful chunks (often sentences).\n\nStart combining these small chunks into a larger chunk until you reach a certain size (as measured by some function).\n\nOnce you reach that size, make that chunk its own piece of text and then start creating a new chunk of text with some overlap (to keep context between chunks).\n\nThat means there are two different axes along which you can customize your text splitter:\n\nHow the text is split\n\nHow the chunk size is measured\n\nAvailable Text Splitters:\n\nCharacter Text Splitter\n\nCode Text Splitter\n\nHtml-To-Markdown Text Splitter\n\nMarkdown Text Splitter\n\nRecursive Character Text Splitter\n\nToken Text Splitter\n\nPrevious\nVoyage AI Rerank Retriever\nNext\nCharacter Text Splitter\n\nLast updated 9 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Reciprocal Rank Fusion Retriever | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/retrievers/reciprocal-rank-fusion-retriever",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nCohere Rerank Retriever\nEmbeddings Filter Retriever\nHyDE Retriever\nLLM Filter Retriever\nPrompt Retriever\nReciprocal Rank Fusion Retriever\nSimilarity Score Threshold Retriever\nVector Store Retriever\nVoyage AI Rerank Retriever\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nReciprocal Rank Fusion Retriever\n\nReciprocal Rank Fusion to re-rank search results by multiple query generation.\n\nReciprocal Rank Fusion Retriever Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nPrompt Retriever\nNext\nSimilarity Score Threshold Retriever\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Prompt Retriever | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/retrievers/prompt-retriever",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nCohere Rerank Retriever\nEmbeddings Filter Retriever\nHyDE Retriever\nLLM Filter Retriever\nPrompt Retriever\nReciprocal Rank Fusion Retriever\nSimilarity Score Threshold Retriever\nVector Store Retriever\nVoyage AI Rerank Retriever\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nPrompt Retriever\n\nStore prompt template with name & description to be later queried by MultiPromptChain.\n\nPrompt Retriever Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nLLM Filter Retriever\nNext\nReciprocal Rank Fusion Retriever\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Embeddings Filter Retriever | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/retrievers/embeddings-filter-retriever",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nCohere Rerank Retriever\nEmbeddings Filter Retriever\nHyDE Retriever\nLLM Filter Retriever\nPrompt Retriever\nReciprocal Rank Fusion Retriever\nSimilarity Score Threshold Retriever\nVector Store Retriever\nVoyage AI Rerank Retriever\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nEmbeddings Filter Retriever\n\nA document compressor that uses embeddings to drop documents unrelated to the query.\n\nEmbeddings Filter Retriever Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nCohere Rerank Retriever\nNext\nHyDE Retriever\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Record Managers | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/record-managers",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nRecord Managers\n\nRecord Managers keep track of your indexed documents, preventing duplicated vector embeddings in Vector Store.\n\nWhen document chunks are upserting, each chunk will be hashed using SHA-1 algorithm. These hashes will get stored in Record Manager. If there is an existing hash, the embedding and upserting process will be skipped.\n\nIn some cases, you might want to delete existing documents that are derived from the same sources as the new documents being indexed. For that, there are 3 cleanup modes for Record Manager:\n\nIncremental\nFull\nNone\n\nWhen you are upserting multiple documents, and you want to prevent deletion of the existing documents that are not part of the current upserting process, use Incremental Cleanup mode.\n\nLet's have a Record Manager with Incremental Cleanup and source as SourceId Key\n\nAnd have the following 2 documents:\n\nText\tMetadata\n\n\nCat\n\n\t\n\n{source:\"cat\"}\n\n\n\n\nDog\n\n\t\n\n{source:\"dog\"}\n\nAfter an upsert, we will see 2 documents that are upserted:\n\nNow, if we delete the Dog document, and update Cat to Cats, we will now see the following:\n\nThe original Cat document is deleted\n\nA new document with Cats is added\n\nDog document is left untouched\n\nThe remaining vector embeddings in Vector Store are Cats and Dog\n\nCurrent available Record Managers are:\n\nSQLite\n\nMySQL\n\nPostgresQL\n\nResources\n\nLangchain Indexing\n\nPrevious\nPrompt Template\nNext\nRetrievers\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "LLM Filter Retriever | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/retrievers/llm-filter-retriever",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nCohere Rerank Retriever\nEmbeddings Filter Retriever\nHyDE Retriever\nLLM Filter Retriever\nPrompt Retriever\nReciprocal Rank Fusion Retriever\nSimilarity Score Threshold Retriever\nVector Store Retriever\nVoyage AI Rerank Retriever\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nLLM Filter Retriever\n\nIterate over the initially returned documents and extract, from each, only the content that is relevant to the query.\n\nLLM Filter Retriever Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nHyDE Retriever\nNext\nPrompt Retriever\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "HyDE Retriever | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/retrievers/hyde-retriever",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nCohere Rerank Retriever\nEmbeddings Filter Retriever\nHyDE Retriever\nLLM Filter Retriever\nPrompt Retriever\nReciprocal Rank Fusion Retriever\nSimilarity Score Threshold Retriever\nVector Store Retriever\nVoyage AI Rerank Retriever\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nHyDE Retriever\n\nUse HyDE retriever to retrieve from a vector store.\n\nHyDE Retriever Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nEmbeddings Filter Retriever\nNext\nLLM Filter Retriever\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Cohere Rerank Retriever | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/retrievers/cohere-rerank-retriever",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nCohere Rerank Retriever\nEmbeddings Filter Retriever\nHyDE Retriever\nLLM Filter Retriever\nPrompt Retriever\nReciprocal Rank Fusion Retriever\nSimilarity Score Threshold Retriever\nVector Store Retriever\nVoyage AI Rerank Retriever\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nCohere Rerank Retriever\n\nCohere Rerank indexes the documents from most to least semantically relevant to the query.\n\nCohere Rerank Retriever Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nRetrievers\nNext\nEmbeddings Filter Retriever\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Few Shot Prompt Template | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/prompts/few-shot-prompt-template",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nChat Prompt Template\nFew Shot Prompt Template\nPrompt Template\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nFew Shot Prompt Template\n\nPrompt template you can build with examples.\n\nFew Shot Prompt Template Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nChat Prompt Template\nNext\nPrompt Template\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Prompt Template | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/prompts/prompt-template",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nChat Prompt Template\nFew Shot Prompt Template\nPrompt Template\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nPrompt Template\n\nSchema to represent a basic prompt for an LLM.\n\nPrompt Template Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nFew Shot Prompt Template\nNext\nRecord Managers\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Retrievers | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/retrievers",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nCohere Rerank Retriever\nEmbeddings Filter Retriever\nHyDE Retriever\nLLM Filter Retriever\nPrompt Retriever\nReciprocal Rank Fusion Retriever\nSimilarity Score Threshold Retriever\nVector Store Retriever\nVoyage AI Rerank Retriever\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nRetrievers\n\nRetriever nodes return documents given an unstructured query. It is more general than a vector store. A retriever does not need to be able to store documents, only to return (or retrieve) them.\n\nAvailable Retrievers:\n\nCohere Rerank Retriever\n\nEmbeddings Filter Retriever\n\nHyDE Retriever\n\nLLM Filter Retriever\n\nPrompt Retriever\n\nReciprocal Rank Fusion Retriever\n\nSimilarity Score Threshold Retriever\n\nVector Store Retriever\n\nVoyage AI Rerank Retriever\n\nPrevious\nRecord Managers\nNext\nCohere Rerank Retriever\n\nLast updated 9 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Chat Prompt Template | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/prompts/chat-prompt-template",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nChat Prompt Template\nFew Shot Prompt Template\nPrompt Template\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChat Prompt Template\n\nSchema to represent a chat prompt.\n\nChat Prompt Template Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nPrompts\nNext\nFew Shot Prompt Template\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Advanced Structured Output Parser | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/output-parsers/advanced-structured-output-parser",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nCSV Output Parser\nCustom List Output Parser\nStructured Output Parser\nAdvanced Structured Output Parser\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAdvanced Structured Output Parser\n\nParse the output of an LLM call into a given structure by providing a Zod schema.\n\nAdvanced Structured Output Parser Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nStructured Output Parser\nNext\nPrompts\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Structured Output Parser | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/output-parsers/structured-output-parser",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nCSV Output Parser\nCustom List Output Parser\nStructured Output Parser\nAdvanced Structured Output Parser\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nStructured Output Parser\n\nParse the output of an LLM call into a given (JSON) structure.\n\nStructured Output Parser Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nCustom List Output Parser\nNext\nAdvanced Structured Output Parser\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Prompts | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/prompts",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nChat Prompt Template\nFew Shot Prompt Template\nPrompt Template\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nPrompts\n\nPrompt template nodes help to translate user input and parameters into instructions for a language model. This can be used to guide a model's response, helping it understand the context and generate relevant and coherent language-based output.\n\nAvailable Prompts:\n\nChat Prompt Template\n\nFew Shot Prompt Template\n\nPrompt Template\n\nPrevious\nAdvanced Structured Output Parser\nNext\nChat Prompt Template\n\nLast updated 9 days ago\n\nEdit on GitHub"
  },
  {
    "title": "CSV Output Parser | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/output-parsers/csv-output-parser",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nCSV Output Parser\nCustom List Output Parser\nStructured Output Parser\nAdvanced Structured Output Parser\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nCSV Output Parser\n\nParse the output of an LLM call as a comma-separated list of values.\n\nCSV Output Parser Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nOutput Parsers\nNext\nCustom List Output Parser\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Custom List Output Parser | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/output-parsers/custom-list-output-parser",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nCSV Output Parser\nCustom List Output Parser\nStructured Output Parser\nAdvanced Structured Output Parser\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nCustom List Output Parser\n\nParse the output of an LLM call as a list of values.\n\nCustom List Output Parser Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nCSV Output Parser\nNext\nStructured Output Parser\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Output Parsers | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/output-parsers",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nCSV Output Parser\nCustom List Output Parser\nStructured Output Parser\nAdvanced Structured Output Parser\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nOutput Parsers\n\nOutput Parser nodes are responsible for taking the output of a model and transforming it to a more suitable format for downstream tasks. Useful when you are using LLMs to generate structured data, or to normalize output from chat models and LLMs.\n\nAvailable Output Parsers:\n\nCSV Output Parser\n\nCustom List Output Parser\n\nStructured Output Parser\n\nAdvanced Structured Output Parser\n\nPrevious\nSimple Prompt Moderation\nNext\nCSV Output Parser\n\nLast updated 9 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Zep Memory | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/memory/zep-memory",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nBuffer Memory\nBuffer Window Memory\nConversation Summary Memory\nConversation Summary Buffer Memory\nDynamoDB Chat Memory\nMongoDB Atlas Chat Memory\nRedis-Backed Chat Memory\nUpstash Redis-Backed Chat Memory\nZep Memory\nThreads\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nZep Memory\n\nZep is long-term memory store for LLM applications. It stores, summarizes, embeds, indexes, and enriches LLM app / chatbot histories, and exposes them via simple, low-latency APIs.\n\nGuide to Deploy Zep to Render\n\nYou can easily deploy Zep to cloud services like Render, Flyio. If you prefer to test it locally, you can also spin up a docker container by following their quick guide.\n\nIn this example, we are going to deploy to Render.\n\nHead over to Zep Repo and click Deploy to Render\n\nThis will bring you to Render's Blueprint page and simply click Create New Resources\n\nWhen the deployment is done, you should see 3 applications created on your dashboard\n\nSimply click the first one called zep and copy the deployed URL\n\nGuide to Deploy Zep to Digital Ocean (via Docker)\n\nClone the Repo\n\nCopy\ngit clone https://github.com/getzep/zep.git\n\ncd zep\n\nnano .env\n\n\nAdd IN your OpenAI API Key in.ENV\n\nCopy\nZEP_OPENAI_API_KEY=\n\nCopy\ndocker-compose up -d --build\n\nAllow firewall access to port 8000\n\nCopy\nsudo ufw allow from any to any port 8000 proto tcp\n\nufw status numbered\n\nIf using Digital ocean separate firewall from dashboard, make sure port 8000 is added there too\n\nUse in Flowise UI\n\nBack to Flowise application, simply create a new canvas or use one of the template from marketplace. In this example, we are going to use Simple Conversational Chain\n\nReplace Buffer Memory with Zep Memory. Then replace the Base URL with the Zep URL you have copied above\n\nSave the chatflow and test it out to see if conversations are remembered.\n\nNow try clearing the chat history, you should see that it is now unable to remember the previous conversations.\n\nZep Authentication\n\nZep allows you to secure your instance using JWT authentication. We'll be using the zepcli command line utility here.\n\n1. Generate a secret and the JWT token\n\nAfter downloaded the ZepCLI:\n\nOn Linux or MacOS\n\nCopy\n./zepcli -i\n\nOn Windows\n\nCopy\nzepcli.exe -i\n\nYou will first get your SECRET Token:\n\nThen you will get JWT Token:\n\n2. Configure Auth environment variables\n\nSet the following environment variables in your Zep server environment:\n\nCopy\nZEP_AUTH_REQUIRED=true\n\nZEP_AUTH_SECRET=<the secret you generated above>\n3. Configure Credential on Flowise\n\nAdd a new credential for Zep, and put in the JWT Token in the API Key field:\n\n4. Use the created credential on Zep node\n\nIn the Zep node Connect Credential, select the credential you have just created. And that's it!\n\nPrevious\nUpstash Redis-Backed Chat Memory\nNext\nThreads\n\nLast updated 16 days ago\n\nGuide to Deploy Zep to Render\nGuide to Deploy Zep to Digital Ocean (via Docker)\nUse in Flowise UI\nZep Authentication\nEdit on GitHub"
  },
  {
    "title": "Simple Prompt Moderation | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/moderation/simple-prompt-moderation",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOpenAI Moderation\nSimple Prompt Moderation\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nSimple Prompt Moderation\n\nCheck whether input consists of any text from Deny list, and prevent being sent to LLM.\n\nSimple Prompt Moderation Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nOpenAI Moderation\nNext\nOutput Parsers\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Upstash Redis-Backed Chat Memory | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/memory/upstash-redis-backed-chat-memory",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nBuffer Memory\nBuffer Window Memory\nConversation Summary Memory\nConversation Summary Buffer Memory\nDynamoDB Chat Memory\nMongoDB Atlas Chat Memory\nRedis-Backed Chat Memory\nUpstash Redis-Backed Chat Memory\nZep Memory\nThreads\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nUpstash Redis-Backed Chat Memory\n\nSummarizes the conversation and stores the memory in Upstash Redis server.\n\nUpstash Redis-Backed Chat Memory Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nRedis-Backed Chat Memory\nNext\nZep Memory\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Threads | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/memory/threads",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nBuffer Memory\nBuffer Window Memory\nConversation Summary Memory\nConversation Summary Buffer Memory\nDynamoDB Chat Memory\nMongoDB Atlas Chat Memory\nRedis-Backed Chat Memory\nUpstash Redis-Backed Chat Memory\nZep Memory\nThreads\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nThreads\n\nThreads is only used when an OpenAI Assistant is being used. It is a conversation session between an Assistant and a user. Threads store messages and automatically handle truncation to fit content into a model’s context.\n\nSeparate conversations for multiple users\nUI & Embedded Chat\n\nBy default, UI and Embedded Chat will automatically separate threads for multiple users conversations. This is done by generating a unique \nchatId\n for each new interaction. That logic is handled under the hood by Flowise.\n\nPrediction API\n\nPOST /api/v1/prediction/{your-chatflowid}, specify the \nchatId\n . Same thread will be used for the same chatId.\n\nCopy\n{\n\n    \"question\": \"hello!\",\n\n    \"chatId\": \"user1\"\n\n}\nMessage API\n\nGET /api/v1/chatmessage/{your-chatflowid}\n\nDELETE /api/v1/chatmessage/{your-chatflowid}\n\nYou can also filter via \nchatId\n - /api/v1/chatmessage/{your-chatflowid}?chatId={your-chatid}\n\nAll conversations can be visualized and managed from UI as well:\n\nPrevious\nZep Memory\nNext\nModeration\n\nLast updated 1 month ago\n\nSeparate conversations for multiple users\nUI & Embedded Chat\nPrediction API\nMessage API\nEdit on GitHub"
  },
  {
    "title": "OpenAI Moderation | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/moderation/openai-moderation",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOpenAI Moderation\nSimple Prompt Moderation\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nOpenAI Moderation\n\nCheck whether content complies with OpenAI usage policies.\n\nOpenAI Moderation Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nModeration\nNext\nSimple Prompt Moderation\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Moderation | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/moderation",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOpenAI Moderation\nSimple Prompt Moderation\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nModeration\n\nModeration nodes are used to check whether the input or output consists of harmful or inappropriate content.\n\nAvailable Moderators:\n\nOpenAI Moderation\n\nSimple Prompt Moderation\n\nPrevious\nThreads\nNext\nOpenAI Moderation\n\nLast updated 9 days ago\n\nEdit on GitHub"
  },
  {
    "title": "DynamoDB Chat Memory | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/memory/dynamodb-chat-memory",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nBuffer Memory\nBuffer Window Memory\nConversation Summary Memory\nConversation Summary Buffer Memory\nDynamoDB Chat Memory\nMongoDB Atlas Chat Memory\nRedis-Backed Chat Memory\nUpstash Redis-Backed Chat Memory\nZep Memory\nThreads\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nDynamoDB Chat Memory\n\nStores the conversation in dynamo db table.\n\nDynamoDB Chat Memory Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nConversation Summary Buffer Memory\nNext\nMongoDB Atlas Chat Memory\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "MongoDB Atlas Chat Memory | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/memory/mongodb-atlas-chat-memory",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nBuffer Memory\nBuffer Window Memory\nConversation Summary Memory\nConversation Summary Buffer Memory\nDynamoDB Chat Memory\nMongoDB Atlas Chat Memory\nRedis-Backed Chat Memory\nUpstash Redis-Backed Chat Memory\nZep Memory\nThreads\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nMongoDB Atlas Chat Memory\n\nStores the conversation in MongoDB Atlas.\n\nMongoDB Atlas Chat Memory Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nDynamoDB Chat Memory\nNext\nRedis-Backed Chat Memory\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Conversation Summary Buffer Memory | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/memory/conversation-summary-buffer-memory",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nBuffer Memory\nBuffer Window Memory\nConversation Summary Memory\nConversation Summary Buffer Memory\nDynamoDB Chat Memory\nMongoDB Atlas Chat Memory\nRedis-Backed Chat Memory\nUpstash Redis-Backed Chat Memory\nZep Memory\nThreads\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nConversation Summary Buffer Memory\n\nUse Flowise database table chat_message as the storage mechanism for storing/retrieving conversations.\n\nThis memory keeps a buffer of recent interactions and compiles old ones into a summary, using both in its storage. Instead of flushing old interactions based solely on their number, it now considers the total length of tokens to decide when to clear them out.\n\nInput\nParameter\tDescription\tDefault\n\n\nChat Model\n\n\t\n\nLLM used to perform summarization\n\n\t\n\n\n\n\nMax Token Limit\n\n\t\n\nSummarize conversations once token limit is reached\n\n\t\n\n2000\n\n\n\n\nSession Id\n\n\t\n\nAn ID to retrieve/store messages. If not specified, a random ID will be used.\n\n\t\n\n\n\n\nMemory Key\n\n\t\n\nA key used to format messages in prompt template\n\n\t\n\nchat_history\n\nPrevious\nConversation Summary Memory\nNext\nDynamoDB Chat Memory\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Redis-Backed Chat Memory | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/memory/redis-backed-chat-memory",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nBuffer Memory\nBuffer Window Memory\nConversation Summary Memory\nConversation Summary Buffer Memory\nDynamoDB Chat Memory\nMongoDB Atlas Chat Memory\nRedis-Backed Chat Memory\nUpstash Redis-Backed Chat Memory\nZep Memory\nThreads\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nRedis-Backed Chat Memory\n\nSummarizes the conversation and stores the memory in Redis server.\n\nRedis-Backed Chat Memory Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nMongoDB Atlas Chat Memory\nNext\nUpstash Redis-Backed Chat Memory\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Conversation Summary Memory | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/memory/conversation-summary-memory",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nBuffer Memory\nBuffer Window Memory\nConversation Summary Memory\nConversation Summary Buffer Memory\nDynamoDB Chat Memory\nMongoDB Atlas Chat Memory\nRedis-Backed Chat Memory\nUpstash Redis-Backed Chat Memory\nZep Memory\nThreads\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nConversation Summary Memory\n\nUse Flowise database table chat_message as the storage mechanism for storing/retrieving conversations.\n\nThis memory type creates a brief summary of the conversation over time. This is useful for shortening information from long discussions. It updates and saves a current summary as the conversation goes on. This is especially helpful in longer chats, where saving every past message would take up too much space.\n\nInput\nParameter\tDescription\tDefault\n\n\nChat Model\n\n\t\n\nLLM used to perform summarization\n\n\t\n\n\n\n\nSession Id\n\n\t\n\nAn ID to retrieve/store messages. If not specified, a random ID will be used.\n\n\t\n\n\n\n\nMemory Key\n\n\t\n\nA key used to format messages in prompt template\n\n\t\n\nchat_history\n\nPrevious\nBuffer Window Memory\nNext\nConversation Summary Buffer Memory\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Buffer Window Memory | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/memory/buffer-window-memory",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nBuffer Memory\nBuffer Window Memory\nConversation Summary Memory\nConversation Summary Buffer Memory\nDynamoDB Chat Memory\nMongoDB Atlas Chat Memory\nRedis-Backed Chat Memory\nUpstash Redis-Backed Chat Memory\nZep Memory\nThreads\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nBuffer Window Memory\n\nUse Flowise database table chat_message as the storage mechanism for storing/retrieving conversations.\n\nDifference being it only fetches the last K interactions. This approach is beneficial for preserving a sliding window of the most recent interactions, ensuring the buffer remains manageable in size.\n\nInput\nParameter\tDescription\tDefault\n\n\nSize\n\n\t\n\nLast K messages to fetch\n\n\t\n\n4\n\n\n\n\nSession Id\n\n\t\n\nAn ID to retrieve/store messages. If not specified, a random ID will be used.\n\n\t\n\n\n\n\nMemory Key\n\n\t\n\nA key used to format messages in prompt template\n\n\t\n\nchat_history\n\nPrevious\nBuffer Memory\nNext\nConversation Summary Memory\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "OpenAI | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/llms/openai",
    "html": "An error occurred\n\nSorry, an unexpected error has occurred. Please try again later.\n\nRetry"
  },
  {
    "title": "Ollama | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/llms/ollama",
    "html": "An error occurred\n\nSorry, an unexpected error has occurred. Please try again later.\n\nRetry"
  },
  {
    "title": "Buffer Memory | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/memory/buffer-memory",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nBuffer Memory\nBuffer Window Memory\nConversation Summary Memory\nConversation Summary Buffer Memory\nDynamoDB Chat Memory\nMongoDB Atlas Chat Memory\nRedis-Backed Chat Memory\nUpstash Redis-Backed Chat Memory\nZep Memory\nThreads\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nBuffer Memory\n\nUse Flowise database table chat_message as the storage mechanism for storing/retrieving conversations.\n\nInput\nParameter\tDescription\tDefault\n\n\nSession Id\n\n\t\n\nAn ID to retrieve/store messages. If not specified, a random ID will be used.\n\n\t\n\n\n\n\nMemory Key\n\n\t\n\nA key used to format messages in prompt template\n\n\t\n\nchat_history\n\nPrevious\nMemory\nNext\nBuffer Window Memory\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Memory | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/memory",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nBuffer Memory\nBuffer Window Memory\nConversation Summary Memory\nConversation Summary Buffer Memory\nDynamoDB Chat Memory\nMongoDB Atlas Chat Memory\nRedis-Backed Chat Memory\nUpstash Redis-Backed Chat Memory\nZep Memory\nThreads\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nMemory\n\nMemory allow you to chat with AI as if AI has the memory of previous conversations.\n\nHuman: hi i am bob\n\nAI: Hello Bob! It's nice to meet you. How can I assist you today?\n\nHuman: what's my name?\n\nAI: Your name is Bob, as you mentioned earlier.\n\nUnder the hood, these conversations are stored in arrays or databases, and provided as context to LLM. For example:\n\nCopy\nYou are an assistant to a human, powered by a large language model trained by OpenAI.\n\n\n\nWhether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n\n\n\nCurrent conversation:\n\n{history}\nAvailable Memories:\n\nBuffer Memory\n\nBuffer Window Memory\n\nConversation Summary Memory\n\nConversation Summary Buffer Memory\n\nDynamoDB Chat Memory\n\nMongoDB Atlas Chat Memory\n\nRedis-Backed Chat Memory\n\nUpstash Redis-Backed Chat Memory\n\nZep Memory\n\nThreads\n\nSeparate conversations for multiple users\nUI & Embedded Chat\n\nBy default, UI and Embedded Chat will automatically separate different users conversations. This is done by generating a unique \nchatId\n for each new interaction. That logic is handled under the hood by Flowise.\n\nPrediction API\n\nYou can separate the conversations for multiple users by specifying a unique \nsessionId\n\nFor every memory node, you should be able to see a input parameter \nSession ID\n\nIn the /api/v1/prediction/{your-chatflowid} POST body request, specify the \nsessionId\n in \noverrideConfig\n\nCopy\n{\n\n    \"question\": \"hello!\",\n\n    \"overrideConfig\": {\n\n        \"sessionId\": \"user1\"\n\n    }\n\n}\nMessage API\n\nGET /api/v1/chatmessage/{your-chatflowid}\n\nDELETE /api/v1/chatmessage/{your-chatflowid}\n\nQuery Param\tType\tValue\n\n\nsessionId\n\n\t\n\nstring\n\n\t\n\n\n\n\nsort\n\n\t\n\nenum\n\n\t\n\nASC or DESC\n\n\n\n\nstartDate\n\n\t\n\nstring\n\n\t\n\n\n\n\nendDate\n\n\t\n\nstring\n\n\t\n\nAll conversations can be visualized and managed from UI as well:\n\nFor OpenAI Assistant, Threads will be used to store conversations.\n\nPrevious\nReplicate\nNext\nBuffer Memory\n\nLast updated 9 days ago\n\nAvailable Memories:\nSeparate conversations for multiple users\nUI & Embedded Chat\nPrediction API\nMessage API\nEdit on GitHub"
  },
  {
    "title": "HuggingFace Inference | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/llms/huggingface-inference",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nAWS Bedrock\nAzure OpenAI\nBittensor\nCohere\nGooglePaLM\nGoogleVertex AI\nHuggingFace Inference\nOllama\nOpenAI\nReplicate\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nHuggingFace Inference\n\nWrapper around HuggingFace large language models.\n\nHuggingFace Inference Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nGoogleVertex AI\nNext\nOllama\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "GoogleVertex AI | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/llms/googlevertex-ai",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nAWS Bedrock\nAzure OpenAI\nBittensor\nCohere\nGooglePaLM\nGoogleVertex AI\nHuggingFace Inference\nOllama\nOpenAI\nReplicate\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nGoogleVertex AI\n\nWrapper around GoogleVertexAI large language models.\n\nGoogleVertex AI Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nGooglePaLM\nNext\nHuggingFace Inference\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Cohere | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/llms/cohere",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nAWS Bedrock\nAzure OpenAI\nBittensor\nCohere\nGooglePaLM\nGoogleVertex AI\nHuggingFace Inference\nOllama\nOpenAI\nReplicate\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nCohere\n\nWrapper around Cohere large language models.\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nBittensor\nNext\nGooglePaLM\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Replicate | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/llms/replicate",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nAWS Bedrock\nAzure OpenAI\nBittensor\nCohere\nGooglePaLM\nGoogleVertex AI\nHuggingFace Inference\nOllama\nOpenAI\nReplicate\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nReplicate\n\nUse Replicate to run open source models on cloud.\n\nReplicate Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nOpenAI\nNext\nMemory\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "GooglePaLM | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/llms/googlepalm",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nAWS Bedrock\nAzure OpenAI\nBittensor\nCohere\nGooglePaLM\nGoogleVertex AI\nHuggingFace Inference\nOllama\nOpenAI\nReplicate\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nGooglePaLM\n\nWrapper around Google MakerSuite PaLM large language models.\n\nGooglePaLM Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nCohere\nNext\nGoogleVertex AI\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "AWS Bedrock | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/llms/aws-bedrock",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nAWS Bedrock\nAzure OpenAI\nBittensor\nCohere\nGooglePaLM\nGoogleVertex AI\nHuggingFace Inference\nOllama\nOpenAI\nReplicate\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAWS Bedrock\n\nWrapper around AWS Bedrock large language models.\n\nAWS Bedrock Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nLLMs\nNext\nAzure OpenAI\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "VoyageAI Embeddings | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/embeddings/voyageai-embeddings",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nAWS Bedrock Embeddings\nAzure OpenAI Embeddings\nCohere Embeddings\nGoogle GenerativeAI Embeddings\nGoogle PaLM Embeddings\nGoogle VertexAI Embeddings\nHuggingFace Inference Embeddings\nLocalAI Embeddings\nMistralAI Embeddings\nOllama Embeddings\nOpenAI Embeddings\nOpenAI Embeddings Custom\nTogetherAI Embedding\nVoyageAI Embeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nVoyageAI Embeddings\n\nVoyage AI API to generate embeddings for a given text.\n\nVoyageAI Embeddings Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nTogetherAI Embedding\nNext\nLLMs\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Azure OpenAI | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/llms/azure-openai",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nAWS Bedrock\nAzure OpenAI\nBittensor\nCohere\nGooglePaLM\nGoogleVertex AI\nHuggingFace Inference\nOllama\nOpenAI\nReplicate\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAzure OpenAI\n\nWrapper around Azure OpenAI large language models.\n\nAzure OpenAI Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nAWS Bedrock\nNext\nBittensor\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Bittensor | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/llms/bittensor",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nAWS Bedrock\nAzure OpenAI\nBittensor\nCohere\nGooglePaLM\nGoogleVertex AI\nHuggingFace Inference\nOllama\nOpenAI\nReplicate\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nBittensor\n\nWrapper around Bittensor subnet 1 large language models.\n\nBittensor Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nAzure OpenAI\nNext\nCohere\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "LLMs | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/llms",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nAWS Bedrock\nAzure OpenAI\nBittensor\nCohere\nGooglePaLM\nGoogleVertex AI\nHuggingFace Inference\nOllama\nOpenAI\nReplicate\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nLLMs\n\nA large language model, LLM for short, is a AI system trained on massive amounts of text data. This allows them to communicate and generate human-like text in response to a wide range of prompts and questions. In essence, they can understand and respond to complex language.\n\nAvailable LLMs:\n\nAWS Bedrock\n\nAzure OpenAI\n\nBittensor\n\nCohere\n\nGooglePaLM\n\nGoogleVertex AI\n\nHuggingFace Inference\n\nOllama\n\nOpenAI\n\nReplicate\n\nPrevious\nVoyageAI Embeddings\nNext\nAWS Bedrock\n\nLast updated 9 days ago\n\nEdit on GitHub"
  },
  {
    "title": "TogetherAI Embedding | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/embeddings/togetherai-embedding",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nAWS Bedrock Embeddings\nAzure OpenAI Embeddings\nCohere Embeddings\nGoogle GenerativeAI Embeddings\nGoogle PaLM Embeddings\nGoogle VertexAI Embeddings\nHuggingFace Inference Embeddings\nLocalAI Embeddings\nMistralAI Embeddings\nOllama Embeddings\nOpenAI Embeddings\nOpenAI Embeddings Custom\nTogetherAI Embedding\nVoyageAI Embeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nTogetherAI Embedding\n\nTogetherAI Embedding models to generate embeddings for a given text.\n\nTogetherAI Embedding Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nOpenAI Embeddings Custom\nNext\nVoyageAI Embeddings\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "OpenAI Embeddings | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/embeddings/openai-embeddings",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nAWS Bedrock Embeddings\nAzure OpenAI Embeddings\nCohere Embeddings\nGoogle GenerativeAI Embeddings\nGoogle PaLM Embeddings\nGoogle VertexAI Embeddings\nHuggingFace Inference Embeddings\nLocalAI Embeddings\nMistralAI Embeddings\nOllama Embeddings\nOpenAI Embeddings\nOpenAI Embeddings Custom\nTogetherAI Embedding\nVoyageAI Embeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nOpenAI Embeddings\n\nOpenAI API to generate embeddings for a given text.\n\nOpenAI Embeddings Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nOllama Embeddings\nNext\nOpenAI Embeddings Custom\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Ollama Embeddings | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/embeddings/ollama-embeddings",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nAWS Bedrock Embeddings\nAzure OpenAI Embeddings\nCohere Embeddings\nGoogle GenerativeAI Embeddings\nGoogle PaLM Embeddings\nGoogle VertexAI Embeddings\nHuggingFace Inference Embeddings\nLocalAI Embeddings\nMistralAI Embeddings\nOllama Embeddings\nOpenAI Embeddings\nOpenAI Embeddings Custom\nTogetherAI Embedding\nVoyageAI Embeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nOllama Embeddings\n\nGenerate embeddings for a given text using open source model on Ollama.\n\nOllama Embeddings Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nMistralAI Embeddings\nNext\nOpenAI Embeddings\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "OpenAI Embeddings Custom | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/embeddings/openai-embeddings-custom",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nAWS Bedrock Embeddings\nAzure OpenAI Embeddings\nCohere Embeddings\nGoogle GenerativeAI Embeddings\nGoogle PaLM Embeddings\nGoogle VertexAI Embeddings\nHuggingFace Inference Embeddings\nLocalAI Embeddings\nMistralAI Embeddings\nOllama Embeddings\nOpenAI Embeddings\nOpenAI Embeddings Custom\nTogetherAI Embedding\nVoyageAI Embeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nOpenAI Embeddings Custom\n\nOpenAI API to generate embeddings for a given text.\n\nOpenAI Embeddings Custom Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nOpenAI Embeddings\nNext\nTogetherAI Embedding\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "MistralAI Embeddings | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/embeddings/mistralai-embeddings",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nAWS Bedrock Embeddings\nAzure OpenAI Embeddings\nCohere Embeddings\nGoogle GenerativeAI Embeddings\nGoogle PaLM Embeddings\nGoogle VertexAI Embeddings\nHuggingFace Inference Embeddings\nLocalAI Embeddings\nMistralAI Embeddings\nOllama Embeddings\nOpenAI Embeddings\nOpenAI Embeddings Custom\nTogetherAI Embedding\nVoyageAI Embeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nMistralAI Embeddings\n\nMistralAI API to generate embeddings for a given text.\n\nMistralAI Embeddings Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nLocalAI Embeddings\nNext\nOllama Embeddings\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "LocalAI Embeddings | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/embeddings/localai-embeddings",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nAWS Bedrock Embeddings\nAzure OpenAI Embeddings\nCohere Embeddings\nGoogle GenerativeAI Embeddings\nGoogle PaLM Embeddings\nGoogle VertexAI Embeddings\nHuggingFace Inference Embeddings\nLocalAI Embeddings\nMistralAI Embeddings\nOllama Embeddings\nOpenAI Embeddings\nOpenAI Embeddings Custom\nTogetherAI Embedding\nVoyageAI Embeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nLocalAI Embeddings\nLocalAI Setup\n\nLocalAI is a drop-in replacement REST API that’s compatible with OpenAI API specifications for local inferencing. It allows you to run LLMs (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families that are compatible with the ggml format.\n\nTo use LocalAI Embeddings within Flowise, follow the steps below:\n\nCopy\ngit clone https://github.com/go-skynet/LocalAI\nCopy\ncd LocalAI\n\nLocalAI provides an API endpoint to download/install the model. In this example, we are going to use BERT Embeddings model:\n\nIn the /models folder, you should be able to see the downloaded model in there:\n\nYou can now test the embeddings:\n\nCopy\ncurl http://localhost:8080/v1/embeddings -H \"Content-Type: application/json\" -d '{\n\n    \"input\": \"Test\",\n\n    \"model\": \"text-embedding-ada-002\"\n\n  }'\n\nResponse should looks like:\n\nFlowise Setup\n\nDrag and drop a new LocalAIEmbeddings component to canvas:\n\nFill in the fields:\n\nBase Path: The base url from LocalAI such as http://localhost:8080/v1\n\nModel Name: The model you want to use. Note that it must be inside /models folder of LocalAI directory. For instance: text-embedding-ada-002\n\nThat's it! For more information, refer to LocalAI docs.\n\nPrevious\nHuggingFace Inference Embeddings\nNext\nMistralAI Embeddings\n\nLast updated 12 months ago\n\nLocalAI Setup\nFlowise Setup\nEdit on GitHub"
  },
  {
    "title": "Google VertexAI Embeddings | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/embeddings/googlevertexai-embeddings",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nAWS Bedrock Embeddings\nAzure OpenAI Embeddings\nCohere Embeddings\nGoogle GenerativeAI Embeddings\nGoogle PaLM Embeddings\nGoogle VertexAI Embeddings\nHuggingFace Inference Embeddings\nLocalAI Embeddings\nMistralAI Embeddings\nOllama Embeddings\nOpenAI Embeddings\nOpenAI Embeddings Custom\nTogetherAI Embedding\nVoyageAI Embeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nGoogle VertexAI Embeddings\n\nGoogle vertexAI API to generate embeddings for a given text.\n\nGoogle VertexAI Embeddings Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nGoogle PaLM Embeddings\nNext\nHuggingFace Inference Embeddings\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Google GenerativeAI Embeddings | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/embeddings/googlegenerativeai-embeddings",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nAWS Bedrock Embeddings\nAzure OpenAI Embeddings\nCohere Embeddings\nGoogle GenerativeAI Embeddings\nGoogle PaLM Embeddings\nGoogle VertexAI Embeddings\nHuggingFace Inference Embeddings\nLocalAI Embeddings\nMistralAI Embeddings\nOllama Embeddings\nOpenAI Embeddings\nOpenAI Embeddings Custom\nTogetherAI Embedding\nVoyageAI Embeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nGoogle GenerativeAI Embeddings\n\nGoogle Generative API to generate embeddings for a given text.\n\nGoogle GenerativeAI Embeddings Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nCohere Embeddings\nNext\nGoogle PaLM Embeddings\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "HuggingFace Inference Embeddings | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/embeddings/huggingface-inference-embeddings",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nAWS Bedrock Embeddings\nAzure OpenAI Embeddings\nCohere Embeddings\nGoogle GenerativeAI Embeddings\nGoogle PaLM Embeddings\nGoogle VertexAI Embeddings\nHuggingFace Inference Embeddings\nLocalAI Embeddings\nMistralAI Embeddings\nOllama Embeddings\nOpenAI Embeddings\nOpenAI Embeddings Custom\nTogetherAI Embedding\nVoyageAI Embeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nHuggingFace Inference Embeddings\n\nHuggingFace Inference API to generate embeddings for a given text.\n\nHuggingFace Inference Embeddings Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nGoogle VertexAI Embeddings\nNext\nLocalAI Embeddings\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Google PaLM Embeddings | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/embeddings/google-palm-embeddings",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nAWS Bedrock Embeddings\nAzure OpenAI Embeddings\nCohere Embeddings\nGoogle GenerativeAI Embeddings\nGoogle PaLM Embeddings\nGoogle VertexAI Embeddings\nHuggingFace Inference Embeddings\nLocalAI Embeddings\nMistralAI Embeddings\nOllama Embeddings\nOpenAI Embeddings\nOpenAI Embeddings Custom\nTogetherAI Embedding\nVoyageAI Embeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nGoogle PaLM Embeddings\n\nGoogle MakerSuite PaLM API to generate embeddings for a given text.\n\nGoogle PaLM Embeddings Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nGoogle GenerativeAI Embeddings\nNext\nGoogle VertexAI Embeddings\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Azure OpenAI Embeddings | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/embeddings/azure-openai-embeddings",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nAWS Bedrock Embeddings\nAzure OpenAI Embeddings\nCohere Embeddings\nGoogle GenerativeAI Embeddings\nGoogle PaLM Embeddings\nGoogle VertexAI Embeddings\nHuggingFace Inference Embeddings\nLocalAI Embeddings\nMistralAI Embeddings\nOllama Embeddings\nOpenAI Embeddings\nOpenAI Embeddings Custom\nTogetherAI Embedding\nVoyageAI Embeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAzure OpenAI Embeddings\nPrerequisite\n\nLog in or sign up to Azure\n\nCreate your Azure OpenAI and wait for approval approximately 10 business days\n\nYour API key will be available at Azure OpenAI > click name_azure_openai > click Click here to manage keys\n\nSetup\nAzure OpenAI Embeddings\n\nClick Go to Azure OpenaAI Studio\n\nClick Deployments\n\nClick Create new deployment\n\nSelect as shown below and click Create\n\nSuccessfully created Azure OpenAI Embeddings\n\nDeployment name: text-embedding-ada-002\n\nInstance name: top right conner\n\nFlowise\n\nEmbeddings > drag Azure OpenAI Embeddings node\n\nConnect Credential > click Create New\n\nCopy & Paste each details (API Key, Instance & Deployment name, API Version) into Azure OpenAI Embeddings credential\n\nVoila 🎉, you have created Azure OpenAI Embeddings node in Flowise\n\nResources\n\nLangChain JS Azure OpenAI Embeddings\n\nAzure OpenAI Service REST API reference\n\nPrevious\nAWS Bedrock Embeddings\nNext\nCohere Embeddings\n\nLast updated 5 months ago\n\nPrerequisite\nSetup\nAzure OpenAI Embeddings\nFlowise\nResources\nEdit on GitHub"
  },
  {
    "title": "Cohere Embeddings | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/embeddings/cohere-embeddings",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nAWS Bedrock Embeddings\nAzure OpenAI Embeddings\nCohere Embeddings\nGoogle GenerativeAI Embeddings\nGoogle PaLM Embeddings\nGoogle VertexAI Embeddings\nHuggingFace Inference Embeddings\nLocalAI Embeddings\nMistralAI Embeddings\nOllama Embeddings\nOpenAI Embeddings\nOpenAI Embeddings Custom\nTogetherAI Embedding\nVoyageAI Embeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nCohere Embeddings\n\nCohere API to generate embeddings for a given text\n\nCohere Embeddings Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nAzure OpenAI Embeddings\nNext\nGoogle GenerativeAI Embeddings\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "VectorStore To Document | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/vectorstore-to-document",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nVectorStore To Document\n\nSearch documents with scores from vector store.\n\nVectorStore To Document Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nUnstructured Folder Loader\nNext\nEmbeddings\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "AWS Bedrock Embeddings | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/embeddings/aws-bedrock-embeddings",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nAWS Bedrock Embeddings\nAzure OpenAI Embeddings\nCohere Embeddings\nGoogle GenerativeAI Embeddings\nGoogle PaLM Embeddings\nGoogle VertexAI Embeddings\nHuggingFace Inference Embeddings\nLocalAI Embeddings\nMistralAI Embeddings\nOllama Embeddings\nOpenAI Embeddings\nOpenAI Embeddings Custom\nTogetherAI Embedding\nVoyageAI Embeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAWS Bedrock Embeddings\n\nAWSBedrock embedding models to generate embeddings for a given text.\n\nAWS Bedrock Embeddings Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nEmbeddings\nNext\nAzure OpenAI Embeddings\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Embeddings | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/embeddings",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nAWS Bedrock Embeddings\nAzure OpenAI Embeddings\nCohere Embeddings\nGoogle GenerativeAI Embeddings\nGoogle PaLM Embeddings\nGoogle VertexAI Embeddings\nHuggingFace Inference Embeddings\nLocalAI Embeddings\nMistralAI Embeddings\nOllama Embeddings\nOpenAI Embeddings\nOpenAI Embeddings Custom\nTogetherAI Embedding\nVoyageAI Embeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nEmbeddings\n\nAn embedding is a vector (list) of floating point numbers. The distance between two vectors measures their relatedness. Small distances suggest high relatedness and large distances suggest low relatedness.\n\nEmbeddings can be used to create a numerical representation of textual data. This numerical representation is useful because it can be used to find similar documents.\n\nThey are commonly used for:\n\nSearch (where results are ranked by relevance to a query string)\n\nClustering (where text strings are grouped by similarity)\n\nRecommendations (where items with related text strings are recommended)\n\nAnomaly detection (where outliers with little relatedness are identified)\n\nDiversity measurement (where similarity distributions are analyzed)\n\nClassification (where text strings are classified by their most similar label)\n\nAvailable Embeddings:\n\nAWS Bedrock Embeddings\n\nAzure OpenAI Embeddings\n\nCohere Embeddings\n\nGoogle GenerativeAI Embeddings\n\nGoogle PaLM Embeddings\n\nGoogle VertexAI Embeddings\n\nHuggingFace Inference Embeddings\n\nLocalAI Embeddings\n\nMistralAI Embeddings\n\nOllama Embeddings\n\nOpenAI Embeddings\n\nOpenAI Embeddings Custom\n\nTogetherAI Embedding\n\nVoyageAI Embeddings\n\nPrevious\nVectorStore To Document\nNext\nAWS Bedrock Embeddings\n\nLast updated 9 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Unstructured File Loader | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/unstructured-file-loader",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nUnstructured File Loader\n\nUse Unstructured.io to load data from a file path.\n\nUnstructured File Loader Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nText File\nNext\nUnstructured Folder Loader\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Unstructured Folder Loader | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/unstructured-folder-loader",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nUnstructured Folder Loader\n\nUse Unstructured.io to load data from a folder. Note: Currently doesn't support .png and .heic until unstructured is updated.\n\nUnstructured Folder Loader Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nUnstructured File Loader\nNext\nVectorStore To Document\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "SerpApi For Web Search | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/serpapi-for-web-search",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nSerpApi For Web Search\n\nLoad and process data from web search results.\n\nSerpApi For Web Search Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nSearchApi For Web Search\nNext\nText File\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "S3 File Loader | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/s3-file-loader",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nS3 File Loader\n\nS3 File Loader allows you to retrieve a file from s3, and use Unstructured to preprocess into a structured Document object that is ready to be converted into vector embeddings. Unstructured is being used to cater for wide range of different file types. Regardless if your file on s3 is PDF, XML, DOCX, CSV, it can be processed by Unstructured. See here for supported file types.\n\nUnstructured Setup\n\nYou can either use the hosted API or running locally via Docker.\n\nHosted API\n\nDocker: docker run -p 8000:8000 -d --rm --name unstructured-api quay.io/unstructured-io/unstructured-api:latest --port 8000 --host 0.0.0.0\n\nS3 File Loader Setup\n\n1. Drag and drop S3 file loader onto canvas:\n\n2. AWS Credential: Create a new credential for your AWS account. You'll need the access and secret key. Remember to grant s3 bucket policy to the associated account. You can refer to the policy guide here.\n\nBucket: Login to your AWS console and navigate to S3. Get your bucket name: \n\nKey: Click on the object you would like to use, and get the Key name:\n\nUnstructured API URL: Depending on how you are using Unstructured, whether its through Hosted API or Docker, change the Unstructured API URL parameter. If you are using Hosted API, you'll need the API key as well.\n\nYou can then start chatting with your file from S3. You don't have to specify the text splitter for chunking down the document because thats handled by Unstructured automatically.\n\nPrevious\nPuppeteer Web Scraper\nNext\nSearchApi For Web Search\n\nLast updated 7 months ago\n\nUnstructured Setup\nS3 File Loader Setup\nEdit on GitHub"
  },
  {
    "title": "SearchApi For Web Search | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/searchapi-for-web-search",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nSearchApi For Web Search\n\nLoad data from real-time search results.\n\nSearchApi For Web Search\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nS3 File Loader\nNext\nSerpApi For Web Search\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Text File | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/text-file",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nText File\n\nLoad data from text files.\n\nText File Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nSerpApi For Web Search\nNext\nUnstructured File Loader\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Plain Text | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/plain-text",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nPlain Text\n\nLoad data from plain text.\n\nPlain Text Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nPDF Files\nNext\nPlaywright Web Scraper\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Notion Database | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/notion-database",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nNotion Database\n\nLoad data from Notion Database (each row is a separate document with all properties as metadata).\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nJson Lines File\nNext\nNotion Folder\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Puppeteer Web Scraper | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/puppeteer-web-scraper",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nPuppeteer Web Scraper\n\nPuppeteer is a Node.js library, controls Chrome/Chromium through the DevTools Protocol in headless mode. Keep in mind that when scraping websites, you should always review and comply with the website's terms of service and policies to ensure ethical and legal use of the data.\n\nScrape One URL\n\n(Optional) Connect Text Splitter.\n\nInput desired URL to be scraped.\n\nCrawl & Scrape Multiple URLs\n\nVisit Web Crawl guide to allow scaping of multiple pages.\n\nOutput\n\nLoads URL content as Document\n\nResources\n\nLangChain JS Puppeteer\n\nPuppeteer\n\nPrevious\nPlaywright Web Scraper\nNext\nS3 File Loader\n\nLast updated 3 months ago\n\nScrape One URL\nCrawl & Scrape Multiple URLs\nOutput\nResources\nEdit on GitHub"
  },
  {
    "title": "Playwright Web Scraper | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/playwright-web-scraper",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nPlaywright Web Scraper\n\nPlaywright is a Node.js library that allows automation of web browsers for web scraping. It was developed by Microsoft and supports multiple browsers, including Chromium. Keep in mind that when scraping websites, you should always review and comply with the website's terms of service and policies to ensure ethical and legal use of the data.\n\nScrape One URL\n\n(Optional) Connect Text Splitter.\n\nInput desired URL to be scraped.\n\nCrawl & Scrape Multiple URLs\n\nVisit Web Crawl guide to allow scaping of multiple pages.\n\nOutput\n\nLoads URL content as Document\n\nResources\n\nLangChain JS Playwright\n\nPlaywright\n\nPrevious\nPlain Text\nNext\nPuppeteer Web Scraper\n\nLast updated 3 months ago\n\nScrape One URL\nCrawl & Scrape Multiple URLs\nOutput\nResources\nEdit on GitHub"
  },
  {
    "title": "PDF Files | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/pdf-file",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nPDF Files\n\nPortable Document Format (PDF), standardized as ISO 32000, is a file format developed by Adobe in 1992 to present documents, including text formatting and images, in a manner independent of application software, hardware, and operating systems.\nThe Pdf File module decodes the base64-encoded data from the PDF document and then loads the PDF content.\nIf a textSplitter is provided, it uses it to split the text content.\n\nInputs\n\nText Splitter (optional)\nPDF File\nUsage\nOne Document per Page OR One Document per File\n\n\nOutput\n\nloads PDF content\n\nPrevious\nNotion Page\nNext\nPlain Text\n\nLast updated 7 months ago\n\nInputs\nOutput\nEdit on GitHub"
  },
  {
    "title": "Notion Page | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/notion-page",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nNotion Page\n\nLoad data from Notion Page (including child pages all as separate documents).\n\nNotion Page Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nNotion Folder\nNext\nPDF Files\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Json Lines File | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/json-lines-file",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nJson Lines File\n\nLoad data from JSON Lines files.\n\nJson Lines File Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nJson File\nNext\nNotion Database\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Notion Folder | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/notion-folder",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nNotion Folder\n\nLoad data from the exported and unzipped Notion folder.\n\nNotion Folder Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nNotion Database\nNext\nNotion Page\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Json File | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/json-file",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nJson File\n\nLoad data from JSON files.\n\nJson File Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nGithub\nNext\nJson Lines File\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Github | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/github",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nGithub\n\nLoad data from a GitHub repository.\n\nGithub Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nGitBook\nNext\nJson File\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Document Store | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/document-store",
    "html": "An error occurred\n\nSorry, an unexpected error has occurred. Please try again later.\n\nRetry"
  },
  {
    "title": "Custom Document Loader | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/custom-document-loader",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nCustom Document Loader\n\nCustom function for loading documents.\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nCsv File\nNext\nDocument Store\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Folder with Files | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/folder-with-files",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nFolder with Files\n\nLoad data from folder with multiple files.\n\nFolder with Files Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nFigma\nNext\nGitBook\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "GitBook | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/gitbook",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nGitBook\n\nLoad data from GitBook.\n\nGitBook Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nFolder with Files\nNext\nGithub\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Figma | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/figma",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nFigma\n\nLoad data from a Figma file.\n\nFigma Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nDocx File\nNext\nFolder with Files\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Docx File | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/docx-file",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nDocx File\n\nLoad data from DOCX files.\n\nDocx File Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nDocument Store\nNext\nFigma\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Confluence | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/confluence",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nConfluence\n\nLoad data from a Confluence Document\n\nConfluence Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nCheerio Web Scraper\nNext\nCsv File\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Csv File | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/csv-file",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nCsv File\n\nLoad data from CSV files.\n\nCsv File Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nConfluence\nNext\nCustom Document Loader\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Apify Website Content Crawler | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/apify-website-content-crawler",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nApify Website Content Crawler\n\nLoad data from Apify Website Content Crawler.\n\nApify Website Content Crawler Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nAirtable\nNext\nCheerio Web Scraper\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Document Loaders | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nDocument Loaders\n\nDocument loaders allow you to load documents from different sources like PDF, TXT, CSV, Notion, Confluence etc. They are often used together with Vector Stores to be upserted as embeddings, which can then retrieved upon query.\n\nWatch an intro on Document Loaders\nAvailable Document Loaders:\n\nAPI Loader\n\nAirtable\n\nApify Website Content Crawler\n\nCheerio Web Scraper\n\nConfluence\n\nCsv File\n\nCustom Document Loader\n\nDocument Store\n\nDocx File\n\nFigma\n\nFolder with Files\n\nGitBook\n\nGithub\n\nJson File\n\nJson Lines File\n\nNotion Database\n\nNotion Folder\n\nNotion Page\n\nPDF Files\n\nPlain Text\n\nPlaywright Web Scraper\n\nPuppeteer Web Scraper\n\nS3 File Loader\n\nSearchApi For Web Search\n\nSerpApi For Web Search\n\nText File\n\nUnstructured File Loader\n\nUnstructured Folder Loader\n\nVectorStore To Document\n\nPrevious\nGroqChat\nNext\nAPI Loader\n\nLast updated 9 days ago\n\nWatch an intro on Document Loaders\nAvailable Document Loaders:\nEdit on GitHub"
  },
  {
    "title": "Cheerio Web Scraper | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/cheerio-web-scraper",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nCheerio Web Scraper\n\nCheerio is lightweight and doesn't require a full browser environment like some other scraping tools. Keep in mind that when scraping websites, you should always review and comply with the website's terms of service and policies to ensure ethical and legal use of the data.\n\nScrape One URL\n\n(Optional) Connect Text Splitter.\n\nInput desired URL to be scraped.\n\nCrawl & Scrape Multiple URLs\n\nVisit Web Crawl guide to allow scaping of multiple pages.\n\nOutput\n\nLoads URL content as Document\n\nResources\n\nLangChain JS Cheerio\n\nCheerio\n\nPrevious\nApify Website Content Crawler\nNext\nConfluence\n\nLast updated 3 months ago\n\nScrape One URL\nCrawl & Scrape Multiple URLs\nOutput\nResources\nEdit on GitHub"
  },
  {
    "title": "Google VertexAI | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models/google-vertexai",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nGoogle VertexAI\nPrerequisites\n\nStart your GCP\n\nInstall the Google Cloud CLI\n\nSetup\nEnable vertex AI API\n\nGo to Vertex AI on GCP and click \"ENABLE ALL RECOMMENDED API\"\n\nCreate credential file (Optional)\n\nThere are 2 ways to create credential file\n\nNo. 1 : Use GCP CLI\n\nOpen terminal and run the following command\n\nCopy\ngcloud auth application-default login\n\nLogin to your GCP account\n\nCheck your credential file. You can find your credential file in ~/.config/gcloud/application_default_credentials.json\n\nNo. 2 : Use GCP console\n\nGo to GCP console and click \"CREATE CREDENTIALS\"\n\nCreate service account\n\nFill in the form of Service account details and click \"CREATE AND CONTINUE\"\n\nSelect proper role (for example Vertex AI User) and click \"DONE\"\n\nClick service account that you created and click \"ADD KEY\" -> \"Create new key\"\n\nSelect JSON and click \"CREATE\" then you can download your credential file\n\nFlowise\nWithout credential file\n\nIf you are using a GCP service like Cloud Run, or if you have installed default credentials on your local machine, you do not need to set this credential.\n\nWith credential file\n\nGo to Credential page on Flowise and click \"Add credential\"\n\nClick Google Vertex Auth\n\nRegister your credential file. There are 2 ways to register your credential file.\n\nOption 1 : Enter path of your credential file\n\nIf you have credential file on your machine, you can enter the path of your credential file into Google Application Credential File Path\n\nOption 2 : Paste text of your credential file\n\nOr you can copy all text in the credential file and paste it into Google Credential JSON Object\n\nFinally, click \"Add\" button.\n\n🎉You can now use ChatGoogleVertexAI with the credential in Flowise now!\n\nResources\n\nLangChain JS GoogleVertexAI\n\nGoogle Service accounts overview\n\nTry Google Vertex AI Palm 2 with Flowise: Without Coding to Leverage Intuition\n\nPrevious\nChatGooglePaLM\nNext\nChatHuggingFace\n\nLast updated 9 months ago\n\nPrerequisites\nSetup\nEnable vertex AI API\nCreate credential file (Optional)\nNo. 1 : Use GCP CLI\nNo. 2 : Use GCP console\nFlowise\nWithout credential file\nWith credential file\nResources\nEdit on GitHub"
  },
  {
    "title": "API Loader | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/document-loaders/api-loader",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nAPI Loader\nAirtable\nApify Website Content Crawler\nCheerio Web Scraper\nConfluence\nCsv File\nCustom Document Loader\nDocument Store\nDocx File\nFigma\nFolder with Files\nGitBook\nGithub\nJson File\nJson Lines File\nNotion Database\nNotion Folder\nNotion Page\nPDF Files\nPlain Text\nPlaywright Web Scraper\nPuppeteer Web Scraper\nS3 File Loader\nSearchApi For Web Search\nSerpApi For Web Search\nText File\nUnstructured File Loader\nUnstructured Folder Loader\nVectorStore To Document\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAPI Loader\n\nLoad data from an API.\n\nAPI Loader Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nDocument Loaders\nNext\nAirtable\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "GroqChat | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models/groqchat",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nGroqChat\n\nWrapper around Groq API with LPU Inference Engine.\n\nGroqChat Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nChatTogetherAI\nNext\nDocument Loaders\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "ChatTogetherAI | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models/chattogetherai",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChatTogetherAI\n\nWrapper around TogetherAI large language models\n\nChatTogetherAI Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nChatOpenAI Custom\nNext\nGroqChat\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "ChatOpenAI Custom | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models/chatopenai-custom",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChatOpenAI Custom\n\nCustom/FineTuned model using OpenAI Chat compatible API.\n\nChatOpenAI Custom Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nChatOpenAI\nNext\nChatTogetherAI\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "ChatOllama | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models/chatollama",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChatOllama\nPrerequisite\n\nDownload Ollama or run it on Docker. \n\nFor example, you can use the following command to spin up a Docker instance with llama3\n\nCopy\ndocker run -d -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\n\ndocker exec -it ollama ollama run llama3\nSetup\n\nChat Models > drag ChatOllama node\n\nFill in the model that is running on Ollama. For example: llama2. You can also use additional parameters:\n\nVoila 🎉, you can now use ChatOllama node in Flowise\n\nAdditional\n\nIf you are running both Flowise and Ollama on docker. You'll have to change the Base URL for ChatOllama.\n\nFor Windows and MacOS Operating Systems specify http://host.docker.internal:8000. For Linux based systems the default docker gateway should be used since host.docker.internal is not available: http://172.17.0.1:8000\n\nResources\n\nLangchainJS ChatOllama\n\nOllama\n\nPrevious\nChatMistralAI\nNext\nChatOpenAI\n\nLast updated 1 month ago\n\nPrerequisite\nSetup\nAdditional\nResources\nEdit on GitHub"
  },
  {
    "title": "ChatOpenAI | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models/azure-chatopenai",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChatOpenAI\nPrerequisite\n\nAn OpenAI account\n\nCreate an API key\n\nSetup\n\nChat Models > drag ChatOpenAI node\n\nConnect Credential > click Create New\n\nFill in the ChatOpenAI credential\n\nVoila 🎉, you can now use ChatOpenAI node in Flowise\n\nCustom base URL and headers\n\nFlowise supports using custom base URL and headers for Chat OpenAI. Users can easily use integrations like OpenRouter, TogetherAI and others that support OpenAI API compatibility.\n\nTogetherAI\n\nRefer to official docs from TogetherAI\n\nCreate a new credential with TogetherAI API key\n\nClick Additional Parameters on ChatOpenAI node.\n\nChange the Base Path:\n\nOpen Router\n\nRefer to official docs from OpenRouter\n\nCreate a new credential with OpenRouter API key\n\nClick Additional Parameters on ChatOpenAI node\n\nChange the Base Path and Base Options:\n\nCustom Model\n\nFor models that are not supported on ChatOpenAI node, you can use ChatOpenAI Custom for that. This allow users to fill in model name such as mistralai/Mixtral-8x7B-Instruct-v0.1\n\nImage Upload\n\nYou can also allow images to be uploaded and analyzed by LLM. Under the hood, Flowise will use OpenAI Vison model to process the image. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent.\n\nFrom the chat interface, you will now see a new image upload button:\n\nPrevious\nChatOllama\nNext\nChatOpenAI Custom\n\nLast updated 2 days ago\n\nPrerequisite\nSetup\nCustom base URL and headers\nTogetherAI\nOpen Router\nCustom Model\nImage Upload\nEdit on GitHub"
  },
  {
    "title": "ChatLocalAI | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models/chatlocalai",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChatLocalAI\nLocalAI Setup\n\nLocalAI is a drop-in replacement REST API that’s compatible with OpenAI API specifications for local inferencing. It allows you to run LLMs (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families that are compatible with the ggml format.\n\nTo use ChatLocalAI within Flowise, follow the steps below:\n\nCopy\ngit clone https://github.com/go-skynet/LocalAI\nCopy\ncd LocalAI\nCopy\n# copy your models to models/\n\ncp your-model.bin models/\n\nFor example:\n\nDownload one of the models from gpt4all.io\n\nCopy\n# Download gpt4all-j to models/\n\nwget https://gpt4all.io/models/ggml-gpt4all-j.bin -O models/ggml-gpt4all-j\n\nIn the /models folder, you should be able to see the downloaded model in there:\n\nRefer here for list of supported models.\n\nCopy\ndocker-compose up -d --pull always\n\nNow API is accessible at localhost:8080\n\nCopy\n# Test API\n\ncurl http://localhost:8080/v1/models\n\n# {\"object\":\"list\",\"data\":[{\"id\":\"ggml-gpt4all-j.bin\",\"object\":\"model\"}]}\nFlowise Setup\n\nDrag and drop a new ChatLocalAI component to canvas:\n\nFill in the fields:\n\nBase Path: The base url from LocalAI such as http://localhost:8080/v1\n\nModel Name: The model you want to use. Note that it must be inside /models folder of LocalAI directory. For instance: ggml-gpt4all-j.bin\n\nIf you are running both Flowise and LocalAI on Docker, you might need to change the base path to http://host.docker.internal:8080/v1. For Linux based systems the default docker gateway should be used since host.docker.internal is not available: http://172.17.0.1:8080/v1\n\nThat's it! For more information, refer to LocalAI docs.\n\nWatch how you can use LocalAI on Flowise\n\nPrevious\nChatHuggingFace\nNext\nChatMistralAI\n\nLast updated 1 month ago\n\nLocalAI Setup\nFlowise Setup\nEdit on GitHub"
  },
  {
    "title": "ChatMistralAI | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models/mistral-ai",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChatMistralAI\nPrerequisite\n\nRegister a Mistral AI account\n\nCreate an API key\n\nSetup\n\nChat Models > drag ChatMistralAI node\n\nConnect Credential > click Create New\n\nFill in the Mistral AI credential\n\nVoila 🎉, you can now use ChatMistralAI node in Flowise\n\nResources\n\nLangChain JS ChatMistralAI\n\nMistral AI\n\nMistral AI Docs\n\nPrevious\nChatLocalAI\nNext\nChatOllama\n\nLast updated 1 month ago\n\nPrerequisite\nSetup\nResources\nEdit on GitHub"
  },
  {
    "title": "ChatGooglePaLM | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models/chatgooglepalm",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChatGooglePaLM\n\nWrapper around Google MakerSuite PaLM large language models using the Chat endpoint.\n\nChatGooglePaLM\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nChatGoogleGenerativeAI\nNext\nGoogle VertexAI\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "ChatHuggingFace | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models/chathuggingface",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChatHuggingFace\n\nWrapper around HuggingFace large language models.\n\nChatHuggingFace Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nGoogle VertexAI\nNext\nChatLocalAI\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "ChatGoogleGenerativeAI | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models/google-ai",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChatGoogleGenerativeAI\nPrerequisite\n\nRegister a Google account\n\nCreate an API key\n\nSetup\n\nChat Models > drag ChatGoogleGenerativeAI node\n\nConnect Credential > click Create New\n\nFill in the Google AI credential\n\nVoila 🎉, you can now use ChatGoogleGenerativeAI node in Flowise\n\nSafety Attributes Configuration\n\nClick Additonal Parameters\n\nWhen configuring Safety Attributes, the amount of selection in Harm Category & Harm Block Threshold should be the same amount. If not it will throw an error Harm Category & Harm Block Threshold are not the same length\n\nThe combination of Safety Attributes below will result in Dangerous is set to Low and Above and Harassment is set to Medium and Above\n\nResources\n\nLangChain JS ChatGoogleGenerativeAI\n\nGoogle AI for Developers\n\nGemini API Docs\n\nPrevious\nChatCohere\nNext\nChatGooglePaLM\n\nLast updated 2 months ago\n\nPrerequisite\nSetup\nSafety Attributes Configuration\nResources\nEdit on GitHub"
  },
  {
    "title": "ChatAnthropic | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models/chatanthropic",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChatAnthropic\n\nWrapper around ChatAnthropic large language models that use the Chat endpoint.\n\nChatAnthropic Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nNIBittensorChat\nNext\nChatCohere\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "NIBittensorChat | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models/nibittensorchat",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nNIBittensorChat\n\nWrapper around Bittensor subnet 1 large language models.\n\nNIBittensorChat Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nAzure ChatOpenAI\nNext\nChatAnthropic\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Azure ChatOpenAI | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models/azure-chatopenai-1",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAzure ChatOpenAI\nPrerequisite\n\nLog in or sign up to Azure\n\nCreate your Azure OpenAI and wait for approval approximately 10 business days\n\nYour API key will be available at Azure OpenAI > click name_azure_openai > click Click here to manage keys\n\nSetup\nAzure ChatOpenAI\n\nClick Go to Azure OpenaAI Studio\n\nClick Deployments\n\nClick Create new deployment\n\nSelect as shown below and click Create\n\nSuccessfully created Azure ChatOpenAI\n\nDeployment name: gpt-35-turbo\n\nInstance name: top right conner\n\nFlowise\n\nChat Models > drag Azure ChatOpenAI node\n\nConnect Credential > click Create New\n\nCopy & Paste each details (API Key, Instance & Deployment name, API Version) into Azure ChatOpenAI credential\n\nVoila 🎉, you have created Azure ChatOpenAI node in Flowise\n\nResources\n\nLangChain JS Azure ChatOpenAI\n\nAzure OpenAI Service REST API reference\n\nPrevious\nAWS ChatBedrock\nNext\nNIBittensorChat\n\nLast updated 2 months ago\n\nPrerequisite\nSetup\nAzure ChatOpenAI\nFlowise\nResources\nEdit on GitHub"
  },
  {
    "title": "ChatCohere | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models/chatcohere",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChatCohere\n\nWrapper around Cohere Chat Endpoints.\n\nChatCohere Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nChatAnthropic\nNext\nChatGoogleGenerativeAI\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "VectorDB QA Chain | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chains/vectordb-qa-chain",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nGET API Chain\nOpenAPI Chain\nPOST API Chain\nConversation Chain\nConversational Retrieval QA Chain\nLLM Chain\nMulti Prompt Chain\nMulti Retrieval QA Chain\nRetrieval QA Chain\nSql Database Chain\nVectara QA Chain\nVectorDB QA Chain\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nVectorDB QA Chain\n\nQA chain for vector databases.\n\nVectorDB QA Chain Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nVectara QA Chain\nNext\nChat Models\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Chat Models | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChat Models\n\nChat models take a list of messages as input and return a model-generated message as output. These models such as gpt-3.5-turbo or gpt4 are powerful and cheaper than its predecessor Completions models such as text-davincii-003.\n\nAvailable Chat Models:\n\nAWS ChatBedrock\n\nAzure ChatOpenAI\n\nNIBittensorChat\n\nChatAnthropic\n\nChatCohere\n\nChatGoogleGenerativeAI\n\nChatGooglePaLM\n\nGoogle VertexAI\n\nChatHuggingFace\n\nChatLocalAI\n\nChatMistralAI\n\nChatOllama\n\nChatOpenAI\n\nChatOpenAI Custom\n\nChatTogetherAI\n\nGroqChat\n\nPrevious\nVectorDB QA Chain\nNext\nAWS ChatBedrock\n\nLast updated 9 days ago\n\nEdit on GitHub"
  },
  {
    "title": "AWS ChatBedrock | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chat-models/aws-chatbedrock",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nAWS ChatBedrock\nAzure ChatOpenAI\nNIBittensorChat\nChatAnthropic\nChatCohere\nChatGoogleGenerativeAI\nChatGooglePaLM\nGoogle VertexAI\nChatHuggingFace\nChatLocalAI\nChatMistralAI\nChatOllama\nChatOpenAI\nChatOpenAI Custom\nChatTogetherAI\nGroqChat\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAWS ChatBedrock\n\nWrapper around AWS Bedrock large language models that use the Chat endpoint.\n\nAWS ChatBedrock\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nChat Models\nNext\nAzure ChatOpenAI\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Sql Database Chain | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chains/sql-database-chain",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nGET API Chain\nOpenAPI Chain\nPOST API Chain\nConversation Chain\nConversational Retrieval QA Chain\nLLM Chain\nMulti Prompt Chain\nMulti Retrieval QA Chain\nRetrieval QA Chain\nSql Database Chain\nVectara QA Chain\nVectorDB QA Chain\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nSql Database Chain\n\nAnswer questions over a SQL database.\n\nSql Database Chain Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nRetrieval QA Chain\nNext\nVectara QA Chain\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Vectara QA Chain | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chains/vectara-chain",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nGET API Chain\nOpenAPI Chain\nPOST API Chain\nConversation Chain\nConversational Retrieval QA Chain\nLLM Chain\nMulti Prompt Chain\nMulti Retrieval QA Chain\nRetrieval QA Chain\nSql Database Chain\nVectara QA Chain\nVectorDB QA Chain\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nVectara QA Chain\n\nA chain for performing question-answering tasks with Vectara.\n\nDefinitions\n\nA retrieval-based question-answering chain, which integrates with a Vectara retrieval component and allows you to configure input parameters and perform question-answering tasks.\n\nInputs\n\nVectara Store\n\nParameters\nName\tDescription\n\n\nSummarizer Prompt Name\n\n\t\n\nmodel to be used in generating the summary\n\n\n\n\nResponse Language\n\n\t\n\ndesired language for the response\n\n\n\n\nMax Summarized Results\n\n\t\n\nnumber of top results to use in summarization (defaults to 7)\n\nOutputs\nName\tDescription\n\n\nVectaraQAChain\n\n\t\n\nFinal node to return response\n\nPrevious\nSql Database Chain\nNext\nVectorDB QA Chain\n\nLast updated 6 months ago\n\nDefinitions\nInputs\nParameters\nOutputs\nEdit on GitHub"
  },
  {
    "title": "Multi Retrieval QA Chain | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chains/multi-retrieval-qa-chain",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nGET API Chain\nOpenAPI Chain\nPOST API Chain\nConversation Chain\nConversational Retrieval QA Chain\nLLM Chain\nMulti Prompt Chain\nMulti Retrieval QA Chain\nRetrieval QA Chain\nSql Database Chain\nVectara QA Chain\nVectorDB QA Chain\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nMulti Retrieval QA Chain\n\nQA Chain that automatically picks an appropriate vector store from multiple retrievers.\n\nMulti Retrieval QA Chain Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nMulti Prompt Chain\nNext\nRetrieval QA Chain\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Retrieval QA Chain | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chains/retrieval-qa-chain",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nGET API Chain\nOpenAPI Chain\nPOST API Chain\nConversation Chain\nConversational Retrieval QA Chain\nLLM Chain\nMulti Prompt Chain\nMulti Retrieval QA Chain\nRetrieval QA Chain\nSql Database Chain\nVectara QA Chain\nVectorDB QA Chain\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nRetrieval QA Chain\n\nQA chain to answer a question based on the retrieved documents.\n\nRetrieval QA Chain Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nMulti Retrieval QA Chain\nNext\nSql Database Chain\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Multi Prompt Chain | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chains/multi-prompt-chain",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nGET API Chain\nOpenAPI Chain\nPOST API Chain\nConversation Chain\nConversational Retrieval QA Chain\nLLM Chain\nMulti Prompt Chain\nMulti Retrieval QA Chain\nRetrieval QA Chain\nSql Database Chain\nVectara QA Chain\nVectorDB QA Chain\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nMulti Prompt Chain\n\nChain automatically picks an appropriate prompt from multiple prompt templates.\n\nMulti Prompt Chain Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nLLM Chain\nNext\nMulti Retrieval QA Chain\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "LLM Chain | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chains/llm-chain",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nGET API Chain\nOpenAPI Chain\nPOST API Chain\nConversation Chain\nConversational Retrieval QA Chain\nLLM Chain\nMulti Prompt Chain\nMulti Retrieval QA Chain\nRetrieval QA Chain\nSql Database Chain\nVectara QA Chain\nVectorDB QA Chain\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nLLM Chain\n\nChain to run queries against LLMs.\n\nLLM Chain Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nConversational Retrieval QA Chain\nNext\nMulti Prompt Chain\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Conversational Retrieval QA Chain | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chains/conversational-retrieval-qa-chain",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nGET API Chain\nOpenAPI Chain\nPOST API Chain\nConversation Chain\nConversational Retrieval QA Chain\nLLM Chain\nMulti Prompt Chain\nMulti Retrieval QA Chain\nRetrieval QA Chain\nSql Database Chain\nVectara QA Chain\nVectorDB QA Chain\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nConversational Retrieval QA Chain\n\nA chain for performing question-answering tasks with a retrieval component.\n\nDefinitions\n\nA retrieval-based question-answering chain, which integrates with a retrieval component and allows you to configure input parameters and perform question-answering tasks.\nRetrieval-Based Chatbots: Retrieval-based chatbots are chatbots that generate responses by selecting pre-defined responses from a database or a set of possible responses. They \"retrieve\" the most appropriate response based on the input from the user.\nQA (Question Answering): QA systems are designed to answer questions posed in natural language. They typically involve understanding the question and searching for or generating an appropriate answer.\n\nInputs\n\nLanguage Model\n\nVector Store Retriever\n\nMemory (optional)\n\nParameters\nName\tDescription\n\n\nReturn Source Documents\n\n\t\n\nTo return citations/sources that were used to build up the response\n\n\n\n\nSystem Message\n\n\t\n\nAn instruction for LLM on how to answer query\n\n\n\n\nChain Option\n\n\t\n\nMethod on how to summarize, answer questions, and extract information from documents. Read more\n\nOutputs\nName\tDescription\n\n\nConversationalRetrievalQAChain\n\n\t\n\nFinal node to return response\n\nPrevious\nConversation Chain\nNext\nLLM Chain\n\nLast updated 5 months ago\n\nDefinitions\nInputs\nParameters\nOutputs\nEdit on GitHub"
  },
  {
    "title": "Conversation Chain | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chains/conversation-chain",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nGET API Chain\nOpenAPI Chain\nPOST API Chain\nConversation Chain\nConversational Retrieval QA Chain\nLLM Chain\nMulti Prompt Chain\nMulti Retrieval QA Chain\nRetrieval QA Chain\nSql Database Chain\nVectara QA Chain\nVectorDB QA Chain\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nConversation Chain\n\nChat models specific conversational chain with memory.\n\nConversation Chain Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nPOST API Chain\nNext\nConversational Retrieval QA Chain\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "POST API Chain | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chains/post-api-chain",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nGET API Chain\nOpenAPI Chain\nPOST API Chain\nConversation Chain\nConversational Retrieval QA Chain\nLLM Chain\nMulti Prompt Chain\nMulti Retrieval QA Chain\nRetrieval QA Chain\nSql Database Chain\nVectara QA Chain\nVectorDB QA Chain\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nPOST API Chain\n\nChain to run queries against POST API.\n\nPOST API Chain Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nOpenAPI Chain\nNext\nConversation Chain\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "OpenAPI Chain | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chains/openapi-chain",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nGET API Chain\nOpenAPI Chain\nPOST API Chain\nConversation Chain\nConversational Retrieval QA Chain\nLLM Chain\nMulti Prompt Chain\nMulti Retrieval QA Chain\nRetrieval QA Chain\nSql Database Chain\nVectara QA Chain\nVectorDB QA Chain\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nOpenAPI Chain\n\nChain that automatically select and call APIs based only on an OpenAPI spec.\n\nOpenAPI Chain Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nGET API Chain\nNext\nPOST API Chain\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Upstash Redis Cache | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/cache/upstash-redis-cache",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nInMemory Cache\nInMemory Embedding Cache\nMomento Cache\nRedis Cache\nUpstash Redis Cache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nUpstash Redis Cache\n\nCache LLM response in Upstash Redis, serverless data for Redis and Kafka.\n\nUpstash Redis Cache Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nRedis Cache\nNext\nChains\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "GET API Chain | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chains/get-api-chain",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nGET API Chain\nOpenAPI Chain\nPOST API Chain\nConversation Chain\nConversational Retrieval QA Chain\nLLM Chain\nMulti Prompt Chain\nMulti Retrieval QA Chain\nRetrieval QA Chain\nSql Database Chain\nVectara QA Chain\nVectorDB QA Chain\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nGET API Chain\n\nChain to run queries against GET API.\n\nGET API Chain Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nChains\nNext\nOpenAPI Chain\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Redis Cache | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/cache/redis-cache",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nInMemory Cache\nInMemory Embedding Cache\nMomento Cache\nRedis Cache\nUpstash Redis Cache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nRedis Cache\n\nCache LLM response in Redis, useful for sharing cache across multiple processes or servers.\n\nRedis Cache Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nMomento Cache\nNext\nUpstash Redis Cache\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Chains | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/chains",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nGET API Chain\nOpenAPI Chain\nPOST API Chain\nConversation Chain\nConversational Retrieval QA Chain\nLLM Chain\nMulti Prompt Chain\nMulti Retrieval QA Chain\nRetrieval QA Chain\nSql Database Chain\nVectara QA Chain\nVectorDB QA Chain\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChains\n\nIn the context of chatbots and large language models, \"chains\" typically refer to sequences of text or conversation turns. These chains are used to store and manage the conversation history and context for the chatbot or language model. Chains help the model understand the ongoing conversation and provide coherent and contextually relevant responses.\n\nHere's how chains work:\n\nConversation History: When a user interacts with a chatbot or language model, the conversation is often represented as a series of text messages or conversation turns. Each message from the user and the model is stored in chronological order to maintain the context of the conversation.\n\nInput and Output: Each chain consists of both user input and model output. The user's input is usually referred to as the \"input chain,\" while the model's responses are stored in the \"output chain.\" This allows the model to refer back to previous messages in the conversation.\n\nContextual Understanding: By preserving the entire conversation history in these chains, the model can understand the context and refer to earlier messages to provide coherent and contextually relevant responses. This is crucial for maintaining a natural and meaningful conversation with users.\n\nMaximum Length: Chains have a maximum length to manage memory usage and computational resources. When a chain becomes too long, older messages may be removed or truncated to make room for new messages. This can potentially lead to loss of context if important conversation details are removed.\n\nContinuation of Conversation: In a real-time chatbot or language model interaction, the input chain is continually updated with the user's new messages, and the output chain is updated with the model's responses. This allows the model to keep track of the ongoing conversation and respond appropriately.\n\nChains are a fundamental concept in building and maintaining chatbot and language model conversations. They ensure that the model has access to the context it needs to generate meaningful and context-aware responses, making the interaction more engaging and useful for users.\n\nAvailable Chains:\n\nGET API Chain\n\nOpenAPI Chain\n\nPOST API Chain\n\nConversation Chain\n\nConversational Retrieval QA Chain\n\nLLM Chain\n\nMulti Prompt Chain\n\nMulti Retrieval QA Chain\n\nRetrieval QA Chain\n\nSql Database Chain\n\nVectara QA Chain\n\nVectorDB QA Chain\n\nPrevious\nUpstash Redis Cache\nNext\nGET API Chain\n\nLast updated 9 days ago\n\nEdit on GitHub"
  },
  {
    "title": "InMemory Embedding Cache | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/cache/inmemory-embedding-cache",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nInMemory Cache\nInMemory Embedding Cache\nMomento Cache\nRedis Cache\nUpstash Redis Cache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nInMemory Embedding Cache\n\nCache generated Embeddings in memory to avoid needing to recompute them.\n\nInMemory Embedding Cache Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nInMemory Cache\nNext\nMomento Cache\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Momento Cache | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/cache/momento-cache",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nInMemory Cache\nInMemory Embedding Cache\nMomento Cache\nRedis Cache\nUpstash Redis Cache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nMomento Cache\n\nCache LLM response using Momento, a distributed, serverless cache.\n\nMomento Cache Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nInMemory Embedding Cache\nNext\nRedis Cache\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "XML Agent | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/agents/xml-agent",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nAirtable Agent\nAutoGPT\nBabyAGI\nCSV Agent\nConversational Agent\nConversational Retrieval Agent\nMistralAI Tool Agent\nOpenAI Assistant\nOpenAI Function Agent\nOpenAI Tool Agent\nReAct Agent Chat\nReAct Agent LLM\nTool Agent\nXML Agent\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nXML Agent\n\nAgent that is designed for LLMs that are good for reasoning/writing XML (e.g: Anthropic Claude).\n\nXML Agent Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nTool Agent\nNext\nCache\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Cache | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/cache",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nInMemory Cache\nInMemory Embedding Cache\nMomento Cache\nRedis Cache\nUpstash Redis Cache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nCache\n\nCaching can save you money by reducing the number of API calls you make to the LLM provider, if you're often requesting the same completion multiple times. It can speed up your application by reducing the number of API calls you make to the LLM provider.\n\nAvailable Caches:\n\nInMemory Cache\n\nInMemory Embedding Cache\n\nMomento Cache\n\nRedis Cache\n\nUpstash Redis Cache\n\nPrevious\nXML Agent\nNext\nInMemory Cache\n\nLast updated 9 days ago\n\nEdit on GitHub"
  },
  {
    "title": "InMemory Cache | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/cache/in-memory-cache",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nInMemory Cache\nInMemory Embedding Cache\nMomento Cache\nRedis Cache\nUpstash Redis Cache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nInMemory Cache\n\nCaches LLM response in local memory, will be cleared when app is restarted.\n\nInMemory Cache Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nCache\nNext\nInMemory Embedding Cache\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Tool Agent | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/agents/tool-agent",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nAirtable Agent\nAutoGPT\nBabyAGI\nCSV Agent\nConversational Agent\nConversational Retrieval Agent\nMistralAI Tool Agent\nOpenAI Assistant\nOpenAI Function Agent\nOpenAI Tool Agent\nReAct Agent Chat\nReAct Agent LLM\nTool Agent\nXML Agent\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nTool Agent\n\nAgent that uses Function Calling to pick the tools and args to call.\n\nTool Agent Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nReAct Agent LLM\nNext\nXML Agent\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "ReAct Agent LLM | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/agents/react-agent-llm",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nAirtable Agent\nAutoGPT\nBabyAGI\nCSV Agent\nConversational Agent\nConversational Retrieval Agent\nMistralAI Tool Agent\nOpenAI Assistant\nOpenAI Function Agent\nOpenAI Tool Agent\nReAct Agent Chat\nReAct Agent LLM\nTool Agent\nXML Agent\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nReAct Agent LLM\n\nAgent that uses the ReAct (Reasoning and Acting) logic to decide what action to take, optimized to be used with Non Chat Models.\n\nReAct Agent LLM Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nReAct Agent Chat\nNext\nTool Agent\n\nLast updated 2 days ago\n\nEdit on GitHub"
  },
  {
    "title": "ReAct Agent Chat | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/agents/react-agent-chat",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nAirtable Agent\nAutoGPT\nBabyAGI\nCSV Agent\nConversational Agent\nConversational Retrieval Agent\nMistralAI Tool Agent\nOpenAI Assistant\nOpenAI Function Agent\nOpenAI Tool Agent\nReAct Agent Chat\nReAct Agent LLM\nTool Agent\nXML Agent\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nReAct Agent Chat\n\nAgent that uses the ReAct (Reasoning and Acting) logic to decide what action to take, optimized to be used with Chat Models.\n\nReAct Agent Chat Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nOpenAI Tool Agent\nNext\nReAct Agent LLM\n\nLast updated 2 days ago\n\nEdit on GitHub"
  },
  {
    "title": "OpenAI Assistant | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/agents/openai-assistant",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nAirtable Agent\nAutoGPT\nBabyAGI\nCSV Agent\nConversational Agent\nConversational Retrieval Agent\nMistralAI Tool Agent\nOpenAI Assistant\nOpenAI Function Agent\nOpenAI Tool Agent\nReAct Agent Chat\nReAct Agent LLM\nTool Agent\nXML Agent\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nOpenAI Assistant\n\nAn agent that uses OpenAI Assistant API to pick the tool and args to call.\n\nOpenAI Assistant\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nMistralAI Tool Agent\nNext\nOpenAI Function Agent\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "OpenAI Function Agent | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/agents/openai-function-agent",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nAirtable Agent\nAutoGPT\nBabyAGI\nCSV Agent\nConversational Agent\nConversational Retrieval Agent\nMistralAI Tool Agent\nOpenAI Assistant\nOpenAI Function Agent\nOpenAI Tool Agent\nReAct Agent Chat\nReAct Agent LLM\nTool Agent\nXML Agent\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nOpenAI Function Agent\n\nDeprecating Node.\n\nPrevious\nOpenAI Assistant\nNext\nOpenAI Tool Agent\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "OpenAI Tool Agent | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/agents/openai-tool-agent",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nAirtable Agent\nAutoGPT\nBabyAGI\nCSV Agent\nConversational Agent\nConversational Retrieval Agent\nMistralAI Tool Agent\nOpenAI Assistant\nOpenAI Function Agent\nOpenAI Tool Agent\nReAct Agent Chat\nReAct Agent LLM\nTool Agent\nXML Agent\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nOpenAI Tool Agent\n\nDeprecating Node.\n\nPrevious\nOpenAI Function Agent\nNext\nReAct Agent Chat\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Conversational Retrieval Agent | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/agents/conversational-retrieval-agent",
    "html": "An error occurred\n\nSorry, an unexpected error has occurred. Please try again later.\n\nRetry"
  },
  {
    "title": "MistralAI Tool Agent | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/agents/mistralai-tool-agent",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nAirtable Agent\nAutoGPT\nBabyAGI\nCSV Agent\nConversational Agent\nConversational Retrieval Agent\nMistralAI Tool Agent\nOpenAI Assistant\nOpenAI Function Agent\nOpenAI Tool Agent\nReAct Agent Chat\nReAct Agent LLM\nTool Agent\nXML Agent\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nMistralAI Tool Agent\n\nDeprecating Node.\n\nPrevious\nConversational Retrieval Agent\nNext\nOpenAI Assistant\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Conversational Agent | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/agents/conversational-agent",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nAirtable Agent\nAutoGPT\nBabyAGI\nCSV Agent\nConversational Agent\nConversational Retrieval Agent\nMistralAI Tool Agent\nOpenAI Assistant\nOpenAI Function Agent\nOpenAI Tool Agent\nReAct Agent Chat\nReAct Agent LLM\nTool Agent\nXML Agent\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nConversational Agent\n\nConversational agent for a chat model. It will utilize chat specific prompts.\n\nConversational Agent Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nCSV Agent\nNext\nConversational Retrieval Agent\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "CSV Agent | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/agents/csv-agent",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nAirtable Agent\nAutoGPT\nBabyAGI\nCSV Agent\nConversational Agent\nConversational Retrieval Agent\nMistralAI Tool Agent\nOpenAI Assistant\nOpenAI Function Agent\nOpenAI Tool Agent\nReAct Agent Chat\nReAct Agent LLM\nTool Agent\nXML Agent\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nCSV Agent\n\nAgent used to to answer queries on CSV data.\n\nCSV Agent Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nBabyAGI\nNext\nConversational Agent\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "BabyAGI | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/agents/babyagi",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nAirtable Agent\nAutoGPT\nBabyAGI\nCSV Agent\nConversational Agent\nConversational Retrieval Agent\nMistralAI Tool Agent\nOpenAI Assistant\nOpenAI Function Agent\nOpenAI Tool Agent\nReAct Agent Chat\nReAct Agent LLM\nTool Agent\nXML Agent\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nBabyAGI\n\nTask Driven Autonomous Agent which creates new task and reprioritizes task list based on objective\n\nBabyAGI Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nAutoGPT\nNext\nCSV Agent\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Airtable Agent | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/agents/airtable-agent",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nAirtable Agent\nAutoGPT\nBabyAGI\nCSV Agent\nConversational Agent\nConversational Retrieval Agent\nMistralAI Tool Agent\nOpenAI Assistant\nOpenAI Function Agent\nOpenAI Tool Agent\nReAct Agent Chat\nReAct Agent LLM\nTool Agent\nXML Agent\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAirtable Agent\n\nAgent used to to answer queries on Airtable table.\n\nAirtable Agent Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nAgents\nNext\nAutoGPT\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "AutoGPT | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/agents/autogpt",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nAirtable Agent\nAutoGPT\nBabyAGI\nCSV Agent\nConversational Agent\nConversational Retrieval Agent\nMistralAI Tool Agent\nOpenAI Assistant\nOpenAI Function Agent\nOpenAI Tool Agent\nReAct Agent Chat\nReAct Agent LLM\nTool Agent\nXML Agent\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAutoGPT\n\nAutonomous agent with chain of thoughts for self-guided task completion.\n\nAutoGPT Node\n\nThis section is a work in progress. We appreciate any help you can provide in completing this section. Please check our Contribution Guide to get started.\n\nPrevious\nAirtable Agent\nNext\nBabyAGI\n\nLast updated 16 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Agents | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain/agents",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nAirtable Agent\nAutoGPT\nBabyAGI\nCSV Agent\nConversational Agent\nConversational Retrieval Agent\nMistralAI Tool Agent\nOpenAI Assistant\nOpenAI Function Agent\nOpenAI Tool Agent\nReAct Agent Chat\nReAct Agent LLM\nTool Agent\nXML Agent\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAgents\n\nBy themselves, language models can't take actions - they just output text.\n\nAgents are systems that use an LLM as a reasoning enginer to determine which actions to take and what the inputs to those actions should be. The results of those actions can then be fed back into the agent and it determine whether more actions are needed, or whether it is okay to finish.\n\nAvailable Agents:\n\nAirtable Agent\n\nAutoGPT\n\nBabyAGI\n\nCSV Agent\n\nConversational Agent\n\nConversational Retrieval Agent\n\nMistralAI Tool Agent\n\nOpenAI Assistant\n\nOpenAI Function Agent\n\nOpenAI Tool Agent\n\nReAct Agent Chat\n\nReAct Agent LLM\n\nTool Agent\n\nXML Agent\n\nPrevious\nLangChain\nNext\nAirtable Agent\n\nLast updated 9 days ago\n\nEdit on GitHub"
  },
  {
    "title": "LangChain | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations/langchain",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nAgents\nCache\nChains\nChat Models\nDocument Loaders\nEmbeddings\nLLMs\nMemory\nModeration\nOutput Parsers\nPrompts\nRecord Managers\nRetrievers\nText Splitters\nTools\nVector Stores\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nLangChain\n\nLangChain is a framework for developing applications powered by language models. It simplifies the process of creating generative AI application, connecting data sources, vectors, memories with LLMs.\n\nFlowise complements LangChain by offering a visual interface. Here, nodes are organized into distinct sections, making it easier to build workflows.\n\nLangChain Sections:\n\nAgents\n\nCache\n\nChains\n\nChat Models\n\nDocument Loaders\n\nEmbeddings\n\nLLMs\n\nMemory\n\nModeration\n\nOutput Parsers\n\nPrompts\n\nRecord Managers\n\nRetrievers\n\nText Splitters\n\nTools\n\nUtilities\n\nVector Stores\n\nPrevious\nIntegrations\nNext\nAgents\n\nLast updated 9 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Rate Limit | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/rate-limit",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nDeployment\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nRate Limit\n\nWhen you share your chatflow to public with no API authorization through API or embedded chat, anybody can access the flow. To prevent spamming, you can set the rate limit on your chatflow.\n\nMessage Limit per Duration: How many messages can be received in a specific duration. Ex: 20\n\nDuration in Seconds: The specified duration. Ex: 60\n\nLimit Message: What message to return when the limit is exceeded. Ex: Quota Exceeded\n\nUsing the example above, that means only 20 messages are allowed to be received in 60 seconds. The rate limitation is tracked by IP-address. If you have deployed Flowise on cloud service, you'll have to set NUMBER_OF_PROXIES env variable.\n\nCloud-Hosted Rate Limit Setup Guide\n\nCloud Host Flowise: Start by hosting Flowise in the cloud.\n\nSet Environment Variable: Create an environment variable named NUMBER_OF_PROXIES and set its value to 0 in your hosting environment.\n\nRestart Cloud-Hosted Flowise Service: This enables Flowise to apply changes of environment variables.\n\nCheck IP Address: To verify the IP address, access the following URL: {{hosted_url}}/api/v1/ip. You can do this either by entering the URL into your web browser or by making an API request.\n\nCompare IP Address After making the request, compare the IP address returned to your current IP address. You can find your current IP address by visiting either of these websites:\n\nhttp://ip.nfriedly.com/\n\nhttps://api.ipify.org/\n\nIncorrect IP Address: If the returned IP address does not match your current IP address, increase NUMBER_OF_PROXIES by 1 and restart Cloud-Hosted Flowise. Repeat this process until the IP address matches your own.\n\nPrevious\nDatabases\nNext\nIntegrations\n\nLast updated 3 months ago\n\nEdit on GitHub"
  },
  {
    "title": "Integrations | FlowiseAI",
    "url": "https://docs.flowiseai.com/integrations",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nLangChain\nLlamaIndex\nUtilities\nExternal Integrations\nMigration Guide\nUse Cases\nPowered by GitBook\nIntegrations\n\nIn Flowise, nodes are referred to as integrations. Similar to LEGO, you can build a customized LLM ochestration flow, a chatbot, an agent with all the integrations available in Flowise.\n\nLangChain Nodes\n\nAgents\n\nCache\n\nChains\n\nChat Models\n\nDocument Loaders\n\nEmbeddings\n\nLLMs\n\nMemory\n\nModeration\n\nOutput Parsers\n\nPrompts\n\nRecord Managers\n\nRetrievers\n\nText Splitters\n\nTools\n\nUtilities\n\nVector Stores\n\nLlamaIndex Nodes\n\nAgents\n\nChat Models\n\nEmbeddings\n\nEngine\n\nResponse Synthesizer\n\nTools\n\nVector Stores\n\nExternal Integrations\n\nZapier Zaps\n\nPrevious\nRate Limit\nNext\nLangChain\n\nLast updated 16 days ago\n\nLangChain Nodes\nLlamaIndex Nodes\nExternal Integrations\nEdit on GitHub"
  },
  {
    "title": "Environment Variables | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/environment-variables",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nDeployment\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nEnvironment Variables\n\nFlowise support different environment variables to configure your instance. You can specify the following variables in the .env file inside packages/server folder. Refer to .env.example file.\n\nVariable\tDescription\tType\tDefault\n\n\nPORT\n\n\t\n\nThe HTTP port Flowise runs on\n\n\t\n\nNumber\n\n\t\n\n3000\n\n\n\n\nFLOWISE_USERNAME\n\n\t\n\nUsername to login\n\n\t\n\nString\n\n\t\n\n\n\n\nFLOWISE_PASSWORD\n\n\t\n\nPassword to login\n\n\t\n\nString\n\n\t\n\n\n\n\nFLOWISE_FILE_SIZE_LIMIT\n\n\t\n\nMaximum file size when uploading\n\n\t\n\nString\n\n\t\n\n50mb\n\n\n\n\nAPIKEY_PATH\n\n\t\n\nLocation where API keys are saved\n\n\t\n\nString\n\n\t\n\nFlowise/packages/server\n\n\n\n\nNUMBER_OF_PROXIES\n\n\t\n\nRate Limit Proxy\n\n\t\n\nNumber\n\n\t\n\n\n\n\nCORS_ORIGINS\n\n\t\n\nThe allowed origins for all cross-origin HTTP calls\n\n\t\n\nString\n\n\t\n\n\n\n\nIFRAME_ORIGINS\n\n\t\n\nThe allowed origins for iframe src embedding\n\n\t\n\nString\n\n\t\n\nDatabase\nVariable\tDescription\tType\tDefault\n\n\nDATABASE_TYPE\n\n\t\n\nType of database to store the flowise data\n\n\t\n\nEnum String: sqlite, mysql, postgres\n\n\t\n\nsqlite\n\n\n\n\nDATABASE_PATH\n\n\t\n\nLocation where database is saved (When DATABASE_TYPE is sqlite)\n\n\t\n\nString\n\n\t\n\nyour-home-dir/.flowise\n\n\n\n\nDATABASE_HOST\n\n\t\n\nHost URL or IP address (When DATABASE_TYPE is not sqlite)\n\n\t\n\nString\n\n\t\n\n\n\n\nDATABASE_PORT\n\n\t\n\nDatabase port (When DATABASE_TYPE is not sqlite)\n\n\t\n\nString\n\n\t\n\n\n\n\nDATABASE_USER\n\n\t\n\nDatabase username (When DATABASE_TYPE is not sqlite)\n\n\t\n\nString\n\n\t\n\n\n\n\nDATABASE_PASSWORD\n\n\t\n\nDatabase password (When DATABASE_TYPE is not sqlite)\n\n\t\n\nString\n\n\t\n\n\n\n\nDATABASE_NAME\n\n\t\n\nDatabase name (When DATABASE_TYPE is not sqlite)\n\n\t\n\nString\n\n\t\n\n\n\n\nDATABASE_SSL\n\n\t\n\nDatabase SSL is required (When DATABASE_TYPE is not sqlite)\n\n\t\n\nBoolean: true or false\n\n\t\n\nfalse\n\nLangSmith Tracing\n\nFlowise supports LangSmith tracing with the following env variables:\n\nVariable\tDescription\tType\n\n\nLANGCHAIN_TRACING_V2\n\n\t\n\nTurn LangSmith tracing ON or OFF\n\n\t\n\nEnum String: true, false\n\n\n\n\nLANGCHAIN_ENDPOINT\n\n\t\n\nLangSmith endpoint\n\n\t\n\nString\n\n\n\n\nLANGCHAIN_API_KEY\n\n\t\n\nLangSmith API Key\n\n\t\n\nString\n\n\n\n\nLANGCHAIN_PROJECT\n\n\t\n\nProject to trace on LangSmith\n\n\t\n\nString\n\nWatch how connect Flowise and LangSmith\n\nBuilt-In and External Dependencies\n\nFor security reasons, by default Tool Function only allow certain dependencies. It's possible to lift that restriction for built-in and external modules by setting the following environment variables:\n\nVariable\tDescription\t\n\n\nTOOL_FUNCTION_BUILTIN_DEP\n\n\t\n\nNodeJS built-in modules to be used for Tool Function\n\n\t\n\nString\n\n\n\n\nTOOL_FUNCTION_EXTERNAL_DEP\n\n\t\n\nExternal modules to be used for Tool Function\n\n\t\n\nString\n\n.env\nCopy\n# Allows usage of all builtin modules\n\nTOOL_FUNCTION_BUILTIN_DEP=*\n\n\n\n# Allows usage of only fs\n\nTOOL_FUNCTION_BUILTIN_DEP=fs\n\n\n\n# Allows usage of only crypto and fs\n\nTOOL_FUNCTION_BUILTIN_DEP=crypto,fs\n\n\n\n# Allow usage of external npm modules.\n\nTOOL_FUNCTION_EXTERNAL_DEP=axios,moment\nDebug and Logs\nVariable\tDescription\tType\t\n\n\nDEBUG\n\n\t\n\nPrint logs from components\n\n\t\n\nBoolean\n\n\t\n\n\n\n\nLOG_PATH\n\n\t\n\nLocation where log files are stored\n\n\t\n\nString\n\n\t\n\nFlowise/packages/server/logs\n\n\n\n\nLOG_LEVEL\n\n\t\n\nDifferent levels of logs\n\n\t\n\nEnum String: error, info, verbose, debug\n\n\t\n\ninfo\n\nDEBUG: if set to true, will print logs to terminal/console:\n\nLOG_LEVEL: Different log levels for loggers to be saved. Can be error, info, verbose, or debug. By default it is set to info, only logger.info will be saved to the log files. If you want to have complete details, set to debug.\n\nserver-requests.log.jsonl - logs every request sent to Flowise\nserver.log - logs general actions on Flowise\nserver-error.log - logs error with stack trace\nCredential\n\nFlowise store your third party API keys as encrypted credentials using an encryption key.\n\nBy default, a random encryption key will be generated when starting up the application and stored under a file path. This encryption key is then retrieved everytime to decrypt the credentials used within a chatflow. For example, your OpenAI API key, Pinecone API key, etc.\n\nVariable\tDescription\tType\t\n\n\nSECRETKEY_PATH\n\n\t\n\nLocation where encryption key (used to encrypt/decrypt credentials) is saved\n\n\t\n\nString\n\n\t\n\nFlowise/packages/server\n\n\n\n\nFLOWISE_SECRETKEY_OVERWRITE\n\n\t\n\nEncryption key to be used instead of the key stored in SECRETKEY_PATH\n\n\t\n\nString\n\n\t\n\nFor some reasons, sometimes encryption key might be re-generated or the stored path was changed, this will cause errors like - Credentials could not be decrypted.\n\nTo avoid this, you can set your own encryption key as FLOWISE_SECRETKEY_OVERWRITE, so that the same encryption key will be used everytime. There is no restriction on the format, you can set it as any text that you want, or the same as your FLOWISE_PASSWORD.\n\nCredential API Key returned from the UI is not the same length as your original Api Key that you have set. This is a fake prefix string that prevents network spoofing, that's why we are not returning the Api Key back to UI. However, the correct Api Key will be retrieved and used during your interaction with the chatflow.\n\nModels\n\nIn some cases, you might want to use custom model on the existing Chat Model and LLM nodes, or restrict access to only certain models.\n\nBy default, Flowise pulls the model list from here. However user can create their own models.json file and specify the file path:\n\nVariable\tDescription\tType\tDefault\n\n\nMODEL_LIST_CONFIG_JSON\n\n\t\n\nLink to load list of models from your models.json config file\n\n\t\n\nString\n\n\t\n\nhttps://raw.githubusercontent.com/FlowiseAI/Flowise/main/packages/components/models.json\n\nStorage\n\nFlowise store the following files under a local path folder by default.\n\nFiles uploaded on Document Loaders/Document Store\n\nImage/Audio uploads from chat\n\nImages/Files from Assistant\n\nFiles from Vector Upsert API\n\nUser can specify STORAGE_TYPE to use AWS S3 or local path\n\nVariable\tDescription\tType\tDefault\n\n\nSTORAGE_TYPE\n\n\t\n\nType of storage for uploaded files. default is local\n\n\t\n\nEnum String: s3, local\n\n\t\n\nlocal\n\n\n\n\nBLOB_STORAGE_PATH\n\n\t\n\nLocal folder path where uploaded files are stored when STORAGE_TYPE is local\n\n\t\n\nString\n\n\t\n\nyour-home-dir/.flowise/storage\n\n\n\n\nS3_STORAGE_BUCKET_NAME\n\n\t\n\nBucket name to hold the uploaded files when STORAGE_TYPE is s3\n\n\t\n\nString\n\n\t\n\n\n\n\nS3_STORAGE_ACCESS_KEY_ID\n\n\t\n\nAWS Access Key\n\n\t\n\nString\n\n\t\n\n\n\n\nS3_STORAGE_SECRET_ACCESS_KEY\n\n\t\n\nAWS Secret Key\n\n\t\n\nString\n\n\t\n\n\n\n\nS3_STORAGE_REGION\n\n\t\n\nRegion for S3 bucket\n\n\t\n\nString\n\n\t\n\nHow to set environment variables\nNPM\n\nYou can set all these variables when running Flowise using npx. For example:\n\nCopy\nnpx flowise start --PORT=3000 --DEBUG=true\nDocker\n\nYou can set all these variables in the .env file inside docker folder. Refer to .env.example file.\n\nRender\nRailway\nPrevious\nZeabur\nNext\nDatabases\n\nLast updated 14 days ago\n\nDatabase\nLangSmith Tracing\nBuilt-In and External Dependencies\nDebug and Logs\nCredential\nModels\nStorage\nHow to set environment variables\nNPM\nDocker\nRender\nRailway\nEdit on GitHub"
  },
  {
    "title": "Databases | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/databases",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nDeployment\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nDatabases\n\nFlowise supports 3 database types:\n\nSQLite\n\nMySQL\n\nPostgreSQL\n\nSQLite will be the default database. These databases can be configured with following env variables:\n\nSQLite\nCopy\nDATABASE_TYPE=sqlite\n\nDATABASE_PATH=/root/.flowise #your preferred location\n\nA database.sqlite file will be created and saved in the path specified by DATABASE_PATH. If not specified, the default store path will be in your home directory -> .flowise\n\nMySQL\nCopy\nDATABASE_TYPE=mysql\n\nDATABASE_PORT=3306\n\nDATABASE_HOST=localhost\n\nDATABASE_NAME=flowise\n\nDATABASE_USER=user\n\nDATABASE_PASSWORD=123\nPostgreSQL\nCopy\nDATABASE_TYPE=postgres\n\nDATABASE_PORT=5432\n\nDATABASE_HOST=localhost\n\nDATABASE_NAME=flowise\n\nDATABASE_USER=user\n\nDATABASE_PASSWORD=123\n\nPGSSLMODE=require\n\nIf none of the env variables is specified, SQLite will be the fallback database choice.\n\nSynchronize in Production\n\nFlowise uses Typeorm to configure database connection. By default, synchronize is set to true. This indicates if database schema should be auto created on every application launch.\n\nHowever, we have to be careful with this option and don't use this in production - otherwise you can lose production data. This option is useful during debug and development.\n\nTo override the value, set the following env variable\n\nCopy\nOVERRIDE_DATABASE=false\nTutorial: How to use Flowise databases SQLite and MySQL/MariaDB\nPrevious\nEnvironment Variables\nNext\nRate Limit\n\nLast updated 1 month ago\n\nSQLite\nMySQL\nPostgreSQL\nSynchronize in Production\nTutorial: How to use Flowise databases SQLite and MySQL/MariaDB\nEdit on GitHub"
  },
  {
    "title": "Zeabur | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/deployment/zeabur",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nDeployment\nAWS\nAzure\nDigital Ocean\nElestio\nGCP\nHugging Face\nKubernetes using Helm\nRailway\nRender\nReplit\nRepoCloud\nSealos\nZeabur\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nZeabur\n\nClick the following prebuilt template or the button below.\n\nClick Deploy\n\nSelect your favorite region and continue\n\nYou will be redirected to Zeabur's dashboard and you will see the deployment process\n\nTo add authorization, navigate to Variables tab and add:\n\nFLOWISE_USERNAME\n\nFLOWISE_PASSWORD\n\nThere are list of env variables you can configure. Refer to Environment Variables\n\nThat's it! You now have a deployed Flowise on Zeabur 🎉🎉\n\nPersistent Volume\n\nZeabur will automatically create a persistent volume for you so you don't have to worry about it.\n\nPrevious\nSealos\nNext\nEnvironment Variables\n\nLast updated 2 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Replit | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/deployment/replit",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nDeployment\nAWS\nAzure\nDigital Ocean\nElestio\nGCP\nHugging Face\nKubernetes using Helm\nRailway\nRender\nReplit\nRepoCloud\nSealos\nZeabur\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nReplit\n\nSign in to Replit\n\nCreate a new Repl. Select Node.js as Template and fill in your preferred Title.\n\nAfter a new Repl is created, on the left hand side bar, click Secret:\n\nCreate 3 Secrets to skip Chromium download for Puppeteer and Playwright libraries.\n\nSecrets\tValue\n\n\nPLAYWRIGHT_SKIP_BROWSER_DOWNLOAD\n\n\t\n\n1\n\n\n\n\nPUPPETEER_SKIP_DOWNLOAD\n\n\t\n\ntrue\n\n\n\n\nPUPPETEER_SKIP_CHROMIUM_DOWNLOAD\n\n\t\n\ntrue\n\nYou can now switch to Shell tab\n\nType in npm install -g flowise into the Shell terminal window. If you are having error about incompatible node version, use the following command yarn global add flowise --ignore-engines\n\nThen followed by npx flowise start\n\nYou should now be able to see Flowise on Replit!\n\nIf you would like to turn on app level authorization, change the command to:\n\nCopy\nnpx flowise start --FLOWISE_USERNAME=user --FLOWISE_PASSWORD=1234\n\nYou will now see a login page. Simply login with the username and password you've set.\n\nPrevious\nRender\nNext\nSealos\n\nLast updated 2 months ago\n\nEdit on GitHub"
  },
  {
    "title": "Sealos | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/deployment/sealos",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nDeployment\nAWS\nAzure\nDigital Ocean\nElestio\nGCP\nHugging Face\nKubernetes using Helm\nRailway\nRender\nReplit\nRepoCloud\nSealos\nZeabur\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nSealos\n\nClick the following prebuilt template\n\nAdd authorization\n\nFLOWISE_USERNAME\n\nFLOWISE_PASSWORD\n\nClick \"Deploy Application\" on the template page to start deployment.\n\nOnce deployment concludes, click \"Details\" to navigate to the application's details.\n\nWait for the application's status to switch to running. Subsequently, click on the external link to open the application's Web interface directly through the external domain.\n\nPersistent Volume\n\nClick \"Update\" top-right on the app details page, then click \"Advanced\" -> \"Add volume\", Fill in the value of \"mount path\": /root/.flowise.\n\nTo wrap up, click the \"Deploy\" button.\n\nNow try creating a flow and save it in Flowise. Then try restarting service or redeploy, you should still be able to see the flow you have saved previously.\n\nPrevious\nReplit\nNext\nZeabur\n\nLast updated 5 months ago\n\nEdit on GitHub"
  },
  {
    "title": "Render | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/deployment/render",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nDeployment\nAWS\nAzure\nDigital Ocean\nElestio\nGCP\nHugging Face\nKubernetes using Helm\nRailway\nRender\nReplit\nRepoCloud\nSealos\nZeabur\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nRender\n\nFork Flowise Official Repository\n\nVisit your github profile to assure you have successfully made a fork\n\nSign in to Render\n\nClick New +\n\nSelect Web Service\n\nConnect Your GitHub Account\n\nSelect your forked Flowise repo and click Connect\n\nFill in your preferred Name and Region.\n\nSelect Docker as your Runtime\n\nSelect an Instance\n\n(Optional) Add app level authorization, click Advanced and add Environment Variable\n\nFLOWISE_USERNAME\n\nFLOWISE_PASSWORD\n\nAdd NODE_VERSION with value 18.18.1 as the node version to run the instance.\n\nThere are list of env variables you can configure. Refer to Environment Variables\n\nClick Create Web Service\n\nNavigate to the deployed URL and that's it 🚀🚀\n\nPersistent Disk\n\nThe default filesystem for services running on Render is ephemeral. Flowise data isn’t persisted across deploys and restarts. To solve this issue, we can use Render Disk.\n\nOn the left hand side bar, click Disks\n\nName your disk, and specify the Mount Path to /opt/render/.flowise\n\nClick the Environment section, and add these new environment variables:\n\nDATABASE_PATH - /opt/render/.flowise\n\nAPIKEY_PATH - /opt/render/.flowise\n\nLOG_PATH - /opt/render/.flowise/logs\n\nSECRETKEY_PATH - /opt/render/.flowise\n\nBLOB_STORAGE_PATH - /opt/render/.flowise/storage\n\nClick Manual Deploy then select Clear build cache & deploy\n\nNow try creating a flow and save it in Flowise. Then try restarting service or redeploy, you should still be able to see the flow you have saved previously.\n\nWatch how to deploy to Render\n\nPrevious\nRailway\nNext\nReplit\n\nLast updated 3 months ago\n\nEdit on GitHub"
  },
  {
    "title": "Railway | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/deployment/railway",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nDeployment\nAWS\nAzure\nDigital Ocean\nElestio\nGCP\nHugging Face\nKubernetes using Helm\nRailway\nRender\nReplit\nRepoCloud\nSealos\nZeabur\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nRailway\n\nClick the following prebuilt template\n\nClick Deploy Now\n\nChange to your preferred repository name and click Deploy\n\nIf succeeds, you should be able to see a deployed URL\n\nTo add authorization, navigate to Variables tab and add:\n\nFLOWISE_USERNAME\n\nFLOWISE_PASSWORD\n\nThere are list of env variables you can configure. Refer to Environment Variables\n\nThat's it! You now have a deployed Flowise on Railway 🎉🎉\n\nPersistent Volume\n\nThe default filesystem for services running on Railway is ephemeral. Flowise data isn’t persisted across deploys and restarts. To solve this issue, we can use Railway Volume.\n\nTo ease the steps, we have a Railway template with volume mounted: https://railway.app/template/nEGbjR\n\nJust click Deploy and fill in the Env Variables like below:\n\nDATABASE_PATH - /opt/railway/.flowise\n\nAPIKEY_PATH - /opt/railway/.flowise\n\nLOG_PATH - /opt/railway/.flowise/logs\n\nSECRETKEY_PATH - /opt/railway/.flowise\n\nBLOB_STORAGE_PATH - /opt/railway/.flowise/storage\n\nNow try creating a flow and save it in Flowise. Then try restarting service or redeploy, you should still be able to see the flow you have saved previously.\n\nPrevious\nHugging Face\nNext\nRender\n\nLast updated 2 months ago\n\nEdit on GitHub"
  },
  {
    "title": "Hugging Face | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/deployment/hugging-face",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nDeployment\nAWS\nAzure\nDigital Ocean\nElestio\nGCP\nHugging Face\nKubernetes using Helm\nRailway\nRender\nReplit\nRepoCloud\nSealos\nZeabur\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nHugging Face\nCreate a new space\n\nSign in to Hugging Face\n\nStart creating a new Space with your preferred name.\n\nSelect Docker as Space SDK and choose Blank as the Docker template.\n\nSelect CPU basic ∙ 2 vCPU ∙ 16GB ∙ FREE as Space hardware.\n\nClick Create Space.\n\nSet the environment variables\n\nGo to Settings of your new space and find the Variables and Secrets section\n\nClick on New variable and add the name as PORT with value 7860\n\nClick on Save\n\n(Optional) Click on New secret\n\n(Optional) Fill in with your environment variables, such as database credentials, file paths, etc. You can check for valid fields in the .env.example here\n\nCreate a Dockerfile\n\nAt the files tab, click on button + Add file and click on Create a new file (or Upload files if you prefer to)\n\nCreate a file called Dockerfile and paste the following:\n\nCopy\nFROM node:18-alpine\n\nUSER root\n\n\n\n# Arguments that can be passed at build time\n\nARG FLOWISE_PATH=/usr/local/lib/node_modules/flowise\n\nARG BASE_PATH=/root/.flowise\n\nARG DATABASE_PATH=$BASE_PATH\n\nARG APIKEY_PATH=$BASE_PATH\n\nARG SECRETKEY_PATH=$BASE_PATH\n\nARG LOG_PATH=$BASE_PATH/logs\n\nARG BLOB_STORAGE_PATH=$BASE_PATH/storage\n\n\n\n# Install dependencies\n\nRUN apk add --no-cache git python3 py3-pip make g++ build-base cairo-dev pango-dev chromium\n\n\n\nENV PUPPETEER_SKIP_DOWNLOAD=true\n\nENV PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium-browser\n\n\n\n# Install Flowise globally\n\nRUN npm install -g flowise\n\n\n\n# Configure Flowise directories using the ARG\n\nRUN mkdir -p $LOG_PATH $FLOWISE_PATH/uploads && chmod -R 777 $LOG_PATH $FLOWISE_PATH\n\n\n\nWORKDIR /data\n\n\n\nCMD [\"npx\", \"flowise\", \"start\"]\n\nClick on Commit file to \nmain\n and it will start to build your app.\n\nDone 🎉\n\nWhen the build finishes you can click on the App tab to see your app running.\n\nPrevious\nGCP\nNext\nRailway\n\nLast updated 2 months ago\n\nCreate a new space\nSet the environment variables\nCreate a Dockerfile\nDone 🎉\nEdit on GitHub"
  },
  {
    "title": "GCP | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/deployment/gcp",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nDeployment\nAWS\nAzure\nDigital Ocean\nElestio\nGCP\nHugging Face\nKubernetes using Helm\nRailway\nRender\nReplit\nRepoCloud\nSealos\nZeabur\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nGCP\nPrerequisites\n\nNotedown your Google Cloud [ProjectId]\n\nInstall Git\n\nInstall the Google Cloud CLI\n\nInstall Docker Desktop\n\nSetup Kubernetes Cluster\n\nCreate a Kubernetes Cluster if you don't have one.\n\nClick `Clusters` to create one.\n\nName the Cluster, choose the right resource location, use Autopilot mode and keep all other default configs.\n\nOnce the Cluster is created, Click the 'Connect' menu from the actions menu\n\nCopy the command and paste into your terminal and hit enter to connect your cluster.\n\nRun the below command and select correct context name, which looks like gke_[ProjectId]_[DataCenter]_[ClusterName]\n\nCopy\nkubectl config get-contexts\n\nSet the current context\n\nCopy\nkubectl config use-context gke_[ProjectId]_[DataCenter]_[ClusterName]\nBuild and Push the Docker image\n\nRun the following commands to build and push the Docker image to GCP Container Registry.\n\nClone the Flowise\n\nCopy\ngit clone https://github.com/FlowiseAI/Flowise.git\n\nBuild the Flowise\n\nCopy\ncd Flowise\n\npnpm install\n\npnpm build\n\nUpdate the Dockerfile file a little.\n\nSpecify the platform of nodejs\n\nCopy\nFROM --platform=linux/amd64 node:18-alpine\n\nAdd python3, make and g++ to install\n\nCopy\nRUN apk add --no-cache python3 make g++\n\nBuild as Docker image, make sure the Docker desktop app is running\n\nCopy\ndocker build -t gcr.io/[ProjectId]/flowise:dev .\n\nPush the Docker image to GCP container registry.\n\nCopy\ndocker push gcr.io/[ProjectId]/flowise:dev\nDeployment to GCP\n\nCreate a yamls root folder in the project.\n\nAdd the deployment.yaml file into that folder.\n\nCopy\n# deployment.yaml\n\napiVersion: apps/v1\n\nkind: Deployment\n\nmetadata:\n\n  name: flowise\n\n  labels:\n\n    app: flowise\n\nspec:\n\n  selector:\n\n    matchLabels:\n\n      app: flowise\n\n  replicas: 1\n\n  template:\n\n    metadata:\n\n      labels:\n\n        app: flowise\n\n    spec:\n\n      containers:\n\n      - name: flowise\n\n        image: gcr.io/[ProjectID]/flowise:dev\n\n        imagePullPolicy: Always\n\n        resources: \n\n          requests:\n\n            cpu: \"1\"\n\n            memory: \"1Gi\"\n\nAdd the service.yaml file into that folder.\n\nCopy\n# service.yaml\n\napiVersion: \"v1\"\n\nkind: \"Service\"\n\nmetadata:\n\n  name: \"flowise-service\"\n\n  namespace: \"default\"\n\n  labels:\n\n    app: \"flowise\"\n\nspec:\n\n  ports:\n\n  - protocol: \"TCP\"\n\n    port: 80\n\n    targetPort: 3000\n\n  selector:\n\n    app: \"flowise\"\n\n  type: \"LoadBalancer\"\n\n\nIt will be look like below.\n\nDeploy the yaml files by running following commands.\n\nCopy\nkubectl apply -f yamls/deployment.yaml\n\nkubectl apply -f yamls/service.yaml\n\nGo to Workloads in the GCP, you can see your pod is running.\n\nGo to Services & Ingress, you can click the Endpoint where the Flowise is hosted.\n\nCongratulations!\n\nYou have successfully hosted the Flowise apps on GCP 🥳\n\nTimeout\n\nBy default, there is a 30 seconds timeout assigned to the proxy by GCP. This caused issue when the response is taking longer than 30 seconds threshold to return. In order to fix this issue, make the following changes to YAML files:\n\nNote: To set the timeout to be 10 minutes (for example) -- we specify 600 seconds below.\n\nCreate a backendconfig.yaml file with the following content:\n\nCopy\napiVersion: cloud.google.com/v1\n\nkind: BackendConfig\n\nmetadata:\n\n  name: flowise-backendconfig\n\n  namespace: your-namespace\n\nspec:\n\n  timeoutSec: 600\n\nIssue: kubectl apply -f backendconfig.yaml\n\nUpdate your service.yaml file with the following reference to the BackendConfig:\n\nCopy\napiVersion: v1\n\nkind: Service\n\nmetadata:\n\n  annotations:\n\n    cloud.google.com/backend-config: '{\"default\": \"flowise-backendconfig\"}'\n\n  name: flowise-service\n\n  namespace: your-namespace\n\n...\n\nIssue: kubectl apply -f service.yaml\n\nPrevious\nDigital Ocean\nNext\nHugging Face\n\nLast updated 2 months ago\n\nPrerequisites\nSetup Kubernetes Cluster\nBuild and Push the Docker image\nDeployment to GCP\nCongratulations!\nTimeout\nEdit on GitHub"
  },
  {
    "title": "Azure | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/deployment/azure",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nDeployment\nAWS\nAzure\nDigital Ocean\nElestio\nGCP\nHugging Face\nKubernetes using Helm\nRailway\nRender\nReplit\nRepoCloud\nSealos\nZeabur\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAzure\nFlowise as Azure App Service with Postgres: Using Terraform\nPrerequisites\n\nAzure Account: Ensure you have an Azure account with an active subscription. If you do not have one, sign up at Azure Portal.\n\nTerraform: Install Terraform CLI on your machine. Download it from Terraform's website.\n\nAzure CLI: Install Azure CLI. Instructions can be found on the Azure CLI documentation page.\n\nSetting Up Your Environment\n\nLogin to Azure: Open your terminal or command prompt and login to Azure CLI using:\n\nCopy\naz login --tenant <Your Subscription ID> --use-device-code \n\nFollow the prompts to complete the login process.\n\nSet Subscription: After logging in, set the Azure subscription using:\n\nCopy\naz account set --subscription <Your Subscription ID>\n\nInitialize Terraform:\n\nCreate a terraform.tfvars file in your Terraform project directory, if it's not already there, and add the following content:\n\nCopy\nsubscription_name = \"subscrpiton_name\"\n\nsubscription_id = \"subscription id\"\n\nproject_name = \"webapp_name\"\n\ndb_username = \"PostgresUserName\"\n\ndb_password = \"strongPostgresPassword\"\n\nflowise_username = \"flowiseUserName\"\n\nflowise_password = \"strongFlowisePassword\"\n\nflowise_secretkey_overwrite = \"longandStrongSecretKey\"\n\nwebapp_ip_rules = [\n\n  {\n\n    name = \"AllowedIP\"\n\n    ip_address = \"X.X.X.X/32\"\n\n    headers = null\n\n    virtual_network_subnet_id = null\n\n    subnet_id = null\n\n    service_tag = null\n\n    priority = 300\n\n    action = \"Allow\"\n\n  }\n\n]\n\npostgres_ip_rules = {\n\n  \"ValbyOfficeIP\" = \"X.X.X.X\"\n\n  // Add more key-value pairs as needed\n\n}\n\nsource_image = \"flowiseai/flowise:latest\"\n\ntagged_image = \"flow:v1\"\n\nReplace the placeholders with actual values for your setup.\n\nThe file tree structure is as follows:\n\nCopy\nflow\n\n├── database.tf\n\n├── main.tf\n\n├── network.tf\n\n├── output.tf\n\n├── providers.tf\n\n├── terraform.tfvars\n\n├── terraform.tfvars.example\n\n├── variables.tf\n\n├── webapp.tf\n\n├── .gitignore // ignore your .tfvars and .lock.hcf, .terraform\n\n\nEach .tf file in the Terraform configuration likely contains a different aspect of the infrastructure as code:\n\n`database.tf` would define the configuration for the Postgres database.\n`main.tf` could be the main configuration file that may include the Azure provider configuration and defines the Azure resource group.\n`network.tf` would include networking resources such as virtual networks, subnets, and network security groups.\n`providers.tf` would define the Terraform providers, such as Azure.\n`variables.tf` would declare variables used across all `.tf` files.\n`webapp.tf` Azure App Services that includes a service plan and linux web app\n\nNote: The .terraform directory is created by Terraform when initializing a project (terraform init) and it contains the plugins and binary files needed for Terraform to run. The .terraform.lock.hcl file is used to record the exact provider versions that are being used to ensure consistent installs across different machines.\n\nNavigate to your Terraform project directory and run:\n\nCopy\nterraform init\n\nThis will initialize Terraform and download the required providers.\n\nConfiguring Terraform Variables\nDeploying with Terraform\n\nPlan the Deployment: Run the Terraform plan command to see what resources will be created:\n\nCopy\nterraform plan\n\nApply the Deployment: If you are satisfied with the plan, apply the changes:\n\nCopy\nterraform apply\n\nConfirm the action when prompted, and Terraform will begin creating the resources.\n\nVerify the Deployment: Once Terraform has completed, it will output any defined outputs such as IP addresses or domain names. Verify that the resources are correctly deployed in your Azure Portal.\n\nAzure Continer Instance: Using Azure Portal UI or Azure CLI\nPrerequisites\n\n(Optional) Install Azure CLI if you'd like to follow the cli based commands\n\nCreate a Container Instance without Persistent Storage\n\nWithout persistent storage your data is kept in memory. This means that on a container restart, all the data that you stored will disappear.\n\nIn Portal\n\nSearch for Container Instances in Marketplace and click Create:\n\nContainer Instances entry in Azure's Marketplace\n\nSelect or create a Resource group, Container name, Region, Image source Other registry, Image type, Image flowiseai/flowise, OS type and Size. Then click \"Next: Networking\" to configure Flowise ports:\n\nFirst page in the Container Instance create wizard\n\nAdd a new port 3000 (TCP) next to the default 80 (TCP). Then Select \"Next: Advanced\":\n\nSecond page in the Container Instance create wizard. It asks for netowrking type and ports.\n\nSet Restart policy to On failure. Next, add 2 Environment variables FLOWISE_USERNAME and FLOWISE_PASSWORD. Add Command override [\"/bin/sh\", \"-c\", \"flowise start\"]. Finally click \"Review + create\":\n\nThird page in the Container Instance create wizard. It asks for restart policy, environment variables and command that runs on container start.\n\nReview final settings and click \"Create\":\n\nFinal review and create page for a Container Instance.\n\nOnce creation is completed, click on \"Go to resource\"\n\nResource creation result page in Azure.\n\nVisit your Flowise instance by copying IP address and adding :3000 as a port:\n\nContainer Instance overview page\nFlowise application deployed as Container Instance\nCreate using Azure CLI\n\nCreate a resource group (if you don't already have one)\n\nCopy\naz group create --name flowise-rg --location \"West US\"\n\nCreate a Container Instance\n\nCopy\naz container create -g flowise-rg \\\n\n\t--name flowise \\\n\n\t--image flowiseai/flowise \\\n\n\t--command-line \"/bin/sh -c 'flowise start'\" \\\n\n\t--environment-variables FLOWISE_USERNAME=flowise-user FLOWISE_PASSWORD=flowise-password \\\n\n\t--ip-address public \\\n\n\t--ports 80 3000 \\\n\n\t--restart-policy OnFailure\n\nVisit the IP address (including port :3000) printed from the output of the above command.\n\nCreate a Container Instance with Persistent Storage\n\nThe creation of a Container Instance with persistent storage is only possible using CLI:\n\nCreate a resource group (if you don't already have one)\n\nCopy\naz group create --name flowise-rg --location \"West US\"\n\nCreate the Storage Account resource (or use existing one) inside above resource group. You can check how to do it here.\n\nInside Azure Storage create new File share. You can check how to do it here.\n\nCreate a Container Instance\n\nCopy\naz container create -g flowise-rg \\\n\n\t--name flowise \\\n\n\t--image flowiseai/flowise \\\n\n\t--command-line \"/bin/sh -c 'flowise start'\" \\\n\n\t--environment-variables FLOWISE_USERNAME=flowise-user FLOWISE_PASSWORD=flowise-password DATABASE_PATH=/opt/flowise/.flowise APIKEY_PATH=/opt/flowise/.flowise SECRETKEY_PATH=/opt/flowise/.flowise LOG_PATH=/opt/flowise/.flowise/logs BLOB_STORAGE_PATH=/opt/flowise/.flowise/storage \\\n\n\t--ip-address public \\\n\n\t--ports 80 3000 \\\n\n\t--restart-policy OnFailure \\\n\n\t--azure-file-volume-share-name here goes the name of your File share \\\n\n\t--azure-file-volume-account-name here goes the name of your Storage Account \\\n\n\t--azure-file-volume-account-key here goes the access key to your Storage Account \\\n\n\t--azure-file-volume-mount-path /opt/flowise/.flowise\n\nVisit the IP address (including port :3000) printed from the output of the above command.\n\nFrom now on your data will be stored in an SQLite database which you can find in your File share.\n\nWatch video tutorial on deploying to Azure Container Instance:\n\nPrevious\nAWS\nNext\nDigital Ocean\n\nLast updated 3 months ago\n\nFlowise as Azure App Service with Postgres: Using Terraform\nPrerequisites\nSetting Up Your Environment\nConfiguring Terraform Variables\nDeploying with Terraform\nAzure Continer Instance: Using Azure Portal UI or Azure CLI\nPrerequisites\nCreate a Container Instance without Persistent Storage\nIn Portal\nCreate using Azure CLI\nCreate a Container Instance with Persistent Storage\nEdit on GitHub"
  },
  {
    "title": "Digital Ocean | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/deployment/digital-ocean",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nDeployment\nAWS\nAzure\nDigital Ocean\nElestio\nGCP\nHugging Face\nKubernetes using Helm\nRailway\nRender\nReplit\nRepoCloud\nSealos\nZeabur\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nDigital Ocean\nCreate Droplet\n\nIn this section, we are going to create a Droplet. For more information, refer to official guide.\n\nFirst, Click Droplets from the dropdown\n\nSelect Data Region and a Basic $6/mo Droplet type\n\nSelect Authentication Method. In this example, we are going to use Password\n\nAfter a while you should be able to see your droplet created successfully\n\nHow to Connect to your Droplet\n\nFor Windows follow this guide.\n\nFor Mac/Linux, follow this guide.\n\nInstall Docker\nCopy\ncurl -fsSL https://get.docker.com -o get-docker.sh\nCopy\nsudo sh get-docker.sh\n\nInstall docker-compose:\n\nCopy\nsudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n\nSet permission:\n\nCopy\nsudo chmod +x /usr/local/bin/docker-compose\nSetup\n\nClone the repo\n\nCopy\ngit clone https://github.com/FlowiseAI/Flowise.git\n\nCd into docker folder\n\nCopy\ncd Flowise && cd docker\n\nCreate a .env file. You can use your favourite editor. I'll use nano\n\nCopy\nnano .env\n\nSpecify the env variables:\n\nCopy\nPORT=3000\n\nDATABASE_PATH=/root/.flowise\n\nAPIKEY_PATH=/root/.flowise\n\nSECRETKEY_PATH=/root/.flowise\n\nLOG_PATH=/root/.flowise/logs\n\nBLOB_STORAGE_PATH=/root/.flowise/storage\n\n(Optional) You can also specify FLOWISE_USERNAME and FLOWISE_PASSWORD for app level authorization. See more \n\nThen press Ctrl + X to Exit, and Y to save the file\n\nRun docker compose\n\nCopy\ndocker compose up -d\n\nYou can then view the app: \"Your Public IPv4 DNS\":3000. Example: 176.63.19.226:3000\n\nYou can bring the app down by:\n\nCopy\ndocker-compose stop\n\nYou can pull from latest image by:\n\nCopy\ndocker pull flowiseai/flowise\nAdding Reverse Proxy & SSL\n\nA reverse proxy is the recommended method to expose an application server to the internet. It will let us connect to our droplet using a URL alone instead of the server IP and port number. This provides security benefits in isolating the application server from direct internet access, the ability to centralize firewall protection, a minimized attack plane for common threats such as denial of service attacks, and most importantly for our purposes, the ability to terminate SSL/TLS encryption in a single place.\n\nA lack of SSL on your Droplet will cause the embeddable widget and API endpoints to be inaccessible in modern browsers. This is because browsers have begun to deprecate HTTP in favor of HTTPS, and block HTTP requests from pages loaded over HTTPS.\n\nStep 1 — Installing Nginx\n\nNginx is available for installation with apt through the default repositories. Update your repository index, then install Nginx:\n\nCopy\nsudo apt update\n\nsudo apt install nginx\n\nPress Y to confirm the installation. If you are asked to restart services, press ENTER to accept the defaults.\n\nYou need to allow access to Nginx through your firewall. Having set up your server according to the initial server prerequisites, add the following rule with ufw:\n\nCopy\nsudo ufw allow 'Nginx HTTP'\n\nNow you can verify that Nginx is running:\n\nCopy\nsystemctl status nginx\n\nOutput:\n\nCopy\n● nginx.service - A high performance web server and a reverse proxy server\n\n     Loaded: loaded (/lib/systemd/system/nginx.service; enabled; vendor preset: enabled)\n\n     Active: active (running) since Mon 2022-08-29 06:52:46 UTC; 39min ago\n\n       Docs: man:nginx(8)\n\n   Main PID: 9919 (nginx)\n\n      Tasks: 2 (limit: 2327)\n\n     Memory: 2.9M\n\n        CPU: 50ms\n\n     CGroup: /system.slice/nginx.service\n\n             ├─9919 \"nginx: master process /usr/sbin/nginx -g daemon on; master_process on;\"\n\n             └─9920 \"nginx: worker process\n\nNext you will add a custom server block with your domain and app server proxy.\n\nStep 2 — Configuring your Server Block + DNS Record\n\nIt is recommended practice to create a custom configuration file for your new server block additions, instead of editing the default configuration directly.\n\nCreate and open a new Nginx configuration file using nano or your preferred text editor:\n\nCopy\nsudo nano /etc/nginx/sites-available/your_domain\n\nInsert the following into your new file, making sure to replace your_domain with your own domain name:\n\nCopy\nserver {\n\n    listen 80;\n\n    listen [::]:80;\n\n    server_name your_domain; #Example: demo.flowiseai.com\n\n    location / {\n\n        proxy_pass http://localhost:3000;\n\n        proxy_http_version 1.1;\n\n        proxy_set_header Host $host;\n\n        proxy_set_header Upgrade $http_upgrade;\n\n        proxy_set_header Connection 'upgrade';\n\n        proxy_cache_bypass $http_upgrade;\n\n    }\n\n}\n\nSave and exit, with nano you can do this by hitting CTRL+O then CTRL+X.\n\nNext, enable this configuration file by creating a link from it to the sites-enabled directory that Nginx reads at startup, making sure again to replace your_domain with your own domain name::\n\nCopy\nsudo ln -s /etc/nginx/sites-available/your_domain /etc/nginx/sites-enabled/\n\nYou can now test your configuration file for syntax errors:\n\nCopy\nsudo nginx -t\n\nWith no problems reported, restart Nginx to apply your changes:\n\nCopy\nsudo systemctl restart nginx\n\nGo to your DNS provider, and add a new A record. Name will be your domain name, and value will be the Public IPv4 address from your droplet\n\nNginx is now configured as a reverse proxy for your application server. You should now be able to open the app: http://yourdomain.com.\n\nStep 3 — Installing Certbot for HTTPS (SSL)\n\nIf you'd like to add a secure https connection to your Droplet like https://yourdomain.com, you'll need to do the following:\n\nFor installing Certbot and enabling HTTPS on NGINX, we will rely on Python. So, first of all, let's set up a virtual environment:\n\nCopy\napt install python3.10-venv\n\nsudo python3 -m venv /opt/certbot/\n\nsudo /opt/certbot/bin/pip install --upgrade pip\n\nAfterwards, run this command to install Certbot:\n\nCopy\nsudo /opt/certbot/bin/pip install certbot certbot-nginx\n\nNow, execute the following command to ensure that the certbot command can be run:\n\nCopy\nsudo ln -s /opt/certbot/bin/certbot /usr/bin/certbot\n\nFinally, run the following command to obtain a certificate and let Certbot automatically modify the NGINX configuration, enabling HTTPS:\n\nCopy\nsudo certbot --nginx\n\nAfter following the certificate generation wizard, we will be able to access our Droplet via HTTPS using the address https://yourdomain.com\n\nSet up automatic renewal\n\nTo enable Certbot to automatically renew the certificates, it is sufficient to add a cron job by running the following command:\n\nCopy\necho \"0 0,12 * * * root /opt/certbot/bin/python -c 'import random; import time; time.sleep(random.random() * 3600)' && sudo certbot renew -q\" | sudo tee -a /etc/crontab > /dev/null\nCongratulations!\n\nYou have successfully setup Flowise on your Droplet, with SSL certificate on your domain 🥳\n\nSteps to update Flowise on Digital Ocean\n\nNavigate to the directory you installed flowise in\n\nCopy\ncd Flowise/docker\n\nStop and remove docker image\n\nNote: This will not delete your flows as the database is stored in a separate folder\n\nCopy\nsudo docker-compose stop\n\nsudo docker-compose rm\n\nPull the latest Flowise Image\n\nYou can check the latest version release here\n\nCopy\ndocker pull flowiseai/flowise\n\nStart the docker\n\nCopy\ndocker-compose up -d\nPrevious\nAzure\nNext\nGCP\n\nLast updated 8 days ago\n\nCreate Droplet\nHow to Connect to your Droplet\nInstall Docker\nSetup\nAdding Reverse Proxy & SSL\nStep 1 — Installing Nginx\nStep 2 — Configuring your Server Block + DNS Record\nStep 3 — Installing Certbot for HTTPS (SSL)\nSet up automatic renewal\nCongratulations!\nSteps to update Flowise on Digital Ocean\nEdit on GitHub"
  },
  {
    "title": "AWS | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/deployment/aws",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nDeployment\nAWS\nAzure\nDigital Ocean\nElestio\nGCP\nHugging Face\nKubernetes using Helm\nRailway\nRender\nReplit\nRepoCloud\nSealos\nZeabur\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAWS\nPrerequisite\n\nThis requires some basic understanding of how AWS works.\n\nTwo options are available to deploy Flowise on AWS:\n\nDeploy on ECS using CloudFormation\n\nManually configure an EC2 Instance\n\nDeploy on ECS using CloudFormation\n\nCloudFormation template is available here: https://gist.github.com/MrHertal/549b31a18e350b69c7200ae8d26ed691\n\nIt deploys Flowise on an ECS cluster exposed through ELB.\n\nIt was inspired by this reference architecture: https://github.com/aws-samples/ecs-refarch-cloudformation\n\nFeel free to edit this template to adapt things like Flowise image version, environment variables etc.\n\nExample of command to deploy Flowise using the AWS CLI:\n\nCopy\naws cloudformation create-stack --stack-name flowise --template-body file://flowise-cloudformation.yml --capabilities CAPABILITY_IAM\n\nAfter deployment, the URL of your Flowise application is available in the CloudFormation stack outputs.\n\nLaunch EC2 Instance\n\nIn the EC2 dashboard, click Launch Instance\n\nScroll down and Create new key pair if you don't have one\n\nFill in your preferred key pair name. For Windows, we will use .ppk and PuTTY to connect to the instance. For Mac and Linux, we will use .pem and OpenSSH\n\nClick Create key pair and select a location path to save the .ppk file\n\nOpen the left side bar, and open a new tab from Security Groups. Then Create security group\n\nFill in your preferred security group name and description. Next, add the following to Inbound Rules and Create security group\n\nBack to the first tab (EC2 Launch an instance) and scroll down to Network settings. Select the security group you've just created\n\nClick Launch instance. Navigate back to EC2 Dashboard, after few mins we should be able to see a new instance up and running 🎉\n\nHow to Connect to your instance (Windows)\n\nFor Windows, we are going to use PuTTY. You can download one from here.\n\nOpen PuTTY and fill in the HostName with your instance's Public IPv4 DNS name\n\nFrom the left hand side bar of PuTTY Configuration, expand SSH and click on Auth. Click Browse and select the .ppk file you downloaded earlier.\n\nClick Open and Accept the pop up message\n\nThen login as ec2-user\n\nNow you are connected to the EC2 instance\n\nHow to Connect to your instance (Mac and Linux)\n\nOpen the Terminal application on your Mac/Linux.\n\n(Optional) Set the permissions of the private key file to restrict access to it:\n\nCopy\nchmod 400 /path/to/mykey.pem\n\nUse the ssh command to connect to your EC2 instance, specifying the username (ec2-user), Public IPv4 DNS, and the path to the .pem file.\n\nCopy\nssh -i /Users/username/Documents/mykey.pem ec2-user@ec2-123-45-678-910.compute-1.amazonaws.com\n\nPress Enter, and if everything is configured correctly, you should successfully establish an SSH connection to your EC2 instance\n\nInstall Docker\n\nApply pending updates using the yum command:\n\nCopy\nsudo yum update\n\nSearch for Docker package:\n\nCopy\nsudo yum search docker\n\nGet version information:\n\nCopy\nsudo yum info docker\n\nInstall docker, run:\n\nCopy\nsudo yum install docker\n\nAdd group membership for the default ec2-user so you can run all docker commands without using the sudo command:\n\nCopy\nsudo usermod -a -G docker ec2-user\n\nid ec2-user\n\nnewgrp docker\n\nInstall docker-compose:\n\nCopy\nsudo yum install python3-pip\n\npip3 install docker-compose\n\nEnable docker service at AMI boot time:\n\nCopy\nsudo systemctl enable docker.service\n\nStart the Docker service:\n\nCopy\nsudo systemctl start docker.service\nInstall Git\nCopy\nsudo yum install git -y\nSetup\n\nClone the repo\n\nCopy\ngit clone https://github.com/FlowiseAI/Flowise.git\n\nCd into docker folder\n\nCopy\ncd Flowise && cd docker\n\nCreate a .env file. You can use your favourite editor. I'll use nano\n\nCopy\nnano .env\n\nSpecify the env variables:\n\nCopy\nPORT=3000\n\nDATABASE_PATH=/root/.flowise\n\nAPIKEY_PATH=/root/.flowise\n\nSECRETKEY_PATH=/root/.flowise\n\nLOG_PATH=/root/.flowise/logs\n\nBLOB_STORAGE_PATH=/root/.flowise/storage\n\n(Optional) You can also specify FLOWISE_USERNAME and FLOWISE_PASSWORD for app level authorization. See more https://github.com/FlowiseAI/FlowiseDocs/blob/main/configuration/deployment/broken-reference/README.md\n\nThen press Ctrl + X to Exit, and Y to save the file\n\nRun docker compose\n\nCopy\ndocker-compose up -d\n\nYour application is now ready at your Public IPv4 DNS on port 3000:\n\nCopy\nhttp://ec2-123-456-789.compute-1.amazonaws.com:3000\n\nYou can bring the app down by:\n\nCopy\ndocker-compose stop\n\nYou can pull from latest image by:\n\nCopy\ndocker pull flowiseai/flowise\nUsing NGINX\n\nIf you want to get rid of the :3000 on the url and have a custom domain, you can use NGINX to reverse proxy port 80 to 3000 So user will be able to open the app using your domain. Example: http://yourdomain.com.\n\nCopy\nsudo yum install nginx\nCopy\nnginx -v\nCopy\nsudo systemctl start nginx\nCopy\nsudo nano /etc/nginx/conf.d/flowise.conf\n\nCopy paste the following and change to your domain:\n\nCopy\nserver {\n\n    listen 80;\n\n    listen [::]:80;\n\n    server_name yourdomain.com; #Example: demo.flowiseai.com\n\n    location / {\n\n        proxy_pass http://localhost:3000;\n\n        proxy_http_version 1.1;\n\n        proxy_set_header Host $host;\n\n        proxy_set_header Upgrade $http_upgrade;\n\n        proxy_set_header Connection 'upgrade';\n\n        proxy_cache_bypass $http_upgrade;\n\n        proxy_set_header X-Real-IP $remote_addr;\n\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n    }\n\n}\n\npress Ctrl + X to Exit, and Y to save the file\n\nCopy\nsudo systemctl restart nginx\n\nGo to your DNS provider, and add a new A record. Name will be your domain name, and value will be the Public IPv4 address from EC2 instance\n\nYou should now be able to open the app: http://yourdomain.com.\n\nInstall Certbot to have HTTPS\n\nIf you like your app to have https://yourdomain.com. Here is how:\n\nFor installing Certbot and enabling HTTPS on NGINX, we will rely on Python. So, first of all, let's set up a virtual environment:\n\nCopy\nsudo python3 -m venv /opt/certbot/\n\nsudo /opt/certbot/bin/pip install --upgrade pip\n\nAfterwards, run this command to install Certbot:\n\nCopy\nsudo /opt/certbot/bin/pip install certbot certbot-nginx\n\nNow, execute the following command to ensure that the certbot command can be run:\n\nCopy\nsudo ln -s /opt/certbot/bin/certbot /usr/bin/certbot\n\nFinally, run the following command to obtain a certificate and let Certbot automatically modify the NGINX configuration, enabling HTTPS:\n\nCopy\nsudo certbot --nginx\n\nAfter following the certificate generation wizard, we will be able to access our EC2 instance via HTTPS using the address https://yourdomain.com\n\nSet up automatic renewal\n\nTo enable Certbot to automatically renew the certificates, it is sufficient to add a cron job by running the following command:\n\nCopy\necho \"0 0,12 * * * root /opt/certbot/bin/python -c 'import random; import time; time.sleep(random.random() * 3600)' && sudo certbot renew -q\" | sudo tee -a /etc/crontab > /dev/null\nCongratulations!\n\nYou have successfully setup Flowise apps on EC2 instance with SSL certificate on your domain🥳\n\nPrevious\nDeployment\nNext\nAzure\n\nLast updated 16 days ago\n\nPrerequisite\nDeploy on ECS using CloudFormation\nLaunch EC2 Instance\nHow to Connect to your instance (Windows)\nHow to Connect to your instance (Mac and Linux)\nInstall Docker\nInstall Git\nSetup\nUsing NGINX\nInstall Certbot to have HTTPS\nSet up automatic renewal\nCongratulations!\nEdit on GitHub"
  },
  {
    "title": "Deployment | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/deployment",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nDeployment\nAWS\nAzure\nDigital Ocean\nElestio\nGCP\nHugging Face\nKubernetes using Helm\nRailway\nRender\nReplit\nRepoCloud\nSealos\nZeabur\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nDeployment\n\nFlowise can be run anywhere.\n\nFlowise is built to be flexible, so you can deploy it wherever you're comfortable. We're platform-agnostic, meaning it works on a variety of systems:\n\nLocal Machine\n\nTo deploy Flowise locally, follow our Getting Started guide.\n\nModern Cloud Providers\n\nModern cloud platforms prioritize automation and focus on developer workflows, simplifying cloud management and ongoing maintenance. This reduces the technical expertise needed, but may limit the level of customization you have over the underlying infrastructure.\n\nElestio\n\nHugging Face\n\nRailway\n\nRender\n\nReplit\n\nRepoCloud\n\nSealos\n\nZeabur\n\nEstablished Cloud Providers\n\nEstablished cloud providers, on the other hand, require a higher level of technical expertise to manage and optimize for your specific needs. This complexity, however, also grants greater flexibility and control over your cloud environment.\n\nAWS\n\nAzure\n\nDigitalOcean\n\nGCP\n\nKubernetes using Helm\n\nPrevious\nChatflow Level\nNext\nAWS\n\nLast updated 2 days ago\n\nLocal Machine\nModern Cloud Providers\nEstablished Cloud Providers\nEdit on GitHub"
  },
  {
    "title": "Chatflow Level | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/authorization/chatflow-level",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nApp Level\nChatflow Level\nDeployment\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nChatflow Level\n\nAfter you have a chatflow constructed, you might want to allow certain people to be able to access and interact with it. You can achieve that by assigning an API key for that specific chatflow.\n\nAPI Key\n\nIn dashboard, navigate to API Keys section, and you should be able to see a DefaultKey created. You can also add or delete any keys.\n\nChatflow\n\nNavigate to the chatflow, and now you can select the API Key you want to use to protect the chatflow.\n\nAfter assigning an API key, one can only access the chatflow API when the Authorization header is provided with the correct API key specified during a HTTP call.\n\nCopy\n\"Authorization\": \"Bearer <your-api-key>\"\n\nAn example of calling the API using POSTMAN\n\nYou can specify the location where the api keys are stored by specifying APIKEY_PATH env variables. Read more Environment Variables\n\nPrevious\nApp Level\nNext\nDeployment\n\nLast updated 1 month ago\n\nAPI Key\nChatflow\nEdit on GitHub"
  },
  {
    "title": "App Level | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/authorization/app-level",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nApp Level\nChatflow Level\nDeployment\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nApp Level\n\nApp level authorization protects your Flowise instance by username and password. This protects your apps from being accessible by anyone when deployed online.\n\nHow to Set Username & Password\nNpm\n\nInstall Flowise\n\nCopy\nnpm install -g flowise\n\nStart Flowise with username & password\n\nCopy\nnpx flowise start --FLOWISE_USERNAME=user --FLOWISE_PASSWORD=1234\n\nOpen http://localhost:3000\n\nDocker\n\nNavigate to docker folder\n\nCopy\ncd docker\n\nCreate .env file and specify the PORT, FLOWISE_USERNAME, and FLOWISE_PASSWORD\n\nCopy\nPORT=3000\n\nFLOWISE_USERNAME=user\n\nFLOWISE_PASSWORD=1234\n\nPass FLOWISE_USERNAME and FLOWISE_PASSWORD to the docker-compose.yml file:\n\nCopy\nenvironment:\n\n    - PORT=${PORT}\n\n    - FLOWISE_USERNAME=${FLOWISE_USERNAME}\n\n    - FLOWISE_PASSWORD=${FLOWISE_PASSWORD}\n\ndocker-compose up -d\n\nOpen http://localhost:3000\n\nYou can bring the containers down by docker-compose stop\n\nGit clone\n\nTo enable app level authentication, add FLOWISE_USERNAME and FLOWISE_PASSWORD to the .env file in packages/server:\n\nCopy\nFLOWISE_USERNAME=user\n\nFLOWISE_PASSWORD=1234\nPrevious\nAuth\nNext\nChatflow Level\n\nLast updated 1 month ago\n\nHow to Set Username & Password\nNpm\nDocker\nGit clone\nEdit on GitHub"
  },
  {
    "title": "Configuration | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nDeployment\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nConfiguration\nAuth\nDeployment\nEnvironment Variables\nDatabases\nRate Limit\nPrevious\nTelemetry\nNext\nAuth\n\nLast updated 8 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Auth | FlowiseAI",
    "url": "https://docs.flowiseai.com/configuration/authorization",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nAuth\nApp Level\nChatflow Level\nDeployment\nEnvironment Variables\nDatabases\nRate Limit\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAuth\n\nApp level\n\nChatflow level\n\nPrevious\nConfiguration\nNext\nApp Level\n\nLast updated 5 months ago\n\nEdit on GitHub"
  },
  {
    "title": "Telemetry | FlowiseAI",
    "url": "https://docs.flowiseai.com/using-flowise/telemetry",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nAPI\nStreaming\nEmbed\nVariables\nAnalytic\nTelemetry\nConfiguration\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nTelemetry\n\nFlowise open source repository has a built-in telemetry that collects anonymous usage information. This helps us to better understand usage of Flowise, enabling us to prioritize our efforts towards developing new features and resolving issues, and enhancing the performance and stability of Flowise.\n\n!! Important - we never collect any confidential information about the node input/output, messages, or any sort of credentials and variables. Only events are being sent.\n\nYou can verify these claims by finding all locations telemetry.sendTelemetry is called from the source code.\n\nEvent\tMetadata\n\n\nchatflow_created\n\n\t\nCopy\n{\n\n    \"version\": <app-version>,\n\n    \"chatlowId\": <chatflow-id>,\n\n    \"flowGraph\": {\n\n        \"nodes\": [<nodeid-1>, <nodeid-2>],\n\n        \"edges\": [\n\n            {\n\n                \"source\": <nodeid-1>,\n\n                \"target\": <nodeid-2>\n\n            }\n\n        ]\n\n    }\n\n}\n\n\n\ntool_created\n\n\t\nCopy\n{\n\n    \"version\": <app-version>,\n\n    \"toolId\": <tool-id>,\n\n    \"toolName\": <tool-name>\n\n}\n\n\n\nassistant_created\n\n\t\nCopy\n{\n\n    \"version\": <app-version>,\n\n    \"assistantId\": <assistant-id>\n\n}\n\n\n\nvector_upserted\n\n\t\nCopy\n{\n\n    \"version\": <app-version>,\n\n    \"chatlowId\": <chatflow-id>,\n\n    \"type\": \"INTERNAL\", // EXTERNAL\n\n    \"flowGraph\": {\n\n        \"nodes\": [<nodeid-1>, <nodeid-2>],\n\n        \"edges\": [\n\n            {\n\n                \"source\": <nodeid-1>,\n\n                \"target\": <nodeid-2>\n\n            }\n\n        ]\n\n    },\n\n    \"stopNodeId\": <nodeid-1>\n\n}\n\n\n\nprediction_sent\n\n\t\nCopy\n{\n\n    \"version\": <app-version>,\n\n    \"chatlowId\": <chatflow-id>,\n\n    \"chatId\": <chat-id>,\n\n    \"type\": \"INTERNAL\", // EXTERNAL\n\n    \"flowGraph\": {\n\n        \"nodes\": [<nodeid-1>, <nodeid-2>],\n\n        \"edges\": [\n\n            {\n\n                \"source\": <nodeid-1>,\n\n                \"target\": <nodeid-2>\n\n            }\n\n        ]\n\n    }\n\n}\nDisable Telemetry\n\nUsers can disable telemetry by setting DISABLE_FLOWISE_TELEMETRY to true in .env file.\n\nPrevious\nAnalytic\nNext\nConfiguration\n\nLast updated 4 months ago\n\nEdit on GitHub"
  },
  {
    "title": "Analytic | FlowiseAI",
    "url": "https://docs.flowiseai.com/using-flowise/analytic",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nAPI\nStreaming\nEmbed\nVariables\nAnalytic\nTelemetry\nConfiguration\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAnalytic\n\nThere are several analytic providers Flowise integrates with:\n\nLangsmith\n\nLangfuse\n\nLunaryAI\n\nUI\n\nAt the top right corner, click Analyse Chatflow:\n\nYou will see the list of providers along with configuration:\n\nSimply fill in the credential and other configuration, then turn it ON:\n\nAPI\n\nOnce the analytic has been turned ON from the UI, you can override or provide additional configuration  in the body of the Prediction API:\n\nCopy\n{\n\n    \"question\": \"hi there\",\n\n    \"overrideConfig\": {\n\n        \"analytics\": {\n\n            \"langFuse\": { // langSmith, langFuse, lunary\n\n                \"userId\": \"user1\"\n\n            }\n\n        }\n\n    }\n\n}\nPrevious\nVariables\nNext\nTelemetry\n\nLast updated 2 months ago\n\nUI\nAPI\nEdit on GitHub"
  },
  {
    "title": "Embed | FlowiseAI",
    "url": "https://docs.flowiseai.com/using-flowise/embed",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nAPI\nStreaming\nEmbed\nVariables\nAnalytic\nTelemetry\nConfiguration\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nEmbed\n\nYou can embed a chat widget to your website. Simply copy paste the embedded code provided to anywhere in the <body> tag of your html file.\n\nWatch how to do that:\n\nYou can also customize your own embedded chat widget UI. See full configuration list.\n\nChatflow Config\n\nYou can pass chatflowConfig JSON object to override existing configuration. This is the same as Override Config in API.\n\nCopy\n<script type=\"module\">\n\n  import Chatbot from 'https://cdn.jsdelivr.net/npm/flowise-embed/dist/web.js';\n\n  Chatbot.init({\n\n    chatflowid: 'abc',\n\n    apiHost: 'http://localhost:3000',\n\n    chatflowConfig: {\n\n      \"sessionId\": \"123\",\n\n      \"returnSourceDocuments\": true\n\n    }\n\n  })\n\n</script>\nObserver Config\n\nThis allows you to execute code in parent based upon signal observations within the chatbot.\n\nCopy\n<script type=\"module\">\n\n  import Chatbot from 'https://cdn.jsdelivr.net/npm/flowise-embed/dist/web.js';\n\n  Chatbot.init({\n\n    chatflowid: 'abc',\n\n    apiHost: 'http://localhost:3000',\n\n    observersConfig: {\n\n      // User input has changed\n\n      observeUserInput: (userInput) => {\n\n        console.log({ userInput });\n\n      },\n\n      // The bot message stack has changed\n\n      observeMessages: (messages) => {\n\n        console.log({ messages });\n\n      },\n\n      // The bot loading signal changed\n\n      observeLoading: (loading) => {\n\n        console.log({ loading });\n\n      },\n\n    },\n\n  })\n\n</script>\nTheme\n\nYou can change the pop up button properties, as well as the chat window:\n\nCopy\n<script type=\"module\">\n\n  import Chatbot from 'https://cdn.jsdelivr.net/npm/flowise-embed/dist/web.js';\n\n  Chatbot.init({\n\n    chatflowid: 'abc',\n\n    apiHost: 'http://localhost:3000',\n\n    theme: {\n\n      button: {\n\n        backgroundColor: '#3B81F6',\n\n        right: 20,\n\n        bottom: 20,\n\n        size: 48, // small | medium | large | number\n\n        dragAndDrop: true,\n\n        iconColor: 'white',\n\n        customIconSrc: 'https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/svg/google-messages.svg',\n\n      },\n\n      chatWindow: {\n\n        showTitle: true, // show/hide the title bar\n\n        title: 'Flowise Bot',\n\n        titleAvatarSrc: 'https://raw.githubusercontent.com/walkxcode/dashboard-icons/main/svg/google-messages.svg',\n\n        welcomeMessage: 'Hello! This is custom welcome message',\n\n        errorMessage: 'This is a custom error message',\n\n        backgroundColor: '#ffffff',\n\n        height: 700,\n\n        width: 400,\n\n        fontSize: 16,\n\n        botMessage: {\n\n          backgroundColor: '#f7f8ff',\n\n          textColor: '#303235',\n\n          showAvatar: true,\n\n          avatarSrc: 'https://raw.githubusercontent.com/zahidkhawaja/langchain-chat-nextjs/main/public/parroticon.png',\n\n        },\n\n        userMessage: {\n\n          backgroundColor: '#3B81F6',\n\n          textColor: '#ffffff',\n\n          showAvatar: true,\n\n          avatarSrc: 'https://raw.githubusercontent.com/zahidkhawaja/langchain-chat-nextjs/main/public/usericon.png',\n\n        },\n\n        textInput: {\n\n          placeholder: 'Type your question',\n\n          backgroundColor: '#ffffff',\n\n          textColor: '#303235',\n\n          sendButtonColor: '#3B81F6',\n\n          maxChars: 50,\n\n          maxCharsWarningMessage: 'You exceeded the characters limit. Please input less than 50 characters.',\n\n        },\n\n        feedback: {\n\n          color: '#303235',\n\n        },\n\n        footer: {\n\n          textColor: '#303235',\n\n          text: 'Powered by',\n\n          company: 'Flowise',\n\n          companyLink: 'https://flowiseai.com',\n\n        },\n\n      },\n\n    },\n\n  });\n\n</script>\nCustom Modificaton\n\nTo modify the full source code of embedded chat widget, follow these steps:\n\nFork the Flowise Chat Embed repository\n\nThen you can make any code changes. One of the popular ask is to remove Flowise branding.\n\nRun pnpm build\n\nPush changes to the forked repo\n\nYou can then use it as embedded chat like so:\n\nReplace username to your Github username, and forked-repo to your forked repo.\n\nCopy\n<script type=\"module\">\n\n      import Chatbot from \"https://cdn.jsdelivr.net/gh/username/forked-repo/dist/web.js\"\n\n      Chatbot.init({\n\n          chatflowid: \"chatflow-id\",\n\n          apiHost: \"http://localhost:3000\",\n\n      })\n\n</script>\nCopy\n<script type=\"module\">\n\n      import Chatbot from \"https://cdn.jsdelivr.net/gh/HenryHengZJ/FlowiseChatEmbed-Test/dist/web.js\"\n\n      Chatbot.init({\n\n          chatflowid: \"chatflow-id\",\n\n          apiHost: \"http://localhost:3000\",\n\n      })\n\n</script>\n\nAn alternative to jsdelivr is unpkg. For example:\n\nCopy\nhttps://unpkg.com/flowise-embed/dist/web.js\nCORS\n\nWhen using embedded chat widget, there's chance that you might face CORS issue like:\n\nAccess to fetch at 'https://<your-flowise.com>/api/v1/prediction/' from origin 'https://<your-flowise.com>' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.\n\nTo fix it, specify the following environment variables:\n\nCopy\nCORS_ORIGINS=*\n\nIFRAME_ORIGINS=*\n\nFor example, if you are using npx flowise start\n\nCopy\nnpx flowise start --CORS_ORIGINS=* --IFRAME_ORIGINS=*\n\nIf using Docker, place the env variables inside Flowise/docker/.env\n\nIf using local Git clone, place the env variables inside Flowise/packages/server/.env\n\nTutorials\n\nWatch how to embed Flowise in a Bootstrap 5 website\n\nWatch how to add chatbot to website\n\nPrevious\nStreaming\nNext\nVariables\n\nLast updated 2 days ago\n\nChatflow Config\nObserver Config\nTheme\nCustom Modificaton\nCORS\nTutorials\nEdit on GitHub"
  },
  {
    "title": "Variables | FlowiseAI",
    "url": "https://docs.flowiseai.com/using-flowise/variables",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nAPI\nStreaming\nEmbed\nVariables\nAnalytic\nTelemetry\nConfiguration\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nVariables\n\nFlowise allow users to create variables that can be used in:\n\nCustom Tool\n\nCustom Function\n\nCustom Loader\n\nIf Else\n\nFor example, you have a database URL that you do not want it to be exposed on the function, but you still want the function to be able to read the URL from your environment variable.\n\nUser can create a variable and get the variable like so:\n\n$vars.<variable-name>\n\nVariables can be Static or Runtime.\n\nStatic\n\nStatic variable will be saved with the value specified, and retrieved as it is.\n\nRuntime\n\nValue of the variable will be fetched from .env file using process.env\n\nResources\n\nPass Variables to Function\n\nPrevious\nEmbed\nNext\nAnalytic\n\nLast updated 2 days ago\n\nStatic\nRuntime\nResources\nEdit on GitHub"
  },
  {
    "title": "API | FlowiseAI",
    "url": "https://docs.flowiseai.com/using-flowise/api",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nAPI\nStreaming\nEmbed\nVariables\nAnalytic\nTelemetry\nConfiguration\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nAPI\nPrediction API\n\nPOST /api/v1/prediction/{your-chatflowid}\n\nRequest Body\n\nKey\tDescription\tType\tRequired\n\n\nquestion\n\n\t\n\nUser's question\n\n\t\n\nstring\n\n\t\n\nYes\n\n\n\n\noverrideConfig\n\n\t\n\nOverride existing flow configuration\n\n\t\n\nobject\n\n\t\n\nNo\n\n\n\n\nhistory\n\n\t\n\nPrepend history messages at the start of conversation\n\n\t\n\narray\n\n\t\n\nNo\n\nYou can use the chatflow as API and connect to frontend applications.\n\nOverride Config\n\nYou also have the flexibility to override input configuration with overrideConfig property.\n\nPython\nJavascript\nCopy\nimport requests\n\n\n\nAPI_URL = \"http://localhost:3000/api/v1/prediction/<chatlfowid>\"\n\n\n\ndef query(payload):\n\n    response = requests.post(API_URL, json=payload)\n\n    return response.json()\n\n    \n\noutput = query({\n\n    \"question\": \"Hey, how are you?\",\n\n    \"overrideConfig\": {\n\n        \"sessionId\": \"123\",\n\n        \"returnSourceDocuments\": true\n\n    }\n\n})\nHistory\n\nYou can prepend history messages to give some context to LLM. For example, if you want the LLM to remember user's name:\n\nPython\nJavascript\nCopy\nimport requests\n\n\n\nAPI_URL = \"http://localhost:3000/api/v1/prediction/<chatlfowid>\"\n\n\n\ndef query(payload):\n\n    response = requests.post(API_URL, json=payload)\n\n    return response.json()\n\n    \n\noutput = query({\n\n    \"question\": \"Hey, how are you?\",\n\n    \"history\": [\n\n        {\n\n            \"role\": \"apiMessage\",\n\n            \"context\": \"Hello how can I help?\"\n\n        },\n\n        {\n\n            \"role\": \"userMessage\",\n\n            \"context\": \"Hi my name is Brian\"\n\n        },\n\n        {\n\n            \"role\": \"apiMessage\",\n\n            \"context\": \"Hi Brian, how can I help?\"\n\n        },\n\n    ]\n\n})\nImage Uploads\n\nWhen Allow Image Upload is enabled, images can be uploaded from chat interface.\n\nPython\nJavascript\nCopy\nimport requests\n\n\n\nAPI_URL = \"http://localhost:3000/api/v1/prediction/<chatlfowid>\"\n\n\n\ndef query(payload):\n\n    response = requests.post(API_URL, json=payload)\n\n    return response.json()\n\n    \n\noutput = query({\n\n    \"question\": \"Can you describe the image?\",\n\n    \"uploads\": [\n\n        {\n\n            \"data\": 'data:image/png;base64,iVBORw0KGgdM2uN0', #base64 string\n\n            \"type\": 'file',\n\n            \"name\": 'Flowise.png',\n\n            \"mime\": 'image/png'\n\n        }\n\n    ]\n\n})\nSpeech to Text\n\nWhen Speech to Text is enabled, users can speak directly into microphone and speech will be transcribed into text.\n\nPython\nJavascript\nCopy\nimport requests\n\n\n\nAPI_URL = \"http://localhost:3000/api/v1/prediction/<chatlfowid>\"\n\n\n\ndef query(payload):\n\n    response = requests.post(API_URL, json=payload)\n\n    return response.json()\n\n    \n\noutput = query({\n\n    \"uploads\": [\n\n        {\n\n            \"data\": 'data:audio/webm;codecs=opus;base64,GkXf', #base64 string\n\n            \"type\": 'audio',\n\n            \"name\": 'audio.wav',\n\n            \"mime\": 'audio/webm'\n\n        }\n\n    ]\n\n})\nAuthentication\n\nYou can assign an API key to the prediction API from the UI. Refer Chatflow Level for more details.\n\nThe Authorization header must be provided with the correct API key specified during a HTTP call.\n\nCopy\n\"Authorization\": \"Bearer <your-api-key>\"\nVector Upsert API\n\nPOST /api/v1/vector/upsert/{your-chatflowid}\n\nRequest Body\n\nKey\tDescription\tType\tRequired\n\n\noverrideConfig\n\n\t\n\nOverride existing flow configuration\n\n\t\n\nobject\n\n\t\n\nNo\n\n\n\n\nstopNodeId\n\n\t\n\nNode ID of the vector store. When you have multiple vector stores in a flow, you might not want to upsert all of them. Specifying stopNodeId will ensure only that specific vector store node is upserted.\n\n\t\n\narray\n\n\t\n\nNo\n\nDocument Loaders with Upload\n\nSome document loaders in Flowise allow user to upload files:\n\nIf the flow contains Document Loaders with Upload File functionality, the API looks slightly different. Instead of passing body as JSON, form-data is being used. This allows you to upload any files to the API.\n\nIt is user's responsibility to make sure the file type is compatible with the expected file type from document loader. For example, if a Text File Loader is being used, you should only upload file with .txt extension.\n\nPython\nJavascript\nCopy\nimport requests\n\n\n\nAPI_URL = \"http://localhost:3000/api/v1/vector/upsert/<chatlfowid>\"\n\n\n\n# use form data to upload files\n\nform_data = {\n\n    \"files\": ('state_of_the_union.txt', open('state_of_the_union.txt', 'rb'))\n\n}\n\n\n\nbody_data = {\n\n    \"returnSourceDocuments\": True\n\n}\n\n\n\ndef query(form_data):\n\n    response = requests.post(API_URL, files=form_data, data=body_data)\n\n    print(response)\n\n    return response.json()\n\n\n\noutput = query(form_data)\n\nprint(output)\nDocument Loaders without Upload\n\nFor other Document Loaders nodes without Upload File functionality, the API body is in JSON format similar to Prediction API.\n\nPython\nJavascript\nCopy\nimport requests\n\n\n\nAPI_URL = \"http://localhost:3000/api/v1/vector/upsert/<chatlfowid>\"\n\n\n\ndef query(form_data):\n\n    response = requests.post(API_URL, json=payload)\n\n    print(response)\n\n    return response.json()\n\n\n\noutput = query({\n\n    \"overrideConfig\": { # optional\n\n        \"returnSourceDocuments\": true\n\n    }\n\n})\n\nprint(output)\nAuthentication\n\nYou can assign an API key to the prediction API from the UI. Refer Chatflow Level for more details.\n\nThe Authorization header must be provided with the correct API key specified during a HTTP call.\n\nCopy\n\"Authorization\": \"Bearer <your-api-key>\"\nMessage API\n\nGET /api/v1/chatmessage/{your-chatflowid}\n\nDELETE /api/v1/chatmessage/{your-chatflowid}\n\nQuery Parameters\n\nParam\tType\tValue\n\n\nsessionId\n\n\t\n\nstring\n\n\t\n\n\n\n\nsort\n\n\t\n\nenum\n\n\t\n\nASC or DESC\n\n\n\n\nstartDate\n\n\t\n\nstring\n\n\t\n\n\n\n\nendDate\n\n\t\n\nstring\n\n\t\n\nAuthentication\n\nMessage API is restricted to only Flowise admin user. Basic authentication must be provided in the headers if Flowise instance has been configured with FLOWISE_USERNAME and FLOWISE_PASSWORD. Refer App Level for more details.\n\nNode\nBrowser\nPython\nCopy\n\"Authorization\": \"Basic \" + Buffer.from(username + \":\" + password).toString('base64')\nTutorials\nPrevious\nUsing Flowise\nNext\nStreaming\n\nLast updated 16 days ago\n\nPrediction API\nOverride Config\nHistory\nImage Uploads\nSpeech to Text\nAuthentication\nVector Upsert API\nDocument Loaders with Upload\nDocument Loaders without Upload\nAuthentication\nMessage API\nAuthentication\nTutorials\nEdit on GitHub"
  },
  {
    "title": "Streaming | FlowiseAI",
    "url": "https://docs.flowiseai.com/using-flowise/streaming",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nAPI\nStreaming\nEmbed\nVariables\nAnalytic\nTelemetry\nConfiguration\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nStreaming\n\nFlowise supports streaming back to your front end application when the final node is a Chain or OpenAI Function Agent.\n\nInstall socket.io-client to your front-end application\n\nYarn\nNpm\nPnpm\nCopy\nyarn add socket.io-client\n\nRefer official docs for more installation options.\n\nImport it\n\nCopy\nimport socketIOClient from 'socket.io-client'\n\nEstablish connection\n\nCopy\nconst socket = socketIOClient(\"http://localhost:3000\") //flowise url\n\nListen to connection\n\nCopy\nimport { useState } from 'react'\n\n\n\nconst [socketIOClientId, setSocketIOClientId] = useState('');\n\n\n\nsocket.on('connect', () => {\n\n  setSocketIOClientId(socket.id)\n\n});\n\nSend query with socketIOClientId\n\nCopy\nasync function query(data) {\n\n    const response = await fetch(\n\n        \"http://localhost:3000/api/v1/prediction/<chatflow-id>\",\n\n        {\n\n            method: \"POST\",\n\n            body: data\n\n        }\n\n    );\n\n    const result = await response.json();\n\n    return result;\n\n}\n\n\n\nquery({\n\n  \"question\": \"Hey, how are you?\",\n\n  \"socketIOClientId\": socketIOClientId\n\n}).then((response) => {\n\n    console.log(response);\n\n});\n\nListen to token stream\n\nCopy\n// When LLM start streaming\n\nsocket.on('start', () => {\n\n  console.log('start');\n\n});\n\n\n\n// The delta token/word when streaming\n\nsocket.on('token', (token) => {\n\n  console.log('token:', token);\n\n});\n\n\n\n// Source documents returned from the chatflow\n\nsocket.on('sourceDocuments', (sourceDocuments) => {\n\n  console.log('sourceDocuments:', sourceDocuments);\n\n});\n\n\n\n// Tools used during execution\n\nsocket.on('usedTools', (usedTools) => {\n\n  console.log('usedTools:', usedTools);\n\n});\n\n\n\n// When LLM finished streaming\n\nsocket.on('end', () => {\n\n  console.log('end');\n\n});\n\n\n\n//------------------- For Multi Agents ----------------------\n\n\n\n// The next agent in line\n\nsocket.on('nextAgent', (nextAgent) => {\n\n  console.log('nextAgent:', nextAgent);\n\n});\n\n\n\n// The whole multi agents thoughts, reasoning and output\n\nsocket.on('agentReasoning', (agentReasoning) => {\n\n  console.log('agentReasoning:', agentReasoning);\n\n});\n\n\n\n// When execution is aborted/interrupted\n\nsocket.on('abort', () => {\n\n  console.log('abort');\n\n});\n\nDisconnect connection\n\nCopy\nsocket.disconnect();\nPrevious\nAPI\nNext\nEmbed\n\nLast updated 14 days ago\n\nEdit on GitHub"
  },
  {
    "title": "Using Flowise | FlowiseAI",
    "url": "https://docs.flowiseai.com/using-flowise",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nAPI\nStreaming\nEmbed\nVariables\nAnalytic\nTelemetry\nConfiguration\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nUsing Flowise\nAPI\nStreaming\nEmbed\nVariables\nAnalytic\nTelemetry\nPrevious\nContributing\nNext\nAPI\n\nLast updated 1 month ago\n\nEdit on GitHub"
  },
  {
    "title": "Contributing | FlowiseAI",
    "url": "https://docs.flowiseai.com/contributing",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nContributing\n\nWe appreciate any form of contributions.\n\n⭐ Star\n\nStar and share the Github Repo.\n\n🙋 Q&A\n\nSearch up for any questions in Q&A section, if you can't find one, don't hesitate to create one. It might helps others that have similar question.\n\n🙌 Share Chatflow\n\nYes! Sharing how you use Flowise is a way of contribution. Export your chatflow as JSON, attach a screenshot and share it in Show and Tell section.\n\n💡 Ideas\n\nIdeas are welcome such as new feature, apps integration, and blockchain networks. Submit in Ideas section.\n\n🐞 Report Bugs\n\nFound an issue? Report it.\n\n📖 Contribute to Docs\n\nFork the official Flowise Docs Repo\n\nClone your forked repository\n\nCreate a new branch\n\nSwitch to the newly created branch\n\nGo into repository folder\n\nCopy\ncd FlowiseDocs\n\nMake changes\n\nCommit changes and submit Pull Request from forked branch pointing to Flowise Docs main.\n\n🏷️ Pull Request process\n\nA member of the FlowiseAI team will automatically be notified/assigned when you open a pull request. You can also reach out to us on Discord.\n\n📜 Code of Conduct\n\nThis project and everyone participating in it are governed by the Code of Conduct which can be found in the file. By participating, you are expected to uphold this code. Please report unacceptable behavior to hello@flowiseai.com.\n\nPrevious\nGetting Started\nNext\nUsing Flowise\n\nLast updated 5 months ago\n\n⭐ Star\n🙋 Q&A\n🙌 Share Chatflow\n💡 Ideas\n🐞 Report Bugs\n📖 Contribute to Docs\n🏷️ Pull Request process\n📜 Code of Conduct\nEdit on GitHub"
  },
  {
    "title": "Welcome to Flowise | FlowiseAI",
    "url": "https://docs.flowiseai.com/",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nWelcome to Flowise\n🤔 What is Flowise?\n\nFlowise is an open source low-code tool for developers to build customized LLM orchestration flow & AI agents.\n\nWatch a quickstart demo (2mins)\n\nWatch a full demo (10 mins)\n\n🙌 Contributing\n\nSee contributing guide. Reach out to us at Discord if you have any questions or issues.\n\nNext\nGetting Started\n\nLast updated 2 months ago\n\n🤔 What is Flowise?\n🙌 Contributing\nEdit on GitHub"
  },
  {
    "title": "Getting Started | FlowiseAI",
    "url": "https://docs.flowiseai.com/getting-started#developers",
    "html": "FlowiseAI\nAsk or Search\nCtrl + K\nWelcome to Flowise\nGetting Started\nContributing\nUsing Flowise\nConfiguration\nIntegrations\nMigration Guide\nUse Cases\nPowered by GitBook\nGetting Started\nPrerequisite\n\nLatest NodeJS installed\n\n⚡Quick Start\n\nInstall Flowise\n\nCopy\nnpm install -g flowise\n\nStart Flowise\n\nCopy\nnpx flowise start\n\nOpen http://localhost:3000\n\n🐳 Docker\nDocker Compose\n\nGo to docker folder at the root of the project\n\nCopy the .env.example file and paste it as another file named .env\n\ndocker-compose up -d\n\nOpen http://localhost:3000\n\nYou can bring the containers down by docker-compose stop\n\nDocker Image\n\nBuild the image locally:\n\nCopy\ndocker build --no-cache -t flowise .\n\nRun image:\n\nCopy\ndocker run -d --name flowise -p 3000:3000 flowise\n\nStop image:\n\nCopy\ndocker stop flowise\n👨‍💻 Developers\n\nFlowise has 3 different modules in a single mono repository.\n\nserver: Node backend to serve API logics\n\nui: React frontend\n\ncomponents: Integrations components\n\nPrerequisite\n\nInstall PNPM\n\nCopy\nnpm i -g pnpm\nSetup\n\nClone the repository\n\nCopy\ngit clone https://github.com/FlowiseAI/Flowise.git\n\nGo into repository folder\n\nCopy\ncd Flowise\n\nInstall all dependencies of all modules:\n\nCopy\npnpm install\n\nBuild all the code:\n\nCopy\npnpm build\n\nStart the app:\n\nCopy\npnpm start\n\nYou can now access the app on http://localhost:3000\n\nFor development build:\n\nCreate .env file and specify the PORT (refer to .env.example) in packages/ui\n\nCreate .env file and specify the PORT (refer to .env.example) in packages/server\n\nCopy\npnpm dev\n\nAny code changes will reload the app automatically on http://localhost:8080\n\nWatch an introduction & setup tutorial on Flowise, shoutout to Leon!\n\nPrevious\nWelcome to Flowise\nNext\nContributing\n\nLast updated 2 months ago\n\nPrerequisite\n⚡Quick Start\n🐳 Docker\nDocker Compose\nDocker Image\n👨‍💻 Developers\nEdit on GitHub"
  }
]